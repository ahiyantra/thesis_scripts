{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes: slice into 640x640 pieces (for the object detection model training step) ~ manual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"D_01_new-work-03_task-03_SliceDivideCode_640[dot]ipynb\"\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "class ImageAnnotationProcessor:\n",
    "    def __init__(self, input_dir, output_dir, slice_size=640):\n",
    "        \"\"\"\n",
    "        Initialize the processor with input/output directories and slice size.\n",
    "        \n",
    "        Args:\n",
    "            input_dir (str): Directory containing images and JSON annotations\n",
    "            output_dir (str): Directory to save processed images and labels\n",
    "            slice_size (int): Size of image slices (default: 640 for YOLO compatibility)\n",
    "        \"\"\"\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.slice_size = slice_size\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Statistics\n",
    "        self.stats = {\n",
    "            \"total_files\": 0,\n",
    "            \"processed_files\": 0,\n",
    "            \"total_slices\": 0,\n",
    "            \"saved_slices\": 0,\n",
    "            \"skipped_slices\": 0,\n",
    "            \"annotations_processed\": 0,\n",
    "            \"failed_annotations\": 0,\n",
    "            \"rectangle_annotations\": 0,\n",
    "            \"polygon_annotations\": 0\n",
    "        }\n",
    "        \n",
    "    def find_matching_files(self):\n",
    "        \"\"\"Find all image files and their corresponding JSON annotations.\"\"\"\n",
    "        image_files = glob.glob(os.path.join(self.input_dir, \"*.jpg\")) + \\\n",
    "                     glob.glob(os.path.join(self.input_dir, \"*.png\"))\n",
    "        pairs = []\n",
    "        \n",
    "        self.stats[\"total_files\"] = len(image_files)\n",
    "        \n",
    "        for image_path in image_files:\n",
    "            base_name = Path(image_path).stem\n",
    "            json_path = os.path.join(self.input_dir, f\"{base_name}.json\")\n",
    "            \n",
    "            if os.path.exists(json_path):\n",
    "                pairs.append((image_path, json_path))\n",
    "            else:\n",
    "                print(f\"Warning: No matching JSON found for {image_path}\")\n",
    "                \n",
    "        return pairs\n",
    "\n",
    "    def normalize_points(self, points, shape_type):\n",
    "        \"\"\"\n",
    "        Convert different annotation formats to a standard [x_min, y_min, x_max, y_max] format.\n",
    "        \n",
    "        Args:\n",
    "            points: Points from the JSON file\n",
    "            shape_type: Type of shape ('rectangle', 'polygon', etc.)\n",
    "            \n",
    "        Returns:\n",
    "            list: Normalized points as [[x_min, y_min], [x_max, y_max]] or None if invalid\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if shape_type == \"rectangle\":\n",
    "                # Rectangle already has two diagonal points\n",
    "                self.stats[\"rectangle_annotations\"] += 1\n",
    "                return points\n",
    "                \n",
    "            elif shape_type == \"polygon\":\n",
    "                self.stats[\"polygon_annotations\"] += 1\n",
    "                # Extract min/max coordinates from polygon\n",
    "                points_array = np.array(points)\n",
    "                x_min, y_min = np.min(points_array, axis=0)\n",
    "                x_max, y_max = np.max(points_array, axis=0)\n",
    "                return [[x_min, y_min], [x_max, y_max]]\n",
    "                \n",
    "            else:\n",
    "                print(f\"Unsupported shape type: {shape_type}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error normalizing points: {e}, shape_type: {shape_type}\")\n",
    "            return None\n",
    "\n",
    "    def convert_to_yolov8_format(self, points, slice_bounds, image_bounds):\n",
    "        \"\"\"\n",
    "        Convert bounding box coordinates to YOLO format with boundary checking.\n",
    "        \n",
    "        Args:\n",
    "            points: Original bounding box points in format [[x_min, y_min], [x_max, y_max]]\n",
    "            slice_bounds: (x_min, y_min, x_max, y_max) of the current slice\n",
    "            image_bounds: (width, height) of the slice\n",
    "        \n",
    "        Returns:\n",
    "            list: YOLO format coordinates or None if invalid\n",
    "        \"\"\"\n",
    "        try:\n",
    "            x_min, y_min = points[0]\n",
    "            x_max, y_max = points[1]\n",
    "            \n",
    "            # Calculate coordinates relative to slice\n",
    "            slice_x_min, slice_y_min, slice_x_max, slice_y_max = slice_bounds\n",
    "            \n",
    "            # Check if box intersects slice\n",
    "            if (x_max < slice_x_min or x_min > slice_x_max or \n",
    "                y_max < slice_y_min or y_min > slice_y_max):\n",
    "                return None\n",
    "            \n",
    "            # Calculate new coordinates relative to slice\n",
    "            new_x_min = max(0, min(x_min - slice_x_min, image_bounds[0]))\n",
    "            new_y_min = max(0, min(y_min - slice_y_min, image_bounds[1]))\n",
    "            new_x_max = max(0, min(x_max - slice_x_min, image_bounds[0]))\n",
    "            new_y_max = max(0, min(y_max - slice_y_min, image_bounds[1]))\n",
    "            \n",
    "            # Skip if box is too small after clipping\n",
    "            if new_x_max - new_x_min < 2 or new_y_max - new_y_min < 2:\n",
    "                return None\n",
    "                \n",
    "            # Convert to YOLO format (class_id, x_center, y_center, width, height)\n",
    "            box_width = new_x_max - new_x_min\n",
    "            box_height = new_y_max - new_y_min\n",
    "            x_center = new_x_min + box_width / 2\n",
    "            y_center = new_y_min + box_height / 2\n",
    "            \n",
    "            # Validate final coordinates\n",
    "            if (x_center < 0 or x_center > image_bounds[0] or \n",
    "                y_center < 0 or y_center > image_bounds[1] or \n",
    "                box_width <= 0 or box_height <= 0):\n",
    "                return None\n",
    "                \n",
    "            return [0,  # class_id (assuming single class)\n",
    "                   x_center / image_bounds[0],\n",
    "                   y_center / image_bounds[1],\n",
    "                   box_width / image_bounds[0],\n",
    "                   box_height / image_bounds[1]]\n",
    "                   \n",
    "        except Exception as e:\n",
    "            print(f\"Error converting coordinates: {e}\")\n",
    "            self.stats[\"failed_annotations\"] += 1\n",
    "            return None\n",
    "\n",
    "    def process_image(self, image_path, json_path):\n",
    "        \"\"\"\n",
    "        Process a single image and its annotations.\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the image file\n",
    "            json_path (str): Path to the JSON annotation file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load image and annotations\n",
    "            image = Image.open(image_path)\n",
    "            image_width, image_height = image.size\n",
    "            \n",
    "            with open(json_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Calculate number of slices for progress bar\n",
    "            num_slices_x = (image_width - 1) // self.slice_size + 1\n",
    "            num_slices_y = (image_height - 1) // self.slice_size + 1\n",
    "            total_slices = num_slices_x * num_slices_y\n",
    "            self.stats[\"total_slices\"] += total_slices\n",
    "            \n",
    "            base_name = Path(image_path).stem\n",
    "            processed_count = 0\n",
    "            \n",
    "            # Process each slice\n",
    "            with tqdm(total=total_slices, desc=f\"Processing {base_name}\") as pbar:\n",
    "                for x in range(0, image_width, self.slice_size):\n",
    "                    for y in range(0, image_height, self.slice_size):\n",
    "                        # Define slice boundaries\n",
    "                        actual_slice_width = min(self.slice_size, image_width - x)\n",
    "                        actual_slice_height = min(self.slice_size, image_height - y)\n",
    "                        \n",
    "                        if actual_slice_width < self.slice_size or actual_slice_height < self.slice_size:\n",
    "                            # Skip partial slices\n",
    "                            pbar.update(1)\n",
    "                            self.stats[\"skipped_slices\"] += 1\n",
    "                            continue\n",
    "                            \n",
    "                        slice_bounds = (x, y, x + self.slice_size, y + self.slice_size)\n",
    "                        slice_image = image.crop(slice_bounds)\n",
    "                        \n",
    "                        # Process annotations for this slice\n",
    "                        slice_boxes = []\n",
    "                        for shape in data['shapes']:\n",
    "                            self.stats[\"annotations_processed\"] += 1\n",
    "                            \n",
    "                            # Get shape type (default to rectangle for backward compatibility)\n",
    "                            shape_type = shape.get(\"shape_type\", \"rectangle\")\n",
    "                            \n",
    "                            # Normalize points to standard format\n",
    "                            normalized_points = self.normalize_points(shape[\"points\"], shape_type)\n",
    "                            if not normalized_points:\n",
    "                                continue\n",
    "                                \n",
    "                            # Convert to YOLO format\n",
    "                            yolo_box = self.convert_to_yolov8_format(\n",
    "                                normalized_points, \n",
    "                                slice_bounds, \n",
    "                                (self.slice_size, self.slice_size)\n",
    "                            )\n",
    "                            if yolo_box:\n",
    "                                slice_boxes.append(yolo_box)\n",
    "                        \n",
    "                        # Save slice and annotations if boxes are found\n",
    "                        if slice_boxes:\n",
    "                            slice_filename = f\"{base_name}_slice_{x}_{y}\"\n",
    "                            \n",
    "                            # Save image\n",
    "                            image_output = os.path.join(self.output_dir, f\"{slice_filename}.png\")\n",
    "                            slice_image.save(image_output)\n",
    "                            \n",
    "                            # Save annotations\n",
    "                            label_output = os.path.join(self.output_dir, f\"{slice_filename}.txt\")\n",
    "                            with open(label_output, 'w') as f:\n",
    "                                for box in slice_boxes:\n",
    "                                    # Convert all values to Python native types\n",
    "                                    class_id = int(box[0])\n",
    "                                    x_center = float(box[1])\n",
    "                                    y_center = float(box[2])\n",
    "                                    width = float(box[3])\n",
    "                                    height = float(box[4])\n",
    "                                    # Write to file using Python native types\n",
    "                                    f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "                            \n",
    "                            processed_count += 1\n",
    "                            self.stats[\"saved_slices\"] += 1\n",
    "                        else:\n",
    "                            self.stats[\"skipped_slices\"] += 1\n",
    "                            \n",
    "                        pbar.update(1)\n",
    "                        \n",
    "            return processed_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "            return 0\n",
    "\n",
    "    def process_all(self):\n",
    "        \"\"\"Process all matching image-annotation pairs in the input directory.\"\"\"\n",
    "        pairs = self.find_matching_files()\n",
    "        if not pairs:\n",
    "            print(\"No valid image-annotation pairs found!\")\n",
    "            return\n",
    "            \n",
    "        total_processed = 0\n",
    "        for image_path, json_path in pairs:\n",
    "            processed = self.process_image(image_path, json_path)\n",
    "            total_processed += processed\n",
    "            self.stats[\"processed_files\"] += 1\n",
    "            \n",
    "        self.print_statistics()\n",
    "        print(f\"\\nProcessing complete! Generated {total_processed} valid slices.\")\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        \"\"\"Print processing statistics\"\"\"\n",
    "        print(\"\\n====== Processing Statistics ======\")\n",
    "        print(f\"Total image files found: {self.stats['total_files']}\")\n",
    "        print(f\"Files successfully processed: {self.stats['processed_files']}\")\n",
    "        print(f\"Total slices created: {self.stats['saved_slices']} / {self.stats['total_slices']}\")\n",
    "        print(f\"Slices skipped (no annotations): {self.stats['skipped_slices']}\")\n",
    "        print(f\"Annotation Statistics:\")\n",
    "        print(f\"  - Total processed: {self.stats['annotations_processed']}\")\n",
    "        print(f\"  - Rectangle annotations: {self.stats['rectangle_annotations']}\")\n",
    "        print(f\"  - Polygon annotations: {self.stats['polygon_annotations']}\")\n",
    "        print(f\"  - Failed annotations: {self.stats['failed_annotations']}\")\n",
    "        print(\"==================================\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Directory containing images and JSON files\n",
    "    # example 01 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\HM_aligned_to_SC_renamed_files_manual_labels_T_(new_OM_images)'\n",
    "    # example 02 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\25_pc_expanded_manual_labels_with_aligned_HM_images_T'\n",
    "    # example 03 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\50_pc_expanded_manual_labels_with_aligned_HM_images_T'\n",
    "    # example 04 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\75_pc_expanded_manual_labels_with_aligned_HM_images_T'\n",
    "    # example 05 : ''\n",
    "    input_dir = \"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\75_pc_expanded_manual_labels_with_aligned_HM_images_T\"  \n",
    "    # Directory to save processed files\n",
    "    # example 01 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_manual_labels'\n",
    "    # example 02 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_manual_labels_pc_125'\n",
    "    # example 03 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_manual_labels_pc_150'\n",
    "    # example 04 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_manual_labels_pc_175'\n",
    "    # example 05 : ''\n",
    "    output_dir = \"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_manual_labels_pc_175\"  \n",
    "    \n",
    "    processor = ImageAnnotationProcessor(\n",
    "        input_dir=input_dir,\n",
    "        output_dir=output_dir,\n",
    "        slice_size=640 # either using a derivative (512) of the size used originally (500) in the script or using the recommended size for YOLO models (640)\n",
    "    )\n",
    "    processor.process_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes: slice into 640x640 pieces (for the object detection model training step) ~ automated labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "class ImageAnnotationProcessor:\n",
    "    def __init__(self, input_dir, output_dir, slice_size=640):\n",
    "        \"\"\"\n",
    "        Initialize the processor with input/output directories and slice size.\n",
    "        \n",
    "        Args:\n",
    "            input_dir (str): Directory containing images and JSON annotations\n",
    "            output_dir (str): Directory to save processed images and labels\n",
    "            slice_size (int): Size of image slices (default: 640 for YOLO compatibility)\n",
    "        \"\"\"\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.slice_size = slice_size\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Statistics\n",
    "        self.stats = {\n",
    "            \"total_files\": 0,\n",
    "            \"processed_files\": 0,\n",
    "            \"total_slices\": 0,\n",
    "            \"saved_slices\": 0,\n",
    "            \"skipped_slices\": 0,\n",
    "            \"annotations_processed\": 0,\n",
    "            \"failed_annotations\": 0,\n",
    "            \"rectangle_annotations\": 0,\n",
    "            \"polygon_annotations\": 0\n",
    "        }\n",
    "        \n",
    "    def find_matching_files(self):\n",
    "        \"\"\"Find all image files and their corresponding JSON annotations.\"\"\"\n",
    "        image_files = glob.glob(os.path.join(self.input_dir, \"*.jpg\")) + \\\n",
    "                     glob.glob(os.path.join(self.input_dir, \"*.png\"))\n",
    "        pairs = []\n",
    "        \n",
    "        self.stats[\"total_files\"] = len(image_files)\n",
    "        \n",
    "        for image_path in image_files:\n",
    "            base_name = Path(image_path).stem\n",
    "            json_path = os.path.join(self.input_dir, f\"{base_name}.json\")\n",
    "            \n",
    "            if os.path.exists(json_path):\n",
    "                pairs.append((image_path, json_path))\n",
    "            else:\n",
    "                print(f\"Warning: No matching JSON found for {image_path}\")\n",
    "                \n",
    "        return pairs\n",
    "\n",
    "    def normalize_points(self, points, shape_type):\n",
    "        \"\"\"\n",
    "        Convert different annotation formats to a standard [x_min, y_min, x_max, y_max] format.\n",
    "        \n",
    "        Args:\n",
    "            points: Points from the JSON file\n",
    "            shape_type: Type of shape ('rectangle', 'polygon', etc.)\n",
    "            \n",
    "        Returns:\n",
    "            list: Normalized points as [[x_min, y_min], [x_max, y_max]] or None if invalid\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if shape_type == \"rectangle\":\n",
    "                # Rectangle already has two diagonal points\n",
    "                self.stats[\"rectangle_annotations\"] += 1\n",
    "                return points\n",
    "                \n",
    "            elif shape_type == \"polygon\":\n",
    "                self.stats[\"polygon_annotations\"] += 1\n",
    "                # Extract min/max coordinates from polygon\n",
    "                points_array = np.array(points)\n",
    "                x_min, y_min = np.min(points_array, axis=0)\n",
    "                x_max, y_max = np.max(points_array, axis=0)\n",
    "                return [[x_min, y_min], [x_max, y_max]]\n",
    "                \n",
    "            else:\n",
    "                print(f\"Unsupported shape type: {shape_type}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error normalizing points: {e}, shape_type: {shape_type}\")\n",
    "            return None\n",
    "\n",
    "    def convert_to_yolov8_format(self, points, slice_bounds, image_bounds):\n",
    "        \"\"\"\n",
    "        Convert bounding box coordinates to YOLO format with boundary checking.\n",
    "        \n",
    "        Args:\n",
    "            points: Original bounding box points in format [[x_min, y_min], [x_max, y_max]]\n",
    "            slice_bounds: (x_min, y_min, x_max, y_max) of the current slice\n",
    "            image_bounds: (width, height) of the slice\n",
    "        \n",
    "        Returns:\n",
    "            list: YOLO format coordinates or None if invalid\n",
    "        \"\"\"\n",
    "        try:\n",
    "            x_min, y_min = points[0]\n",
    "            x_max, y_max = points[1]\n",
    "            \n",
    "            # Calculate coordinates relative to slice\n",
    "            slice_x_min, slice_y_min, slice_x_max, slice_y_max = slice_bounds\n",
    "            \n",
    "            # Check if box intersects slice\n",
    "            if (x_max < slice_x_min or x_min > slice_x_max or \n",
    "                y_max < slice_y_min or y_min > slice_y_max):\n",
    "                return None\n",
    "            \n",
    "            # Calculate new coordinates relative to slice\n",
    "            new_x_min = max(0, min(x_min - slice_x_min, image_bounds[0]))\n",
    "            new_y_min = max(0, min(y_min - slice_y_min, image_bounds[1]))\n",
    "            new_x_max = max(0, min(x_max - slice_x_min, image_bounds[0]))\n",
    "            new_y_max = max(0, min(y_max - slice_y_min, image_bounds[1]))\n",
    "            \n",
    "            # Skip if box is too small after clipping\n",
    "            if new_x_max - new_x_min < 2 or new_y_max - new_y_min < 2:\n",
    "                return None\n",
    "                \n",
    "            # Convert to YOLO format (class_id, x_center, y_center, width, height)\n",
    "            box_width = new_x_max - new_x_min\n",
    "            box_height = new_y_max - new_y_min\n",
    "            x_center = new_x_min + box_width / 2\n",
    "            y_center = new_y_min + box_height / 2\n",
    "            \n",
    "            # Validate final coordinates\n",
    "            if (x_center < 0 or x_center > image_bounds[0] or \n",
    "                y_center < 0 or y_center > image_bounds[1] or \n",
    "                box_width <= 0 or box_height <= 0):\n",
    "                return None\n",
    "                \n",
    "            return [0,  # class_id (assuming single class)\n",
    "                   x_center / image_bounds[0],\n",
    "                   y_center / image_bounds[1],\n",
    "                   box_width / image_bounds[0],\n",
    "                   box_height / image_bounds[1]]\n",
    "                   \n",
    "        except Exception as e:\n",
    "            print(f\"Error converting coordinates: {e}\")\n",
    "            self.stats[\"failed_annotations\"] += 1\n",
    "            return None\n",
    "\n",
    "    def process_image(self, image_path, json_path):\n",
    "        \"\"\"\n",
    "        Process a single image and its annotations.\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the image file\n",
    "            json_path (str): Path to the JSON annotation file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load image and annotations\n",
    "            image = Image.open(image_path)\n",
    "            image_width, image_height = image.size\n",
    "            \n",
    "            with open(json_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Calculate number of slices for progress bar\n",
    "            num_slices_x = (image_width - 1) // self.slice_size + 1\n",
    "            num_slices_y = (image_height - 1) // self.slice_size + 1\n",
    "            total_slices = num_slices_x * num_slices_y\n",
    "            self.stats[\"total_slices\"] += total_slices\n",
    "            \n",
    "            base_name = Path(image_path).stem\n",
    "            processed_count = 0\n",
    "            \n",
    "            # Process each slice\n",
    "            with tqdm(total=total_slices, desc=f\"Processing {base_name}\") as pbar:\n",
    "                for x in range(0, image_width, self.slice_size):\n",
    "                    for y in range(0, image_height, self.slice_size):\n",
    "                        # Define slice boundaries\n",
    "                        actual_slice_width = min(self.slice_size, image_width - x)\n",
    "                        actual_slice_height = min(self.slice_size, image_height - y)\n",
    "                        \n",
    "                        if actual_slice_width < self.slice_size or actual_slice_height < self.slice_size:\n",
    "                            # Skip partial slices\n",
    "                            pbar.update(1)\n",
    "                            self.stats[\"skipped_slices\"] += 1\n",
    "                            continue\n",
    "                            \n",
    "                        slice_bounds = (x, y, x + self.slice_size, y + self.slice_size)\n",
    "                        slice_image = image.crop(slice_bounds)\n",
    "                        \n",
    "                        # Process annotations for this slice\n",
    "                        slice_boxes = []\n",
    "                        for shape in data['shapes']:\n",
    "                            self.stats[\"annotations_processed\"] += 1\n",
    "                            \n",
    "                            # Get shape type (default to rectangle for backward compatibility)\n",
    "                            shape_type = shape.get(\"shape_type\", \"rectangle\")\n",
    "                            \n",
    "                            # Normalize points to standard format\n",
    "                            normalized_points = self.normalize_points(shape[\"points\"], shape_type)\n",
    "                            if not normalized_points:\n",
    "                                continue\n",
    "                                \n",
    "                            # Convert to YOLO format\n",
    "                            yolo_box = self.convert_to_yolov8_format(\n",
    "                                normalized_points, \n",
    "                                slice_bounds, \n",
    "                                (self.slice_size, self.slice_size)\n",
    "                            )\n",
    "                            if yolo_box:\n",
    "                                slice_boxes.append(yolo_box)\n",
    "                        \n",
    "                        # Save slice and annotations if boxes are found\n",
    "                        if slice_boxes:\n",
    "                            slice_filename = f\"{base_name}_slice_{x}_{y}\"\n",
    "                            \n",
    "                            # Save image\n",
    "                            image_output = os.path.join(self.output_dir, f\"{slice_filename}.png\")\n",
    "                            slice_image.save(image_output)\n",
    "                            \n",
    "                            # Save annotations\n",
    "                            label_output = os.path.join(self.output_dir, f\"{slice_filename}.txt\")\n",
    "                            with open(label_output, 'w') as f:\n",
    "                                for box in slice_boxes:\n",
    "                                    # Convert all values to Python native types\n",
    "                                    class_id = int(box[0])\n",
    "                                    x_center = float(box[1])\n",
    "                                    y_center = float(box[2])\n",
    "                                    width = float(box[3])\n",
    "                                    height = float(box[4])\n",
    "                                    # Write to file using Python native types\n",
    "                                    f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "                            \n",
    "                            processed_count += 1\n",
    "                            self.stats[\"saved_slices\"] += 1\n",
    "                        else:\n",
    "                            self.stats[\"skipped_slices\"] += 1\n",
    "                            \n",
    "                        pbar.update(1)\n",
    "                        \n",
    "            return processed_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "            return 0\n",
    "\n",
    "    def process_all(self):\n",
    "        \"\"\"Process all matching image-annotation pairs in the input directory.\"\"\"\n",
    "        pairs = self.find_matching_files()\n",
    "        if not pairs:\n",
    "            print(\"No valid image-annotation pairs found!\")\n",
    "            return\n",
    "            \n",
    "        total_processed = 0\n",
    "        for image_path, json_path in pairs:\n",
    "            processed = self.process_image(image_path, json_path)\n",
    "            total_processed += processed\n",
    "            self.stats[\"processed_files\"] += 1\n",
    "            \n",
    "        self.print_statistics()\n",
    "        print(f\"\\nProcessing complete! Generated {total_processed} valid slices.\")\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        \"\"\"Print processing statistics\"\"\"\n",
    "        print(\"\\n====== Processing Statistics ======\")\n",
    "        print(f\"Total image files found: {self.stats['total_files']}\")\n",
    "        print(f\"Files successfully processed: {self.stats['processed_files']}\")\n",
    "        print(f\"Total slices created: {self.stats['saved_slices']} / {self.stats['total_slices']}\")\n",
    "        print(f\"Slices skipped (no annotations): {self.stats['skipped_slices']}\")\n",
    "        print(f\"Annotation Statistics:\")\n",
    "        print(f\"  - Total processed: {self.stats['annotations_processed']}\")\n",
    "        print(f\"  - Rectangle annotations: {self.stats['rectangle_annotations']}\")\n",
    "        print(f\"  - Polygon annotations: {self.stats['polygon_annotations']}\")\n",
    "        print(f\"  - Failed annotations: {self.stats['failed_annotations']}\")\n",
    "        print(\"==================================\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Directory containing images and JSON files\n",
    "    # example 01 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\HM_aligned_to_SC_renamed_files_automated_labels_T'\n",
    "    # example 02 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\25_pc_expanded_automated_labels_with_aligned_HM_images_T'\n",
    "    # example 03 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\50_pc_expanded_automated_labels_with_aligned_HM_images_T'\n",
    "    # example 04 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\75_pc_expanded_automated_labels_with_aligned_HM_images_T'\n",
    "    # example 05 : ''\n",
    "    input_dir = \"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\75_pc_expanded_automated_labels_with_aligned_HM_images_T\"  \n",
    "    # Directory to save processed files\n",
    "    # example 01 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_slicing_output_automated_labels_T'\n",
    "    # example 02 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_automated_labels_pc_125'\n",
    "    # example 03 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_automated_labels_pc_150'\n",
    "    # example 04 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_automated_labels_pc_175'\n",
    "    # example 05 : ''\n",
    "    output_dir = \"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_automated_labels_pc_175\"  \n",
    "    \n",
    "    processor = ImageAnnotationProcessor(\n",
    "        input_dir=input_dir,\n",
    "        output_dir=output_dir,\n",
    "        slice_size=640  # either using a derivative (512) of the size used originally (500) in the script or using the recommended size for YOLO models (640)\n",
    "    )\n",
    "    processor.process_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes: divide into test/train/val data sets (for the cross-validation splitting step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_yolo_directories(output_path):\n",
    "    \"\"\"\n",
    "    Create the standard YOLO dataset directory structure.\n",
    "    YOLO expects a specific directory layout:\n",
    "    - train/images/ and train/labels/\n",
    "    - val/images/ and val/labels/\n",
    "    - test/images/ and test/labels/\n",
    "    \n",
    "    Parameters:\n",
    "        output_path (str): Base directory where the dataset structure will be created\n",
    "    \"\"\"\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        # Create separate directories for images and their corresponding labels\n",
    "        os.makedirs(os.path.join(output_path, split, 'images'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_path, split, 'labels'), exist_ok=True)\n",
    "\n",
    "def get_file_pairs(source_path):\n",
    "    \"\"\"\n",
    "    Find matching pairs of images and their label files.\n",
    "    For YOLO, each image must have a corresponding label file with the same name but .txt extension.\n",
    "    ONLY includes pairs where both the image and label files exist.\n",
    "    \n",
    "    Parameters:\n",
    "        source_path (str): Directory containing the image and label files\n",
    "    \n",
    "    Returns:\n",
    "        list: Pairs of (image_file, label_file) that exist in the source directory\n",
    "    \"\"\"\n",
    "    # Get all image files\n",
    "    image_files = [f for f in os.listdir(source_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    # Get all label files\n",
    "    label_files = [f for f in os.listdir(source_path) if f.endswith('.txt')]\n",
    "    \n",
    "    file_pairs = []\n",
    "    \n",
    "    # Only include images that have matching label files\n",
    "    for img_file in image_files:\n",
    "        base_name = os.path.splitext(img_file)[0]  # Remove extension\n",
    "        label_file = base_name + '.txt'  # YOLO format label file\n",
    "        \n",
    "        # Strict check: only include pairs where both files exist\n",
    "        if label_file in label_files:\n",
    "            # Verify the label file is not empty (contains bounding boxes)\n",
    "            label_path = os.path.join(source_path, label_file)\n",
    "            if os.path.getsize(label_path) > 0:\n",
    "                file_pairs.append((img_file, label_file))\n",
    "            else:\n",
    "                print(f\"Skipping {img_file}: label file exists but is empty (no bounding boxes)\")\n",
    "        else:\n",
    "            print(f\"Skipping {img_file}: no corresponding label file found\")\n",
    "    \n",
    "    return file_pairs\n",
    "\n",
    "def copy_file_pair(source_path, output_path, split, image_file, label_file):\n",
    "    \"\"\"\n",
    "    Copy an image and its corresponding label file to the appropriate YOLO directories.\n",
    "    Maintains the relationship between images and their annotations.\n",
    "    \n",
    "    Parameters:\n",
    "        source_path (str): Source directory containing original files\n",
    "        output_path (str): Base directory of the YOLO dataset\n",
    "        split (str): Dataset split ('train', 'valid', or 'test')\n",
    "        image_file (str): Name of the image file\n",
    "        label_file (str): Name of the label file\n",
    "    \"\"\"\n",
    "    # Copy image to the images subdirectory of the appropriate split\n",
    "    shutil.copy(\n",
    "        os.path.join(source_path, image_file),\n",
    "        os.path.join(output_path, split, 'images', image_file)\n",
    "    )\n",
    "    \n",
    "    # Copy label to the labels subdirectory of the appropriate split\n",
    "    shutil.copy(\n",
    "        os.path.join(source_path, label_file),\n",
    "        os.path.join(output_path, split, 'labels', label_file)\n",
    "    )\n",
    "\n",
    "def split_dataset(source_folder, output_folder, train_size=0.7, val_size=0.15, test_size=0.15):\n",
    "    \"\"\"\n",
    "    Split the dataset into train, validation, and test sets while maintaining\n",
    "    the relationship between images and their label files.\n",
    "    \n",
    "    The function expects that the source_folder contains:\n",
    "    - Image files (.png, .jpg, .jpeg)\n",
    "    - YOLO format label files (.txt) with the same names as their corresponding images\n",
    "    \n",
    "    Parameters:\n",
    "        source_folder (str): Directory containing the image and label files\n",
    "        output_folder (str): Directory where the split dataset will be created\n",
    "        train_size (float): Proportion of data for training (default: 0.7)\n",
    "        val_size (float): Proportion of data for validation (default: 0.15)\n",
    "        test_size (float): Proportion of data for testing (default: 0.15)\n",
    "    \"\"\"\n",
    "    print(f\"Processing source directory: {source_folder}\")\n",
    "    \n",
    "    # Create fresh YOLO directory structure\n",
    "    if os.path.exists(output_folder):\n",
    "        print(f\"The output directory '{output_folder}' already exists. It will be replaced.\")\n",
    "        shutil.rmtree(output_folder)\n",
    "    print(f\"Creating output directory: '{output_folder}'\")\n",
    "    create_yolo_directories(output_folder)\n",
    "    \n",
    "    # Get all valid image-label pairs\n",
    "    file_pairs = get_file_pairs(source_folder)\n",
    "    total_pairs = len(file_pairs)\n",
    "    print(f\"Found {total_pairs} valid image-label pairs with bounding boxes\")\n",
    "    \n",
    "    if not file_pairs:\n",
    "        print(\"No valid image-label pairs found. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Perform the train-val-test split while keeping pairs together\n",
    "    train_pairs, temp_pairs = train_test_split(\n",
    "        file_pairs,\n",
    "        test_size=(val_size + test_size),\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    val_pairs, test_pairs = train_test_split(\n",
    "        temp_pairs,\n",
    "        test_size=test_size/(val_size + test_size),\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Process each split\n",
    "    splits = {\n",
    "        'train': train_pairs,\n",
    "        'valid': val_pairs,\n",
    "        'test': test_pairs\n",
    "    }\n",
    "    \n",
    "    # Copy files to their respective directories with progress tracking\n",
    "    for split, pairs in splits.items():\n",
    "        print(f\"\\nProcessing {split} split ({len(pairs)} pairs)\")\n",
    "        for img_file, label_file in tqdm(pairs, desc=f\"Copying {split} files\"):\n",
    "            try:\n",
    "                copy_file_pair(source_folder, output_folder, split, img_file, label_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing files {img_file}, {label_file}: {str(e)}\")\n",
    "    \n",
    "    # Print final statistics\n",
    "    print(\"\\nDataset split complete!\")\n",
    "    print(f\"Train set: {len(train_pairs)} pairs ({len(train_pairs)/total_pairs*100:.1f}%)\")\n",
    "    print(f\"Validation set: {len(val_pairs)} pairs ({len(val_pairs)/total_pairs*100:.1f}%)\")\n",
    "    print(f\"Test set: {len(test_pairs)} pairs ({len(test_pairs)/total_pairs*100:.1f}%)\")\n",
    "\n",
    "# Example usage\n",
    "# default = '/Users/gustavszviedris/Desktop/vet_images_sliced_copy/Training' ; \n",
    "# example 01 = 'E:\\\\-_EDI_-\\\\notes\\\\havetai+vetcyto\\\\vet_images_sliced\\\\Training' ; \n",
    "# example 02 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_manual_labels'\n",
    "# example 03 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_automated_labels'\n",
    "# example 04 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_manual_labels_pc_125'\n",
    "# example 05 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_automated_labels_pc_125'\n",
    "# example 06 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_manual_labels_pc_150'\n",
    "# example 07 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_automated_labels_pc_150'\n",
    "# example 08 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_manual_labels_pc_175'\n",
    "# example 09 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_automated_labels_pc_175'\n",
    "# example 10 : ''\n",
    "source_folder = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\640_T_slicing_output_automated_labels_pc_175' ; \n",
    "# default = '/Users/gustavszviedris/Desktop/vet_images_sliced_split' ; \n",
    "# example 01 = 'E:\\\\-_EDI_-\\\\notes\\\\havetai+vetcyto\\\\vet_images_sliced_split' ; \n",
    "# example 02 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_manual_labels_T_640'\n",
    "# example 03 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640'\n",
    "# example 04 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_manual_labels_T_640_pc_125'\n",
    "# example 05 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_125'\n",
    "# example 06 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_manual_labels_T_640_pc_150'\n",
    "# example 07 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_150'\n",
    "# example 08 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_manual_labels_T_640_pc_175'\n",
    "# example 09 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_175'\n",
    "# example 10 : ''\n",
    "output_folder = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_175' ; \n",
    "\n",
    "split_dataset(source_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes: rewriting permissions for files (such as undesirable results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o-c\n",
    "\n",
    "import os\n",
    "\n",
    "def set_permissions_recursive(path, dir_mode=0o777, file_mode=0o666):\n",
    "    \"\"\"\n",
    "    Recursively set permissions for a folder.\n",
    "    \n",
    "    Directories are set to `dir_mode` (default 777: read, write, execute)\n",
    "    Files are set to `file_mode` (default 666: read and write).\n",
    "    \n",
    "    Note: For directories the execute bit is necessary to access their contents.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        raise NotADirectoryError(f\"'{path}' is not a valid directory.\")\n",
    "    \n",
    "    # Change permission for the root directory\n",
    "    os.chmod(path, dir_mode)\n",
    "    \n",
    "    # Walk through all subdirectories and files\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for d in dirs:\n",
    "            os.chmod(os.path.join(root, d), dir_mode)\n",
    "        for f in files:\n",
    "            os.chmod(os.path.join(root, f), file_mode)\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# Provide your results folder path here:\n",
    "results_folder = \"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_manual_labels_T_500\\\\results\"  # <-- update this path accordingly ~ default : '/path/to/your/results_folder'\n",
    "\n",
    "try:\n",
    "    set_permissions_recursive(results_folder)\n",
    "    print(f\"Permissions updated for folder: {results_folder}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# a-c\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import stat\n",
    "\n",
    "def set_permissions(path):\n",
    "    \"\"\"Recursively make directory and contents readable/writable by everyone\"\"\"\n",
    "    try:\n",
    "        if os.name == 'nt':  # Windows\n",
    "            # Remove read-only attributes from files/directories\n",
    "            subprocess.run(f'attrib -r \"{os.path.abspath(path)}\" /s /d', shell=True, check=True)\n",
    "        else:  # Unix/Linux/macOS\n",
    "            # Recursively set 777 permissions (rwx for all)\n",
    "            for root, dirs, files in os.walk(path):\n",
    "                for d in dirs:\n",
    "                    os.chmod(os.path.join(root, d), stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n",
    "                for f in files:\n",
    "                    os.chmod(os.path.join(root, f), stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n",
    "            # Set permissions for the root directory itself\n",
    "            os.chmod(path, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n",
    "            \n",
    "        print(f\"Successfully set permissions for: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting permissions: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Example usage\n",
    "results_path = r\"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_manual_labels_T_500\\\\results\"  # either \"C:\\Users\\user\\project\\results\" for windows or \"/home/user/project/results\" for Linux/macOS\n",
    "set_permissions(results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes: cleaning up garbage files (such as discarded results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Navigate to the data set folder & delete any read-only folders, in case that they get created by accident\n",
    "! echo \"# test 01\" && cd \"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\" && dir\n",
    "#shutil.rmtree(\"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640\\\\results\")\n",
    "#hutil.rmtree(\"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640\\\\runs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes: counting images & instances in data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# provide address\n",
    "# 'original-00' = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\02nd_task-03\\\\October15.v1i.yolov8\\\\data.yaml'\n",
    "# 'attempt-00' = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\google_colab-splitting_output_manual_labels-20250306T170409Z-001\\\\splitting_output_manual_labels_T_500\\\\data.yaml'\n",
    "# 'attempt-01' = [not used for any step]\n",
    "# 'attempt-02' = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_manual_labels_T_500\\\\data.yaml'\n",
    "# 'attempt-03' = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_manual_labels_T_640\\\\data.yaml'\n",
    "# 'attempt-04' = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_automated_labels_T_640\\\\data.yaml'\n",
    "# 'attempt-05' = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_manual_labels_T_640_pc_125\\\\data.yaml'\n",
    "# 'attempt-06' = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_automated_labels_T_640_pc_125\\\\data.yaml'\n",
    "# 'attempt-07' = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_manual_labels_T_640_pc_150\\\\data.yaml'\n",
    "# 'attempt-08' = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_150\\\\data.yaml'\n",
    "# 'attempt-09' = ?\n",
    "# 'attempt-10' = ?\n",
    "data_yaml_path = \"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_150\\\\data.yaml\"\n",
    "# Define paths (adjust as needed) ~ train or valid or test ~ 'train/labels' vs 'valid/labels' vs 'test/labels'\n",
    "labels_path = os.path.join(os.path.dirname(data_yaml_path), 'train/labels')\n",
    "\n",
    "# Get all txt files (labels)\n",
    "label_files = [f for f in os.listdir(labels_path) if f.endswith('.txt')]\n",
    "image_count = len(label_files)\n",
    "\n",
    "# Count object instances\n",
    "instance_count = 0\n",
    "for label_file in label_files:\n",
    "    file_path = os.path.join(labels_path, label_file)\n",
    "    with open(file_path, 'r') as f:\n",
    "        instance_count += len(f.readlines())\n",
    "\n",
    "print(f\"Training/Validating/Testing set: {image_count} images with {instance_count} object instances...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  notes: reviewing model details for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# \"original-00\" = \"task-03\" = \"experiment-step-02\" [ManualAnnotations] ~ 100%\n",
    "# model_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\02nd_task-03\\\\October15.v1i.yolov8\\\\results\\\\200_epochs-\\\\weights\\\\'\n",
    "# “attempt-00” = “experiment-step-04” [ManualAnnotations] ~ 100% (models missing! deleted to make space? transferred to external memory drive?)\n",
    "# model_path = '' \n",
    "# “attempt-02” = “experiment-step-05” [ManualAnnotations] ~ 100%\n",
    "# model_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_manual_labels_T_500\\\\results\\\\yolov8s_training_20250224_005615\\\\weights\\\\'\n",
    "# \"attempt-03\" = \"experiment-step-06\" [ManualAnnotations] ~ 100%\n",
    "# model_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_manual_labels_T_640\\\\results\\\\yolov8s_training_20250226_013840\\\\weights\\\\'\n",
    "# \"attempt-04\" = \"experiment-step-07\" [AutomatedAnnotations] ~ 100%\n",
    "# model_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_automated_labels_T_640\\\\results\\\\yolov8s_training_20250308_124715\\\\weights\\\\'\n",
    "# “attempt-05” = “experiment-step-08” [ManualAnnotations] ~ 125%\n",
    "# model_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_manual_labels_T_640_pc_125\\\\results\\\\yolov8s_training_20250308_214357\\\\\\weights\\\\'\n",
    "# “attempt-06” = “experiment-step-09” [AutomatedAnnotations] ~ 125%\n",
    "# model_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_125\\\\results\\\\yolov8s_training_20250311_013323\\\\weights\\\\'\n",
    "# \"attempt-07\" = \"experiment-step-10\" [ManualAnnotations] ~ 150%\n",
    "# model_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_manual_labels_T_640_pc_150\\\\results\\\\yolov8s_training_20250311_172821\\\\weights\\\\'\n",
    "# \"attempt-08\" = \"experiment-step-11\" [AutomatedAnnotations] ~ 150%\n",
    "# model_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_150\\\\results\\\\yolov8s_training_20250311_221910\\\\weights\\\\'\n",
    "# \"attempt-09\" = ?\n",
    "# 'attempt-10' = ?\n",
    "# Load either your best or last model\n",
    "print(\"\\nLoading the last resulting model...\")\n",
    "# default = '{project_path}/{name}/weights/last.pt'\n",
    "model_path_last = f'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_150\\\\results\\\\yolov8s_training_20250311_221910\\\\weights\\\\last.pt'  # last.pt or best.pt\n",
    "model_last = YOLO(model_path_last)\n",
    "# Access model information\n",
    "print(\"\\nmodel's info:\\n\", model_last.info())  # Basic model information\n",
    "print(\"\\nmodel's names:\\n\", model_last.names)   # Class names\n",
    "#print(\"\\nmodel's ckpt:\\n\", model_last.ckpt)    # Checkpoint information (uses up too much space)\n",
    "# If trained with validation, metrics are stored in model.metrics\n",
    "if hasattr(model_last, 'metrics'):\n",
    "    print(\"\\nSaved metrics:\", model_last.metrics)\n",
    "\n",
    "# default = 'path/to/your/validation/data.yaml'\n",
    "# \"original-00\" = \"task-03\" = \"experiment-step-02\" [ManualAnnotations] ~ 100%\n",
    "# data yaml = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\02nd_task-03\\\\October15.v1i.yolov8\\\\data.yaml'\n",
    "# “attempt-00” = “experiment-step-04” [ManualAnnotations] ~ 100% (models missing! deleted to make space? transferred to external memory drive?)\n",
    "# data yaml = '' \n",
    "# “attempt-02” = “experiment-step-05” [ManualAnnotations] ~ 100%\n",
    "# data yaml = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_manual_labels_T_500\\\\data.yaml'\n",
    "# \"attempt-03\" = \"experiment-step-06\" [ManualAnnotations] ~ 100%\n",
    "# data yaml = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_manual_labels_T_640\\\\data.yaml'\n",
    "# \"attempt-04\" = \"experiment-step-07\" [AutomatedAnnotations] ~ 100%\n",
    "# data yaml = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_automated_labels_T_640\\\\data.yaml'\n",
    "# “attempt-05” = “experiment-step-08” [ManualAnnotations] ~ 125%\n",
    "# data yaml = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\_legacy_\\\\splitting_output_manual_labels_T_640_pc_125\\\\data.yaml'\n",
    "# “attempt-06” = “experiment-step-09” [AutomatedAnnotations] ~ 125%\n",
    "# data yaml = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_125\\\\data.yaml'\n",
    "# \"attempt-07\" = \"experiment-step-10\" [ManualAnnotations] ~ 150%\n",
    "# data yaml = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_manual_labels_T_640_pc_150\\\\data.yaml'\n",
    "# \"attempt-08\" = \"experiment-step-11\" [AutomatedAnnotations] ~ 150%\n",
    "# data yaml = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_150\\\\data.yaml'\n",
    "# \"attempt-09\" = ?\n",
    "# 'attempt-10' = ?\n",
    "test_results = model_last.val(data='C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_150\\\\data.yaml', split='') # train or val or test\n",
    "print(f\"Box Precision: {test_results.box.p}\")\n",
    "print(f\"Box Recall: {test_results.box.r}\")\n",
    "print(f\"Box MAP50: {test_results.box.map50}\")\n",
    "print(f\"Box MAP50-95: {test_results.box.map}\")\n",
    "\n",
    "# Extract and print specific metrics for the last model\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Load either your best or last model\n",
    "print(\"\\nLoading the best resulting model...\")\n",
    "# default = '{project_path}/{name}/weights/best.pt'\n",
    "model_path_best = f'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_150\\\\results\\\\yolov8s_training_20250311_221910\\\\weights\\\\best.pt'  # best.pt or last.pt\n",
    "model_best = YOLO(model_path_best)\n",
    "# Access model information\n",
    "print(\"\\nmodel's info:\\n\", model_best.info())  # Basic model information\n",
    "print(\"\\nmodel's names:\\n\", model_best.names)   # Class names\n",
    "#print(\"\\nmodel's ckpt:\\n\", model_best.ckpt)    # Checkpoint information (uses up too much space)\n",
    "# If trained with validation, metrics are stored in model.metrics\n",
    "if hasattr(model_best, 'metrics'):\n",
    "    print(\"\\nSaved metrics:\", model_best.metrics)\n",
    "\n",
    "# default = 'path/to/your/validation/data.yaml'\n",
    "test_results = model_best.val(data='C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_150\\\\data.yaml', split='') # train or val or test\n",
    "print(f\"Box Precision: {test_results.box.p}\")\n",
    "print(f\"Box Recall: {test_results.box.r}\")\n",
    "print(f\"Box MAP50: {test_results.box.map50}\")\n",
    "print(f\"Box MAP50-95: {test_results.box.map}\")\n",
    "\n",
    "# Extract and print specific metrics for the best model\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: The End."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
