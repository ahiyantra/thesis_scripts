{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790784d8-c969-4ae2-a591-a1ba5ba944c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"script_v2-151_2A1_continuation-modified[dot]ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e146c5f-4832-4736-9eaf-f1195c70b768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# Enhanced Continuation Script for \"WGAN-SN v2.151\" with Comprehensive Improvements\n",
    "# Builds upon the original training with additional features for better monitoring,\n",
    "# stability, metrics, and visualizations\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend for server environments\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import logging\n",
    "import sys\n",
    "import gc\n",
    "import random\n",
    "import traceback\n",
    "import importlib\n",
    "import subprocess\n",
    "import shutil\n",
    "import re\n",
    "from datetime import datetime\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from collections import deque\n",
    "\n",
    "print(\"!!! setting the 'TF_ENABLE_ONEDNN_OPTS' value to '0' for avoiding the 'oneDNN custom operations' message in powershell console !!!\")\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "# --- Auto-installation Block ---\n",
    "def install_and_import(package_name, import_name=None, pip_name=None):\n",
    "    \"\"\"Tries to import a package, installs it via pip if import fails.\"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package_name\n",
    "    if pip_name is None:\n",
    "        pip_name = package_name\n",
    "    try:\n",
    "        module = importlib.import_module(package_name)\n",
    "        globals()[import_name] = module\n",
    "        print(f\"Successfully imported {package_name} as {import_name}\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(f\"{package_name} not found. Attempting installation using pip...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pip_name])\n",
    "            module = importlib.import_module(package_name)\n",
    "            globals()[import_name] = module\n",
    "            print(f\"Successfully installed and imported {package_name} as {import_name}\")\n",
    "            return True\n",
    "        except (subprocess.CalledProcessError, ImportError, ModuleNotFoundError) as e:\n",
    "            print(f\"ERROR: Failed to install/import {package_name} (pip name: {pip_name}). {e}\")\n",
    "            print(\"Please install required packages manually and restart the script.\")\n",
    "            return False\n",
    "\n",
    "print(\"--- Checking and Installing Dependencies ---\")\n",
    "# Core dependencies\n",
    "numpy_success = install_and_import('numpy', 'np')\n",
    "torch_success = install_and_import('torch')\n",
    "torchvision_success = install_and_import('torchvision')\n",
    "install_and_import('PIL')\n",
    "install_and_import('tqdm')\n",
    "install_and_import('matplotlib.pyplot', 'plt')\n",
    "install_and_import('scipy')\n",
    "install_and_import('pytorch_fid', pip_name='pytorch-fid')\n",
    "\n",
    "# For advanced visualizations\n",
    "install_and_import('sklearn.manifold', 'manifold', pip_name='scikit-learn')\n",
    "install_and_import('umap', pip_name='umap-learn')\n",
    "\n",
    "# For improved metrics\n",
    "install_and_import('torchmetrics.image.kid', 'torchmetrics_kid', pip_name='torchmetrics')\n",
    "\n",
    "# Check critical dependencies\n",
    "critical_imports_successful = all([numpy_success, torch_success, torchvision_success])\n",
    "if not critical_imports_successful:\n",
    "    print(\"ERROR: Critical packages (numpy, torch, torchvision) failed to import.\")\n",
    "    print(\"Please install these packages manually and restart the script.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- Core Imports ---\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.nn.utils import spectral_norm \n",
    "from torch.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Import FID calculation utilities ---\n",
    "try:\n",
    "    from pytorch_fid.inception import InceptionV3\n",
    "    from pytorch_fid.fid_score import calculate_frechet_distance\n",
    "    print(\"Successfully imported FID utilities\")\n",
    "    FID_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"WARNING: Could not import FID utilities from 'pytorch_fid'. FID calculation will be disabled.\")\n",
    "    FID_AVAILABLE = False\n",
    "\n",
    "# --- Import KID calculation (TorchMetrics) ---\n",
    "try:\n",
    "    from torchmetrics.image.kid import KernelInceptionDistance\n",
    "    print(\"Successfully imported KID utilities from torchmetrics\")\n",
    "    TORCHMETRICS_KID_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"WARNING: Could not import KID from torchmetrics. Will use custom implementation.\")\n",
    "    TORCHMETRICS_KID_AVAILABLE = False\n",
    "\n",
    "# --- Import visualization utilities ---\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    TSNE_AVAILABLE = True\n",
    "    print(\"Successfully imported t-SNE from sklearn\")\n",
    "except ImportError:\n",
    "    print(\"WARNING: Could not import t-SNE. Feature space visualization will be limited.\")\n",
    "    TSNE_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import umap\n",
    "    UMAP_AVAILABLE = True\n",
    "    print(\"Successfully imported UMAP\")\n",
    "except ImportError:\n",
    "    print(\"WARNING: Could not import UMAP. Feature space visualization will be limited.\")\n",
    "    UMAP_AVAILABLE = False\n",
    "\n",
    "# --- Import models and dataset class from separate files ---\n",
    "try:\n",
    "    from wgan_models_v2A1 import Generator, CriticSN, initialize_weights \n",
    "    print(\"Successfully imported models from local .py files.\")\n",
    "    MODELS_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: Could not import models from .py files: {e}\")\n",
    "    print(\"Ensure wgan_models_v2A1.py exists in the same directory.\")\n",
    "    MODELS_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from pollen_datasets_v2A1 import PollenDataset \n",
    "    print(\"Successfully imported dataset from local .py files.\")\n",
    "    DATASET_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: Could not import dataset from .py files: {e}\")\n",
    "    print(\"Ensure pollen_datasets_v2A1.py exists in the same directory.\")\n",
    "    DATASET_AVAILABLE = False\n",
    "\n",
    "# --- Verify critical imports ---\n",
    "if not MODELS_AVAILABLE or not DATASET_AVAILABLE:\n",
    "    print(\"Critical model or dataset definitions missing. Please fix import issues.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ====== CONFIGURATION SECTION - MODIFY THESE SETTINGS ======\n",
    "\n",
    "# --- Original Paths ---\n",
    "ORIGINAL_OUTPUT_DIR = r\"C:\\Users\\praam\\Desktop\\havetai+vetcyto\\task-05_dataset\\WGAN-SN_training-output_v2-151\"\n",
    "PREPROCESSED_DATA_DIR = r\"C:\\Users\\praam\\Desktop\\havetai+vetcyto\\task-05_dataset\\pre-processing_px-128_step_automated-labels_pc-150\"\n",
    "\n",
    "# --- Continuation Settings ---\n",
    "CONTINUATION_DIR_NAME = \"continuation_enhanced\"  # Change this for different continuation runs\n",
    "CONTINUATION_DIR = os.path.join(ORIGINAL_OUTPUT_DIR, CONTINUATION_DIR_NAME)\n",
    "CONTINUATION_PREFIX = \"cont_\"  # Prefix for continuation files\n",
    "\n",
    "# --- Checkpoint Selection ---\n",
    "START_FROM_EPOCH_CKPT = None  # Specific epoch number or None\n",
    "USE_BEST_FID_CKPT = True  # Use best FID checkpoint (ignored if START_FROM_EPOCH_CKPT is not None)\n",
    "LATEST_CKPT_FILENAME = \"latest_checkpoint_sn_v2151.pth.tar\"\n",
    "BEST_FID_CKPT_FILENAME = \"best_fid_checkpoint_v2151.pth.tar\"\n",
    "\n",
    "# --- Training Settings ---\n",
    "USE_ORIGINAL_SETTINGS = False  # Load HPs from original config or use NEW ones below?\n",
    "NEW_LEARNING_RATE = 0.00002  # Used if USE_ORIGINAL_SETTINGS is False\n",
    "NEW_BATCH_SIZE = 64  # Used if USE_ORIGINAL_SETTINGS is False\n",
    "NEW_CRITIC_ITERATIONS = 5  # Used if USE_ORIGINAL_SETTINGS is False\n",
    "USE_GRADIENT_CLIPPING = False  # Enable/disable gradient clipping (SN should suffice)\n",
    "ADDITIONAL_EPOCHS = 250  # Number of additional epochs to train\n",
    "\n",
    "# --- Early Stopping Settings ---\n",
    "NEW_EARLY_STOPPING_PATIENCE = 50  # New patience value for the continuation run\n",
    "\n",
    "# --- Evaluation Settings ---\n",
    "PRIMARY_EVAL_METRIC = \"FID\"  # \"FID\" or \"KID\"\n",
    "FID_FREQ_EPOCHS = 1  # How often to calculate metrics\n",
    "FID_NUM_IMAGES = 10000  # Number of images for FID/KID calculation\n",
    "FID_BATCH_SIZE = 64  # Batch size for metric calculations\n",
    "CALCULATE_KID = True  # Also calculate KID alongside FID\n",
    "KID_SUBSET_SIZE = 1000  # Subset size for KID calculation\n",
    "KID_SUBSETS = 100  # Number of subsets for KID calculation\n",
    "\n",
    "# --- Plotting Settings ---\n",
    "PLOT_PER_EPOCH = True  # Generate plots after each evaluation epoch\n",
    "PLOT_FEATURE_SPACE = True  # Generate t-SNE/UMAP visualizations\n",
    "USE_UMAP = True  # Prefer UMAP over t-SNE if available\n",
    "TSNE_UMAP_SAMPLE_SIZE = 2000  # Number of samples for feature space visualization\n",
    "TSNE_PERPLEXITY = 30  # t-SNE perplexity parameter\n",
    "TSNE_UMAP_RANDOM_STATE = 42  # Random seed for reproducibility\n",
    "\n",
    "# --- Sample Settings ---\n",
    "SAMPLE_FREQ_STEPS = 500  # How often to save sample images during training\n",
    "\n",
    "# --- Stability Monitoring ---\n",
    "MONITOR_LOSS_STABILITY = True  # Enable loss stability monitoring\n",
    "LOSS_STABILITY_WINDOW = 100  # Window size for moving average\n",
    "LOSS_STABILITY_THRESHOLD = 5.0  # Threshold for abnormal loss spikes\n",
    "HEARTBEAT_LOG_FREQ = 200  # How often to log \"heartbeat\" messages (0 to disable)\n",
    "\n",
    "# --- Misc Settings ---\n",
    "FORCE_RECALCULATE_REAL_STATS = False  # Force recalculation of real image statistics\n",
    "AMP_ENABLED = False  # Automatic Mixed Precision (keep disabled as in original script)\n",
    "\n",
    "# --- Random Seed for Reproducibility ---\n",
    "MANUAL_SEED = 42\n",
    "\n",
    "# ====== DO NOT MODIFY BELOW THIS LINE UNLESS YOU KNOW WHAT YOU'RE DOING ======\n",
    "\n",
    "# --- Create Continuation Directories ---\n",
    "CONT_CHKPT_DIR = os.path.join(CONTINUATION_DIR, \"checkpoints\")\n",
    "CONT_SAMPLE_DIR = os.path.join(CONTINUATION_DIR, \"samples\")\n",
    "CONT_LOG_DIR = os.path.join(CONTINUATION_DIR, \"logs\")\n",
    "CONT_PLOT_DIR = os.path.join(CONTINUATION_DIR, \"plots\")\n",
    "CONT_ANALYSIS_DIR = os.path.join(CONTINUATION_DIR, \"analysis_results\")\n",
    "\n",
    "# Create all required directories\n",
    "for directory in [CONTINUATION_DIR, CONT_CHKPT_DIR, CONT_SAMPLE_DIR, CONT_LOG_DIR, CONT_PLOT_DIR, CONT_ANALYSIS_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# --- Setup Logging ---\n",
    "log_formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(name)s - %(message)s')\n",
    "logger = logging.getLogger(\"WGAN_Continuation_Enhanced\")\n",
    "logger.setLevel(logging.INFO)\n",
    "# Clear any existing handlers\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "# Add console handler\n",
    "console_handler = logging.StreamHandler(sys.stdout)\n",
    "console_handler.setFormatter(log_formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Add file handler\n",
    "log_file = os.path.join(CONT_LOG_DIR, f\"{CONTINUATION_PREFIX}training_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "file_handler = logging.FileHandler(log_file, mode='a')\n",
    "file_handler.setFormatter(log_formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.info(\"=\"*80)\n",
    "logger.info(f\"WGAN-SN Training Continuation Script (Enhanced) - {datetime.now()}\")\n",
    "logger.info(f\"Output directory: {CONTINUATION_DIR}\")\n",
    "logger.info(\"=\"*80)\n",
    "\n",
    "# --- Set Random Seeds ---\n",
    "if MANUAL_SEED is not None:\n",
    "    logger.info(f\"Using manual seed: {MANUAL_SEED}\")\n",
    "    random.seed(MANUAL_SEED)\n",
    "    np.random.seed(MANUAL_SEED)\n",
    "    torch.manual_seed(MANUAL_SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(MANUAL_SEED)\n",
    "\n",
    "# --- Setup Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    logger.info(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    logger.info(f\"GPU Name: {gpu_name}\")\n",
    "\n",
    "logger.info(f\"AMP Enabled: {AMP_ENABLED}\")\n",
    "logger.info(f\"Gradient Clipping Enabled: {USE_GRADIENT_CLIPPING}\")\n",
    "\n",
    "# ==============================================\n",
    "# Utility Functions\n",
    "# ==============================================\n",
    "\n",
    "# --- GPU Memory Logger ---\n",
    "def log_gpu_memory_usage(step=''):\n",
    "    \"\"\"Log current GPU memory usage to the logger\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return\n",
    "    \n",
    "    allocated = torch.cuda.memory_allocated() / (1024 ** 3)  # GB\n",
    "    reserved = torch.cuda.memory_reserved() / (1024 ** 3)    # GB\n",
    "    \n",
    "    logger.info(f\"GPU Memory [{step}]: Allocated: {allocated:.2f} GB | Reserved: {reserved:.2f} GB\")\n",
    "\n",
    "# --- KID Calculation Fallback Functions ---\n",
    "def polynomial_kernel_custom(X, Y, degree=3, gamma=None, coef0=1.0):\n",
    "    \"\"\"\n",
    "    Polynomial kernel for KID: k(x,y) = (gamma <x,y> + coef0)^degree\n",
    "    Using carefully balanced parameters to prevent underflow/overflow.\n",
    "    \"\"\"\n",
    "    # Convert to higher precision\n",
    "    X = X.astype(np.float64)\n",
    "    Y = Y.astype(np.float64)\n",
    "    \n",
    "    # Normalize features with slightly relaxed epsilon\n",
    "    X_norm = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-8)\n",
    "    Y_norm = Y / (np.linalg.norm(Y, axis=1, keepdims=True) + 1e-8)\n",
    "    \n",
    "    # More balanced parameters that won't underflow\n",
    "    gamma = 0.2\n",
    "    coef0 = 1.0\n",
    "    degree = 3\n",
    "    \n",
    "    dot_product = np.matmul(X_norm, Y_norm.T)\n",
    "    \n",
    "    # Prevent exact zeros with lower bound\n",
    "    return np.clip((gamma * dot_product + coef0) ** degree, 1e-8, 1e6)\n",
    "\n",
    "def calculate_kid_from_features_custom(real_features, fake_features, subset_size=1000, num_subsets=100):\n",
    "    \"\"\"\n",
    "    Calculate KID given features extracted from Inception.\n",
    "    Uses polynomial kernel and subsampling with safeguards against numerical issues.\n",
    "    \"\"\"\n",
    "    # Use high precision\n",
    "    real_features = real_features.astype(np.float64)\n",
    "    fake_features = fake_features.astype(np.float64)\n",
    "    \n",
    "    # Center the features (remove mean) - this is still good practice\n",
    "    real_features = real_features - np.mean(real_features, axis=0, keepdims=True)\n",
    "    fake_features = fake_features - np.mean(fake_features, axis=0, keepdims=True)\n",
    "    \n",
    "    n_r, n_f = real_features.shape[0], fake_features.shape[0]\n",
    "    \n",
    "    subset_size = min(subset_size, min(n_r, n_f))\n",
    "    kid_values = []\n",
    "    \n",
    "    # Verify inputs aren't identical\n",
    "    if np.array_equal(real_features, fake_features):\n",
    "        logger.warning(\"WARNING: real_features and fake_features are identical arrays! KID calculation will be biased.\")\n",
    "    \n",
    "    for _ in range(num_subsets):\n",
    "        # Sample subset_size features from both distributions\n",
    "        r_idx = np.random.choice(n_r, size=subset_size, replace=False)\n",
    "        f_idx = np.random.choice(n_f, size=subset_size, replace=False)\n",
    "        \n",
    "        r_subset = real_features[r_idx]\n",
    "        f_subset = fake_features[f_idx]\n",
    "        \n",
    "        # Calculate polynomial kernel MMD (Maximum Mean Discrepancy)\n",
    "        k_rr = polynomial_kernel_custom(r_subset, r_subset)\n",
    "        k_rf = polynomial_kernel_custom(r_subset, f_subset)\n",
    "        k_ff = polynomial_kernel_custom(f_subset, f_subset)\n",
    "        \n",
    "        # Calculate unbiased MMD estimate with safeguards\n",
    "        n = subset_size\n",
    "        mmd_numerator = np.sum(k_rr) - np.trace(k_rr) + np.sum(k_ff) - np.trace(k_ff) - 2 * np.sum(k_rf)\n",
    "        mmd_denominator = n * (n-1)\n",
    "        \n",
    "        # Prevent division by zero (should never happen with our subset size checks)\n",
    "        if mmd_denominator <= 0:\n",
    "            logger.warning(\"WARNING: Invalid denominator in KID calculation!\")\n",
    "            mmd = 0.01  # Fallback value\n",
    "        else:\n",
    "            mmd = mmd_numerator / mmd_denominator\n",
    "        \n",
    "        # Ensure non-negative MMD and prevent exact zeros\n",
    "        mmd = max(1e-8, mmd)\n",
    "        kid_values.append(mmd)\n",
    "    \n",
    "    return np.mean(kid_values), np.std(kid_values)\n",
    "\n",
    "# --- Checkpoint Finding Utilities ---\n",
    "def find_checkpoint_file(original_ckpt_dir):\n",
    "    \"\"\"Find the appropriate checkpoint file to load based on configuration settings\"\"\"\n",
    "    if START_FROM_EPOCH_CKPT is not None:\n",
    "        # Look for checkpoint from specific epoch\n",
    "        specific_ckpt = glob.glob(os.path.join(original_ckpt_dir, f\"checkpoint_epoch_{START_FROM_EPOCH_CKPT:04d}*.pth.tar\"))\n",
    "        if specific_ckpt:\n",
    "            logger.info(f\"Found checkpoint for specified epoch {START_FROM_EPOCH_CKPT}: {os.path.basename(specific_ckpt[0])}\")\n",
    "            return specific_ckpt[0]\n",
    "        else:\n",
    "            logger.warning(f\"No checkpoint found for epoch {START_FROM_EPOCH_CKPT}. Will try best FID/latest checkpoint.\")\n",
    "    \n",
    "    if USE_BEST_FID_CKPT:\n",
    "        # Try to find best FID checkpoint\n",
    "        best_fid_path = os.path.join(original_ckpt_dir, BEST_FID_CKPT_FILENAME)\n",
    "        if os.path.exists(best_fid_path):\n",
    "            logger.info(f\"Using best FID checkpoint: {BEST_FID_CKPT_FILENAME}\")\n",
    "            return best_fid_path\n",
    "            \n",
    "        # If specific best_fid file not found, try to find any best_fid checkpoint\n",
    "        best_fid_ckpts = glob.glob(os.path.join(original_ckpt_dir, \"best_fid_checkpoint*.pth.tar\"))\n",
    "        if best_fid_ckpts:\n",
    "            # Sort by FID score if possible\n",
    "            try:\n",
    "                # Extract FID score from filename using regex (e.g. best_fid_checkpoint_e0074_fid68.32.pth.tar)\n",
    "                scores = []\n",
    "                for ckpt in best_fid_ckpts:\n",
    "                    match = re.search(r'fid(\\d+\\.\\d+)', os.path.basename(ckpt))\n",
    "                    if match:\n",
    "                        scores.append((float(match.group(1)), ckpt))\n",
    "                if scores:\n",
    "                    best_score, best_ckpt = min(scores, key=lambda x: x[0])\n",
    "                    logger.info(f\"Using best FID checkpoint with score {best_score:.4f}: {os.path.basename(best_ckpt)}\")\n",
    "                    return best_ckpt\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            # If regex fails, just use the first one\n",
    "            logger.info(f\"Using best FID checkpoint: {os.path.basename(best_fid_ckpts[0])}\")\n",
    "            return best_fid_ckpts[0]\n",
    "    \n",
    "    # Fall back to latest checkpoint\n",
    "    latest_ckpt = os.path.join(original_ckpt_dir, LATEST_CKPT_FILENAME)\n",
    "    if os.path.exists(latest_ckpt):\n",
    "        logger.info(f\"Using latest checkpoint: {LATEST_CKPT_FILENAME}\")\n",
    "        return latest_ckpt\n",
    "        \n",
    "    # If all else fails, look for any checkpoint\n",
    "    all_ckpts = glob.glob(os.path.join(original_ckpt_dir, \"*.pth.tar\"))\n",
    "    if all_ckpts:\n",
    "        logger.warning(f\"Specified checkpoints not found. Using available checkpoint: {os.path.basename(all_ckpts[0])}\")\n",
    "        return all_ckpts[0]\n",
    "        \n",
    "    logger.error(f\"No checkpoints found in {original_ckpt_dir}. Cannot continue.\")\n",
    "    return None\n",
    "\n",
    "# --- Checkpoint Loading/Saving ---\n",
    "def load_checkpoint(checkpoint_path):\n",
    "    \"\"\"Load a checkpoint file and extract configuration and history data\"\"\"\n",
    "    logger.info(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "    try:\n",
    "        print(\"!!! maintain the 'weights_only' value as 'false' to avoid issues even if a warning appears in jupyter console !!!\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "        logger.info(\"Checkpoint loaded successfully!\")\n",
    "        \n",
    "        # Extract training history\n",
    "        g_losses_hist = checkpoint.get('g_losses_history', [])\n",
    "        c_losses_hist = checkpoint.get('c_losses_history', [])\n",
    "        fid_scores_hist = checkpoint.get('fid_scores_history', [])\n",
    "        fid_epochs_hist = checkpoint.get('fid_epochs_history', [])\n",
    "        kid_scores_hist = checkpoint.get('kid_scores_history', [])\n",
    "        kid_std_hist = checkpoint.get('kid_std_history', [])\n",
    "        kid_epochs_hist = checkpoint.get('kid_epochs_history', [])\n",
    "        best_fid = checkpoint.get('best_fid', float('inf'))\n",
    "        best_kid = checkpoint.get('best_kid', float('inf'))\n",
    "        epochs_no_improve = checkpoint.get('epochs_no_improve', 0)\n",
    "        start_epoch = checkpoint.get('epoch', 0)\n",
    "        global_step = checkpoint.get('step', 0)\n",
    "        \n",
    "        logger.info(f\"Loaded checkpoint from Epoch {start_epoch}, Step {global_step}\")\n",
    "        logger.info(f\"Training history: {len(g_losses_hist)} loss points, {len(fid_scores_hist)} FID scores, {len(kid_scores_hist)} KID scores\")\n",
    "        logger.info(f\"Best scores: FID: {best_fid:.4f}, KID: {best_kid:.6f}\")\n",
    "        logger.info(f\"Original early stopping status: {epochs_no_improve}/{checkpoint.get('early_stopping_patience', 10)}\")\n",
    "        \n",
    "        history_data = {\n",
    "            'g_losses_hist': g_losses_hist,\n",
    "            'c_losses_hist': c_losses_hist,\n",
    "            'fid_scores_hist': fid_scores_hist,\n",
    "            'fid_epochs_hist': fid_epochs_hist,\n",
    "            'kid_scores_hist': kid_scores_hist,\n",
    "            'kid_std_hist': kid_std_hist,\n",
    "            'kid_epochs_hist': kid_epochs_hist,\n",
    "            'best_fid': best_fid,\n",
    "            'best_kid': best_kid,\n",
    "            'start_epoch': start_epoch,\n",
    "            'global_step': global_step\n",
    "        }\n",
    "        \n",
    "        return checkpoint, history_data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading checkpoint: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    \"\"\"Save a checkpoint file to the continuation directory\"\"\"\n",
    "    save_path = os.path.join(CONT_CHKPT_DIR, filename)\n",
    "    logger.info(f\"Saving checkpoint to {save_path}\")\n",
    "    try:\n",
    "        torch.save(state, save_path)\n",
    "        logger.info(\"Checkpoint saved successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save checkpoint: {e}\", exc_info=True)\n",
    "\n",
    "def save_best_model_inference(generator, model_config, filename=f\"{CONTINUATION_PREFIX}best_model.pt\"):\n",
    "    \"\"\"Save the best generator model in a format suitable for inference\"\"\"\n",
    "    save_path = os.path.join(CONTINUATION_DIR, filename)\n",
    "    logger.info(f\"Saving best model for inference to {save_path}\")\n",
    "    try:\n",
    "        torch.save({\n",
    "            'model_state_dict': generator.state_dict(),\n",
    "            'model_config': model_config\n",
    "        }, save_path)\n",
    "        logger.info(\"Best model saved successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save best model: {e}\", exc_info=True)\n",
    "\n",
    "def save_best_fake_features(fake_features, filename=f\"{CONTINUATION_PREFIX}best_fake_features.npy\"):\n",
    "    \"\"\"Save the best fake features for later analysis\"\"\"\n",
    "    if fake_features is None:\n",
    "        logger.warning(\"No fake features to save.\")\n",
    "        return False\n",
    "        \n",
    "    save_path = os.path.join(CONT_ANALYSIS_DIR, filename)\n",
    "    logger.info(f\"Saving best fake features to {save_path}\")\n",
    "    try:\n",
    "        np.save(save_path, fake_features)\n",
    "        logger.info(\"Best fake features saved successfully.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save fake features: {e}\", exc_info=True)\n",
    "        return False\n",
    "\n",
    "def save_best_samples(generator, fixed_noise, epoch, filename=None):\n",
    "    \"\"\"Generate and save samples using the generator with fixed noise\"\"\"\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"{CONTINUATION_PREFIX}best_samples_e{epoch:04d}_{timestamp}.png\"\n",
    "        \n",
    "    save_path = os.path.join(CONT_SAMPLE_DIR, filename)\n",
    "    logger.info(f\"Saving best samples to {save_path}\")\n",
    "    \n",
    "    try:\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            fake_samples = generator(fixed_noise)\n",
    "            img_grid = vutils.make_grid(fake_samples * 0.5 + 0.5, normalize=False)\n",
    "            vutils.save_image(img_grid, save_path)\n",
    "        generator.train()\n",
    "        logger.info(\"Best samples saved successfully.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save best samples: {e}\", exc_info=True)\n",
    "        generator.train()\n",
    "        return False\n",
    "\n",
    "# --- Configuration Loading ---\n",
    "def extract_original_config(original_dir):\n",
    "    \"\"\"Try to load original configuration from JSON file or use defaults\"\"\"\n",
    "    config_path = os.path.join(original_dir, \"training_config_v2151.json\")\n",
    "    if os.path.exists(config_path):\n",
    "        try:\n",
    "            with open(config_path, 'r') as f:\n",
    "                config = json.load(f)\n",
    "            logger.info(f\"Loaded original configuration from {config_path}\")\n",
    "            return config\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading configuration: {e}\")\n",
    "    \n",
    "    logger.warning(\"Original configuration file not found. Using default values.\")\n",
    "    return {\n",
    "        \"LEARNING_RATE\": 0.00005,\n",
    "        \"BATCH_SIZE\": 64,\n",
    "        \"CRITIC_ITERATIONS\": 5,\n",
    "        \"NUM_EPOCHS\": 250,\n",
    "        \"NOISE_DIM\": 100,\n",
    "        \"CHANNELS_IMG\": 1,\n",
    "        \"G_FEATURES\": 64,\n",
    "        \"C_FEATURES\": 64,\n",
    "        \"FID_FREQ_EPOCHS\": 1,\n",
    "        \"FID_NUM_IMAGES\": 10000,\n",
    "        \"FID_BATCH_SIZE\": 64,\n",
    "        \"SAMPLE_FREQ_STEPS\": 500,\n",
    "        \"EARLY_STOPPING_PATIENCE\": 10,\n",
    "        \"CHECKPOINT_FREQ_EPOCHS\": 5,\n",
    "        \"IMAGE_SIZE\": 128\n",
    "    }\n",
    "\n",
    "# --- Plotting Utilities ---\n",
    "def _annotate_plot(fig, ax, final_epoch, stop_reason=None, status_text=None):\n",
    "    \"\"\"Add annotations to a plot regarding training status\"\"\"\n",
    "    if status_text is None:\n",
    "        status_text = f\"Training status: Finished during Epoch {final_epoch}\"\n",
    "    if stop_reason is not None:\n",
    "        status_text += f\"\\nStop reason: {stop_reason}\"\n",
    "        \n",
    "    # Add text below the x-axis, aligned to the left instead of center\n",
    "    fig.text(0.1, 0.01, status_text, ha='left', fontsize=9)  # Changed from 0.5 to 0.1 and ha='center' to ha='left'\n",
    "    \n",
    "    # Mark the last epoch with a distinctive marker\n",
    "    # The following lines are removed to stop marking the last epoch with a star\n",
    "    # last_x = ax.get_lines()[0].get_xdata()[-1]\n",
    "    # last_y = ax.get_lines()[0].get_ydata()[-1]\n",
    "    # ax.plot(last_x, last_y, 'r*', markersize=10, label='Last Epoch')\n",
    "\n",
    "def plot_losses(g_losses, c_losses, save_dir, filename_base, final_epoch, timestamp, is_final=False, stop_reason=None):\n",
    "    \"\"\"Plot generator and critic losses with current epoch in title\"\"\"\n",
    "    try:\n",
    "        if not g_losses or not c_losses:\n",
    "            logger.warning(\"No loss data to plot\")\n",
    "            return False\n",
    "            \n",
    "        fig, ax = plt.figure(figsize=(10, 6)), plt.gca()\n",
    "        epochs = range(1, len(g_losses) + 1)\n",
    "        \n",
    "        # Plot losses\n",
    "        ax.plot(epochs, g_losses, 'r-', label=\"Generator Loss\", alpha=0.8)\n",
    "        ax.plot(epochs, c_losses, 'b-', label=\"Critic Loss\", alpha=0.8)\n",
    "        \n",
    "        # Fix: Include current epoch number in title\n",
    "        ax.set_title(f\"Generator and Critic Loss vs. Epoch (Most recent: {final_epoch})\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        \n",
    "        # Mark the last epoch and annotate with status\n",
    "        if is_final:\n",
    "            _annotate_plot(fig, ax, final_epoch, stop_reason)\n",
    "            filename = f\"{filename_base}_final_{timestamp}.png\"\n",
    "        else:\n",
    "            filename = f\"{filename_base}_current.png\"\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(save_dir, filename)\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        logger.info(f\"Saved loss plot to {save_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate or save loss plot: {e}\", exc_info=True)\n",
    "        return False\n",
    "\n",
    "def plot_metric(scores, epochs_hist, best_score, metric_name, save_dir, filename_base, final_epoch, timestamp, \n",
    "               is_final=False, stop_reason=None, std_devs=None):\n",
    "    \"\"\"Plot metric (FID or KID) scores with current epoch in title\"\"\"\n",
    "    try:\n",
    "        if not scores or not epochs_hist:\n",
    "            logger.warning(f\"No {metric_name} data to plot\")\n",
    "            return False\n",
    "            \n",
    "        fig, ax = plt.figure(figsize=(10, 6)), plt.gca()\n",
    "        \n",
    "        # Plot with error bars if std_devs provided\n",
    "        if std_devs and len(std_devs) == len(scores):\n",
    "            # Change the color parameter here from blue to green\n",
    "            ax.errorbar(epochs_hist, scores, yerr=std_devs, fmt='g-o',  # Changed 'o-' or similar to 'g-o'\n",
    "                      label=f\"{metric_name} Score\", capsize=4)\n",
    "        else:\n",
    "            # Change the color parameter here from blue to green\n",
    "            ax.plot(epochs_hist, scores, marker='o', linestyle='-', color='green', label=f\"{metric_name} Score\")\n",
    "        \n",
    "        # Find and annotate best score\n",
    "        best_score_val = min(scores)\n",
    "        best_epoch_idx = scores.index(best_score_val)\n",
    "        best_epoch = epochs_hist[best_epoch_idx]\n",
    "        ax.scatter([best_epoch], [best_score_val], color='purple', s=100, zorder=5, marker='o')\n",
    "        ax.annotate(f'Best: {best_score_val:.4f}\\nEpoch: {best_epoch}', \n",
    "                    xy=(best_epoch, best_score_val), xytext=(10, -30),\n",
    "                    textcoords='offset points', arrowprops=dict(arrowstyle=\"->\", color='purple'),\n",
    "                    color='purple')\n",
    "        \n",
    "        # Fix: Include current epoch number in title\n",
    "        ax.set_title(f\"{metric_name} Score vs. Epoch (Most recent: {final_epoch})\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(f\"{metric_name} Score (Lower is Better)\")\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        \n",
    "        # Mark the last epoch and annotate with status\n",
    "        if is_final:\n",
    "            _annotate_plot(fig, ax, final_epoch, stop_reason)\n",
    "            filename = f\"{filename_base}_final_{timestamp}.png\"\n",
    "        else:\n",
    "            filename = f\"{filename_base}_current.png\"\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(save_dir, filename)\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        logger.info(f\"Saved {metric_name} plot to {save_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate or save {metric_name} plot: {e}\", exc_info=True)\n",
    "        return False\n",
    "\n",
    "def plot_combined_metrics(fid_scores, kid_scores, epochs_hist, save_dir, filename_base, final_epoch, timestamp, \n",
    "                         is_final=False, stop_reason=None):\n",
    "    \"\"\"Plot FID and KID scores on the same graph with dual axes and proper handling of different lengths\"\"\"\n",
    "    try:\n",
    "        if not fid_scores or not kid_scores:\n",
    "            logger.warning(\"Missing data for combined metrics plot\")\n",
    "            return False\n",
    "            \n",
    "        fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        # Fix: Make sure we have matching x and y arrays for both metrics\n",
    "        # For FID (primary y-axis)\n",
    "        fid_epochs = epochs_hist[:len(fid_scores)]  # Just in case lengths don't match\n",
    "        line1, = ax1.plot(fid_epochs, fid_scores, 'b-o', label=\"FID Score\")\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('FID Score', color='b')\n",
    "        ax1.tick_params(axis='y', labelcolor='b')\n",
    "        \n",
    "        # Create right y-axis for KID, ensuring we use matching x and y lengths\n",
    "        ax2 = ax1.twinx()\n",
    "        kid_epochs = epochs_hist[:len(kid_scores)]  # Just in case lengths don't match\n",
    "        line2, = ax2.plot(kid_epochs, kid_scores, 'r-o', label=\"KID Score\")\n",
    "        ax2.set_ylabel('KID Score', color='r')\n",
    "        ax2.tick_params(axis='y', labelcolor='r')\n",
    "        \n",
    "        # Add grid to the plot\n",
    "        ax1.grid(True, linestyle='--', alpha=0.3)\n",
    "        \n",
    "        # Add legend\n",
    "        lines = [line1, line2]\n",
    "        labels = [line.get_label() for line in lines]\n",
    "        ax1.legend(lines, labels, loc=\"upper right\")\n",
    "        \n",
    "        # Fix: Include current epoch number in title\n",
    "        plt.title(f'FID and KID Scores vs. Epoch (Most recent: {final_epoch})')\n",
    "        \n",
    "        # Mark the last epoch and annotate with status\n",
    "        if is_final:\n",
    "            _annotate_plot(fig, ax1, final_epoch, stop_reason)\n",
    "            filename = f\"{filename_base}_final_{timestamp}.png\"\n",
    "        else:\n",
    "            filename = f\"{filename_base}_current.png\"\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(save_dir, filename)\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        logger.info(f\"Saved combined metrics plot to {save_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate or save combined metrics plot: {e}\", exc_info=True)\n",
    "        return False\n",
    "\n",
    "def plot_feature_space(real_features, fake_features, method, save_dir, filename_base, final_epoch, timestamp, stop_reason=None):\n",
    "    \"\"\"Create t-SNE or UMAP visualization of real vs fake feature distributions\"\"\"\n",
    "    try:\n",
    "        if real_features is None or fake_features is None:\n",
    "            logger.warning(\"Missing features for visualization\")\n",
    "            return False\n",
    "            \n",
    "        # Sample if too many points\n",
    "        max_samples = TSNE_UMAP_SAMPLE_SIZE // 2  # Half for real, half for fake\n",
    "        \n",
    "        if len(real_features) > max_samples:\n",
    "            indices = np.random.choice(len(real_features), max_samples, replace=False)\n",
    "            real_sample = real_features[indices]\n",
    "        else:\n",
    "            real_sample = real_features\n",
    "            \n",
    "        if len(fake_features) > max_samples:\n",
    "            indices = np.random.choice(len(fake_features), max_samples, replace=False)\n",
    "            fake_sample = fake_features[indices]\n",
    "        else:\n",
    "            fake_sample = fake_features\n",
    "        \n",
    "        # Combine features\n",
    "        combined_features = np.vstack([real_sample, fake_sample])\n",
    "        \n",
    "        # Create labels (0 for real, 1 for fake)\n",
    "        labels = np.zeros(len(combined_features))\n",
    "        labels[len(real_sample):] = 1\n",
    "        \n",
    "        # Perform dimensionality reduction\n",
    "        if method.lower() == 'umap' and UMAP_AVAILABLE:\n",
    "            logger.info(\"Computing UMAP embedding...\")\n",
    "            reducer = umap.UMAP(random_state=TSNE_UMAP_RANDOM_STATE)\n",
    "            embedding = reducer.fit_transform(combined_features)\n",
    "            title = f'UMAP Visualization of Real vs Generated Feature Distributions (Epoch {final_epoch})'\n",
    "        else:\n",
    "            logger.info(\"Computing t-SNE embedding...\")\n",
    "            tsne = manifold.TSNE(n_components=2, perplexity=TSNE_PERPLEXITY, \n",
    "                                random_state=TSNE_UMAP_RANDOM_STATE, n_iter=1000)\n",
    "            embedding = tsne.fit_transform(combined_features)\n",
    "            title = f't-SNE Visualization of Real vs Generated Feature Distributions (Epoch {final_epoch})'\n",
    "        \n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        real_points = embedding[:len(real_sample)]\n",
    "        fake_points = embedding[len(real_sample):]\n",
    "        \n",
    "        ax.scatter(real_points[:, 0], real_points[:, 1], c='blue', alpha=0.6, label='Real', s=20)\n",
    "        ax.scatter(fake_points[:, 0], fake_points[:, 1], c='red', alpha=0.6, label='Generated', s=20)\n",
    "        \n",
    "        # Fix: Include current epoch number in title\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "        \n",
    "        # Add a description of what plot shows\n",
    "        ax.annotate(\"Note: Points closer together have similar feature representations\\n\"\n",
    "                    \"Good generation = red points distributed similarly to blue points\", \n",
    "                    xy=(0.5, -0.01), xycoords='axes fraction', \n",
    "                    ha='center', va='top', fontsize=9)\n",
    "        \n",
    "        # Add status information\n",
    "        status_text = f\"Feature space visualization after Epoch {final_epoch}\"\n",
    "        if stop_reason:\n",
    "            status_text += f\"\\nStop reason: {stop_reason}\"\n",
    "        fig.text(0.5, 0.01, status_text, ha='center', fontsize=9)\n",
    "        \n",
    "        filename = f\"{filename_base}_{method.lower()}_{timestamp}.png\"\n",
    "        save_path = os.path.join(save_dir, filename)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        logger.info(f\"Saved {method} visualization to {save_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate or save feature space visualization: {e}\", exc_info=True)\n",
    "        return False\n",
    "\n",
    "def generate_final_sample_grid(samples_dir, grid_size=(4, 8), max_samples=32, epoch=None, timestamp=None):\n",
    "    \"\"\"Create a grid of sample images, preferring the best epoch samples if available\"\"\"\n",
    "    try:\n",
    "        # Look for best samples first\n",
    "        best_samples = sorted(glob.glob(os.path.join(samples_dir, f\"{CONTINUATION_PREFIX}best_samples*.png\")))\n",
    "        \n",
    "        # If no best samples, use regular samples\n",
    "        if not best_samples:\n",
    "            sample_files = sorted(glob.glob(os.path.join(samples_dir, f\"{CONTINUATION_PREFIX}sample_*.png\")))\n",
    "            if not sample_files:\n",
    "                logger.warning(f\"No sample images found in {samples_dir}\")\n",
    "                return False\n",
    "        else:\n",
    "            # Use the most recent best sample file\n",
    "            best_sample = best_samples[-1]\n",
    "            \n",
    "            # Extract epoch from filename if possible\n",
    "            epoch_match = re.search(r'e(\\d+)', os.path.basename(best_sample))\n",
    "            best_epoch = int(epoch_match.group(1)) if epoch_match else \"best\"\n",
    "            \n",
    "            # Load this single file as the best image\n",
    "            best_img = Image.open(best_sample)\n",
    "            \n",
    "            # Create a filename for the output\n",
    "            if timestamp is None:\n",
    "                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            \n",
    "            filename = f\"{CONTINUATION_PREFIX}best_epoch_{best_epoch}_sample_grid_{timestamp}.png\"\n",
    "            save_path = os.path.join(CONT_ANALYSIS_DIR, filename)\n",
    "            \n",
    "            # Save directly (no need for grid since it's already a grid)\n",
    "            best_img.save(save_path)\n",
    "            logger.info(f\"Saved best epoch sample grid to {save_path}\")\n",
    "            return True\n",
    "            \n",
    "        # If we're here, we're using regular samples\n",
    "        selected_samples = sample_files[-max_samples:] if len(sample_files) > max_samples else sample_files\n",
    "        \n",
    "        # Create figure for grid\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.suptitle(f\"Generated Samples (Current Epoch: {epoch})\", fontsize=16)\n",
    "        \n",
    "        for i, sample_path in enumerate(selected_samples):\n",
    "            if i >= grid_size[0] * grid_size[1]:\n",
    "                break\n",
    "                \n",
    "            # Load and display the image\n",
    "            img = Image.open(sample_path)\n",
    "            plt.subplot(grid_size[0], grid_size[1], i+1)\n",
    "            plt.imshow(np.array(img), cmap='gray')\n",
    "            \n",
    "            # Extract epoch and step from filename\n",
    "            filename = os.path.basename(sample_path)\n",
    "            match = re.search(r'sample_(\\d+)_(\\d+)', filename)\n",
    "            if match:\n",
    "                epoch, step = match.groups()\n",
    "                plt.title(f\"Epoch {int(epoch)}, Step {int(step)}\")\n",
    "            else:\n",
    "                plt.title(filename)\n",
    "                \n",
    "            plt.axis('off')\n",
    "        \n",
    "        # Save the grid\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            \n",
    "        if epoch is None:\n",
    "            epoch_str = \"final\"\n",
    "        else:\n",
    "            epoch_str = f\"{epoch:04d}\"\n",
    "            \n",
    "        filename = f\"{CONTINUATION_PREFIX}sample_grid_e{epoch_str}_{timestamp}.png\"\n",
    "        save_path = os.path.join(CONT_ANALYSIS_DIR, filename)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        logger.info(f\"Saved sample grid to {save_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate or save sample grid: {e}\", exc_info=True)\n",
    "        return False\n",
    "\n",
    "# --- FID/KID Calculation ---\n",
    "def get_inception_model(device):\n",
    "    \"\"\"Load the InceptionV3 model for feature extraction\"\"\"\n",
    "    if not FID_AVAILABLE:\n",
    "        raise RuntimeError(\"pytorch-fid library not available.\")\n",
    "    block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
    "    model = InceptionV3([block_idx]).to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def get_activations(dataloader_or_generator, model, device, num_images, batch_size, desc=\"\", noise_dim=None):\n",
    "    \"\"\"Extract features using the Inception model from real or generated images\"\"\"\n",
    "    if not FID_AVAILABLE:\n",
    "        logger.warning(\"pytorch-fid not available.\")\n",
    "        return None\n",
    "        \n",
    "    n_batches = ceil(num_images / batch_size)\n",
    "    n_used_imgs = 0\n",
    "    pred_list = []\n",
    "    \n",
    "    # Determine if we're processing a dataloader or generating from a generator\n",
    "    is_dataloader = noise_dim is None\n",
    "    \n",
    "    if is_dataloader:\n",
    "        logger.info(f\"Getting activations from {num_images} real images ({n_batches} batches)...\")\n",
    "        iterator = iter(dataloader_or_generator)\n",
    "    else:\n",
    "        logger.info(f\"Generating {num_images} fake images & activations ({n_batches} batches)...\")\n",
    "        generator = dataloader_or_generator\n",
    "        generator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm.tqdm(range(n_batches), desc=f\"Activations {desc}\", leave=False):\n",
    "            try:\n",
    "                if is_dataloader:\n",
    "                    # Process real images from dataloader\n",
    "                    try:\n",
    "                        batch = next(iterator).to(device)\n",
    "                    except StopIteration:\n",
    "                        logger.warning(f\"Dataloader exhausted early @ batch {i}. Using {n_used_imgs} images.\")\n",
    "                        break\n",
    "                        \n",
    "                    if isinstance(batch, (list, tuple)):\n",
    "                        batch = batch[0]\n",
    "                    if batch.shape[0] == 0:\n",
    "                        continue\n",
    "                else:\n",
    "                    # Generate fake images\n",
    "                    current_batch_size = min(batch_size, num_images - n_used_imgs)\n",
    "                    if current_batch_size <= 0:\n",
    "                        break\n",
    "                        \n",
    "                    noise = torch.randn(current_batch_size, noise_dim, 1, 1, device=device)\n",
    "                    batch = generator(noise)\n",
    "                \n",
    "                current_batch_size = batch.shape[0]\n",
    "                \n",
    "                # Preprocess batch for Inception\n",
    "                if batch.dtype != torch.float32:\n",
    "                    batch = batch.float()\n",
    "                if batch.shape[1] == 1:\n",
    "                    batch = batch.repeat(1, 3, 1, 1)  # Expand grayscale to RGB\n",
    "                if batch.shape[1] != 3:\n",
    "                    raise ValueError(f\"Batch needs 3 channels, got {batch.shape[1]}\")\n",
    "                \n",
    "                # Rescale from [-1,1] to [0,1]\n",
    "                batch = (batch * 0.5) + 0.5  \n",
    "                batch = torch.clamp(batch, 0.0, 1.0)\n",
    "                \n",
    "                # Get activations and process them\n",
    "                pred = model(batch)[0]\n",
    "                if pred.size(2) != 1 or pred.size(3) != 1:\n",
    "                    pred = F.adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "                \n",
    "                pred_list.append(pred.squeeze(3).squeeze(2).cpu().numpy())\n",
    "                n_used_imgs += current_batch_size\n",
    "                \n",
    "                if n_used_imgs >= num_images:\n",
    "                    break\n",
    "                    \n",
    "                # Clean up\n",
    "                del batch, pred\n",
    "                if not is_dataloader:\n",
    "                    del noise\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error during activation batch {i}: {e}\", exc_info=True)\n",
    "                if not is_dataloader:\n",
    "                    generator.train()\n",
    "                return None\n",
    "    \n",
    "    # Restore generator state if needed\n",
    "    if not is_dataloader:\n",
    "        generator.train()\n",
    "    \n",
    "    # Process results\n",
    "    if not pred_list:\n",
    "        return None\n",
    "    \n",
    "    pred_arr = np.concatenate(pred_list, axis=0)\n",
    "    pred_arr = pred_arr[:num_images]\n",
    "    \n",
    "    # Clean up\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return pred_arr\n",
    "\n",
    "def get_real_stats_and_features(real_dataloader, paths, inception_model, device, num_images, batch_size, force_recalculate=False):\n",
    "    \"\"\"Get real image statistics and features for FID/KID calculation\"\"\"\n",
    "    real_stats_path = paths.get('real_stats_path')\n",
    "    real_features_path = paths.get('real_features_path')\n",
    "    original_real_stats_path = paths.get('original_real_stats_path')\n",
    "    original_real_features_path = paths.get('original_real_features_path')\n",
    "    \n",
    "    # Check if we can use existing stats/features\n",
    "    if not force_recalculate and real_stats_path and real_features_path:\n",
    "        if os.path.exists(real_stats_path) and os.path.exists(real_features_path):\n",
    "            logger.info(f\"Loading pre-calculated real stats and features\")\n",
    "            try:\n",
    "                stats = np.load(real_stats_path)\n",
    "                mu_real, sigma_real = stats['mu'], stats['sigma']\n",
    "                \n",
    "                real_features = np.load(real_features_path)\n",
    "                \n",
    "                if (mu_real is not None and sigma_real is not None and \n",
    "                    mu_real.shape == (2048,) and sigma_real.shape == (2048, 2048) and\n",
    "                    real_features.shape[1] == 2048):\n",
    "                    logger.info(\"Loaded real stats and features successfully.\")\n",
    "                    return mu_real, sigma_real, real_features\n",
    "                else:\n",
    "                    logger.warning(\"Loaded real stats or features invalid.\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not load real stats or features file: {e}\")\n",
    "    \n",
    "    # Try to copy from original run\n",
    "    if original_real_stats_path and original_real_features_path:\n",
    "        if os.path.exists(original_real_stats_path) and os.path.exists(original_real_features_path):\n",
    "            logger.info(\"Copying real stats and features from original run\")\n",
    "            try:\n",
    "                # Ensure destination directories exist\n",
    "                os.makedirs(os.path.dirname(real_stats_path), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(real_features_path), exist_ok=True)\n",
    "                \n",
    "                # Copy files\n",
    "                shutil.copy2(original_real_stats_path, real_stats_path)\n",
    "                shutil.copy2(original_real_features_path, real_features_path)\n",
    "                \n",
    "                # Load copied files\n",
    "                stats = np.load(real_stats_path)\n",
    "                mu_real, sigma_real = stats['mu'], stats['sigma']\n",
    "                \n",
    "                real_features = np.load(real_features_path)\n",
    "                \n",
    "                if (mu_real is not None and sigma_real is not None and \n",
    "                    mu_real.shape == (2048,) and sigma_real.shape == (2048, 2048) and\n",
    "                    real_features.shape[1] == 2048):\n",
    "                    logger.info(\"Copied and loaded real stats and features successfully.\")\n",
    "                    return mu_real, sigma_real, real_features\n",
    "                else:\n",
    "                    logger.warning(\"Copied real stats or features invalid.\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to copy/load real stats or features: {e}\")\n",
    "    \n",
    "    # If we get here, we need to calculate from scratch\n",
    "    logger.info(f\"Calculating FID stats and features for {num_images} real images...\")\n",
    "    real_activations = get_activations(real_dataloader, inception_model, device, num_images, batch_size, desc=\"Real\")\n",
    "    \n",
    "    if real_activations is None or len(real_activations) < num_images // 2:  # Allow some tolerance\n",
    "        logger.error(f\"Failed to get enough real activations. Got {len(real_activations) if real_activations is not None else 0}.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mu_real = np.mean(real_activations, axis=0)\n",
    "    sigma_real = np.cov(real_activations, rowvar=False)\n",
    "    \n",
    "    logger.info(f\"Calculated real stats (mu: {mu_real.shape}, sigma: {sigma_real.shape}).\")\n",
    "    \n",
    "    # Save results\n",
    "    try:\n",
    "        # Save stats for FID\n",
    "        os.makedirs(os.path.dirname(real_stats_path), exist_ok=True)\n",
    "        np.savez(real_stats_path, mu=mu_real, sigma=sigma_real)\n",
    "        logger.info(f\"Saved real FID stats to: {real_stats_path}\")\n",
    "        \n",
    "        # Save raw features for KID and visualization\n",
    "        np.save(real_features_path, real_activations)\n",
    "        logger.info(f\"Saved real features to: {real_features_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save real stats or features: {e}\", exc_info=True)\n",
    "    \n",
    "    return mu_real, sigma_real, real_activations\n",
    "\n",
    "def calculate_metrics(generator, inception_model, real_mu, real_sigma, real_features, device, noise_dim, num_images, batch_size):\n",
    "    \"\"\"Calculate FID and KID metrics using the same generated features\"\"\"\n",
    "    if not FID_AVAILABLE:\n",
    "        logger.warning(\"pytorch-fid not available.\")\n",
    "        return float('inf'), (float('inf'), float('inf')), None\n",
    "    \n",
    "    if real_mu is None or real_sigma is None or real_features is None:\n",
    "        logger.error(\"Real stats or features not available.\")\n",
    "        return float('inf'), (float('inf'), float('inf')), None\n",
    "    \n",
    "    logger.info(f\"Calculating FID and KID using {num_images} generated images...\")\n",
    "    fake_features = get_activations(generator, inception_model, device, num_images, batch_size, desc=\"Fake (FID/KID)\", noise_dim=noise_dim)\n",
    "    \n",
    "    if fake_features is None or len(fake_features) < num_images // 2:  # Allow some tolerance\n",
    "        logger.error(f\"Failed to get enough fake activations. Got {len(fake_features) if fake_features is not None else 0}.\")\n",
    "        return float('inf'), (float('inf'), float('inf')), None\n",
    "    \n",
    "    # Calculate FID\n",
    "    mu_fake = np.mean(fake_features, axis=0)\n",
    "    sigma_fake = np.cov(fake_features, rowvar=False)\n",
    "    \n",
    "    logger.info(\"Calculating Frechet distance...\")\n",
    "    \n",
    "    try:\n",
    "        fid_value = calculate_frechet_distance(mu_fake, sigma_fake, real_mu, real_sigma)\n",
    "        logger.info(f\"Calculated FID: {fid_value:.4f}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating Frechet distance: {e}\", exc_info=True)\n",
    "        fid_value = float('inf')\n",
    "    \n",
    "    # Calculate KID\n",
    "    if CALCULATE_KID:\n",
    "        logger.info(f\"Calculating KID score...\")\n",
    "        try:\n",
    "            # Fixed: Always use custom KID implementation with pre-computed features\n",
    "            logger.info(\"Using custom KID implementation with pre-computed features\")\n",
    "            kid_mean, kid_std = calculate_kid_from_features_custom(\n",
    "                real_features, fake_features, \n",
    "                subset_size=KID_SUBSET_SIZE,\n",
    "                num_subsets=KID_SUBSETS\n",
    "            )\n",
    "            logger.info(f\"Calculated KID (custom): {kid_mean:.6f} ± {kid_std:.6f}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calculating KID: {e}\", exc_info=True)\n",
    "            kid_mean, kid_std = float('inf'), float('inf')\n",
    "    else:\n",
    "        kid_mean, kid_std = float('inf'), float('inf')\n",
    "    \n",
    "    # Clean up\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return fid_value, (kid_mean, kid_std), fake_features\n",
    "\n",
    "# --- Markdown Report ---\n",
    "def generate_markdown_report(history_data, training_info, output_path):\n",
    "    \"\"\"Generate a markdown report of training results\"\"\"\n",
    "    g_losses_hist = history_data.get('g_losses_hist', [])\n",
    "    c_losses_hist = history_data.get('c_losses_hist', [])\n",
    "    fid_scores_hist = history_data.get('fid_scores_hist', [])\n",
    "    fid_epochs_hist = history_data.get('fid_epochs_hist', [])\n",
    "    kid_scores_hist = history_data.get('kid_scores_hist', [])\n",
    "    kid_epochs_hist = history_data.get('kid_epochs_hist', [])\n",
    "    best_fid = history_data.get('best_fid', float('inf'))\n",
    "    best_kid = history_data.get('best_kid', float('inf'))\n",
    "    \n",
    "    try:\n",
    "        with open(output_path, \"w\") as f:\n",
    "            f.write(f\"# WGAN-SN Training Continuation Report (Enhanced)\\n\\n\")\n",
    "            f.write(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "            \n",
    "            # Continuation settings\n",
    "            f.write(\"## Continuation Settings\\n\\n\")\n",
    "            f.write(f\"- Continued from: {'Best FID model' if USE_BEST_FID_CKPT else 'Latest checkpoint'}\\n\")\n",
    "            f.write(f\"- Original epochs: {training_info.get('original_epochs', 'N/A')}\\n\")\n",
    "            f.write(f\"- Additional epochs: {ADDITIONAL_EPOCHS}\\n\")\n",
    "            f.write(f\"- Total epochs completed: {training_info.get('current_epoch', 'N/A')}\\n\")\n",
    "            f.write(f\"- Used original settings: {USE_ORIGINAL_SETTINGS}\\n\")\n",
    "            \n",
    "            if not USE_ORIGINAL_SETTINGS:\n",
    "                f.write(f\"- Learning rate: {NEW_LEARNING_RATE}\\n\")\n",
    "                f.write(f\"- Batch size: {NEW_BATCH_SIZE}\\n\")\n",
    "                f.write(f\"- Critic iterations: {NEW_CRITIC_ITERATIONS}\\n\")\n",
    "                f.write(f\"- Gradient clipping: {USE_GRADIENT_CLIPPING}\\n\")\n",
    "            \n",
    "            f.write(f\"- Early stopping patience: {NEW_EARLY_STOPPING_PATIENCE}\\n\")\n",
    "            \n",
    "            # Training summary\n",
    "            f.write(\"\\n## Training Summary\\n\\n\")\n",
    "            f.write(f\"- Final status: {training_info.get('stop_reason', 'Completed')}\\n\")\n",
    "            f.write(f\"- Training time: {training_info.get('training_time', 0):.2f} seconds\\n\")\n",
    "            f.write(f\"- Final generator loss: {g_losses_hist[-1] if g_losses_hist else 'N/A'}\\n\")\n",
    "            f.write(f\"- Final critic loss: {c_losses_hist[-1] if c_losses_hist else 'N/A'}\\n\")\n",
    "            \n",
    "            # FID information\n",
    "            if fid_scores_hist:\n",
    "                f.write(\"\\n## FID Analysis\\n\\n\")\n",
    "                \n",
    "                # Original best FID\n",
    "                original_fid_scores = [fid for i, fid in enumerate(fid_scores_hist) \n",
    "                                      if fid_epochs_hist[i] <= training_info.get('original_epochs', 0)]\n",
    "                original_best_fid = min(original_fid_scores) if original_fid_scores else float('inf')\n",
    "                \n",
    "                # Continuation best FID\n",
    "                cont_fid_scores = [fid for i, fid in enumerate(fid_scores_hist) \n",
    "                                   if fid_epochs_hist[i] > training_info.get('original_epochs', 0)]\n",
    "                cont_best_fid = min(cont_fid_scores) if cont_fid_scores else float('inf')\n",
    "                \n",
    "                f.write(f\"- Original best FID score: {original_best_fid:.4f}\\n\")\n",
    "                f.write(f\"- Continuation best FID score: {cont_best_fid:.4f}\\n\")\n",
    "                f.write(f\"- FID improvement: {original_best_fid - cont_best_fid:.4f}\\n\")\n",
    "                f.write(f\"- Final FID score: {fid_scores_hist[-1] if fid_scores_hist else 'N/A'}\\n\")\n",
    "                \n",
    "                # FID trends\n",
    "                if len(fid_scores_hist) >= 3:\n",
    "                    last_fids = fid_scores_hist[-3:]\n",
    "                    \n",
    "                    if last_fids[0] > last_fids[-1] and last_fids[1] > last_fids[-1]:\n",
    "                        f.write(\"\\n- FID scores were continuing to improve at the end.\\n\")\n",
    "                    elif all(abs(last_fids[0] - fid) < 1.0 for fid in last_fids[1:]):\n",
    "                        f.write(\"\\n- FID scores had stabilized at the end.\\n\")\n",
    "                    elif last_fids[0] < last_fids[-1] and last_fids[1] < last_fids[-1]:\n",
    "                        f.write(\"\\n- FID scores were worsening at the end.\\n\")\n",
    "            \n",
    "            # KID information\n",
    "            if kid_scores_hist:\n",
    "                f.write(\"\\n## KID Analysis\\n\\n\")\n",
    "                \n",
    "                # Original best KID\n",
    "                original_kid_scores = [kid for i, kid in enumerate(kid_scores_hist) \n",
    "                                      if kid_epochs_hist[i] <= training_info.get('original_epochs', 0)]\n",
    "                original_best_kid = min(original_kid_scores) if original_kid_scores else float('inf')\n",
    "                \n",
    "                # Continuation best KID\n",
    "                cont_kid_scores = [kid for i, kid in enumerate(kid_scores_hist) \n",
    "                                   if kid_epochs_hist[i] > training_info.get('original_epochs', 0)]\n",
    "                cont_best_kid = min(cont_kid_scores) if cont_kid_scores else float('inf')\n",
    "                \n",
    "                f.write(f\"- Original best KID score: {original_best_kid:.6f}\\n\")\n",
    "                f.write(f\"- Continuation best KID score: {cont_best_kid:.6f}\\n\")\n",
    "                f.write(f\"- KID improvement: {original_best_kid - cont_best_kid:.6f}\\n\")\n",
    "                f.write(f\"- Final KID score: {kid_scores_hist[-1] if kid_scores_hist else 'N/A'}\\n\")\n",
    "                \n",
    "                # KID trends\n",
    "                if len(kid_scores_hist) >= 3:\n",
    "                    last_kids = kid_scores_hist[-3:]\n",
    "                    \n",
    "                    if last_kids[0] > last_kids[-1] and last_kids[1] > last_kids[-1]:\n",
    "                        f.write(\"\\n- KID scores were continuing to improve at the end.\\n\")\n",
    "                    elif all(abs(last_kids[0] - kid) < 0.0005 for kid in last_kids[1:]):\n",
    "                        f.write(\"\\n- KID scores had stabilized at the end.\\n\")\n",
    "                    elif last_kids[0] < last_kids[-1] and last_kids[1] < last_kids[-1]:\n",
    "                        f.write(\"\\n- KID scores were worsening at the end.\\n\")\n",
    "            \n",
    "            # Overall improvement analysis\n",
    "            if fid_scores_hist and kid_scores_hist:\n",
    "                f.write(\"\\n## Overall Improvement Analysis\\n\\n\")\n",
    "                fid_improved = cont_best_fid < original_best_fid if cont_fid_scores else False\n",
    "                kid_improved = cont_best_kid < original_best_kid if cont_kid_scores else False\n",
    "                \n",
    "                if fid_improved and kid_improved:\n",
    "                    f.write(\"- **Both FID and KID scores improved** during continuation training.\\n\")\n",
    "                    f.write(\"- The model is generating more realistic images with better feature distributions.\\n\")\n",
    "                elif fid_improved:\n",
    "                    f.write(\"- **FID improved but KID did not** during continuation training.\\n\")\n",
    "                    f.write(\"- The model is generating more realistic images, but the feature distribution may not have improved.\\n\")\n",
    "                elif kid_improved:\n",
    "                    f.write(\"- **KID improved but FID did not** during continuation training.\\n\")\n",
    "                    f.write(\"- The model's feature distribution improved, but overall image realism may not have increased.\\n\")\n",
    "                else:\n",
    "                    f.write(\"- **Neither FID nor KID scores improved** during continuation training.\\n\")\n",
    "                    f.write(\"- The continuation training did not yield better results than the original training.\\n\")\n",
    "            \n",
    "            # Recommendations\n",
    "            f.write(\"\\n## Recommendations\\n\\n\")\n",
    "            \n",
    "            if training_info.get('stop_reason', '') == \"Early stopping\":\n",
    "                f.write(\"- Training stopped early due to metric plateau. Consider:\\n\")\n",
    "                f.write(\"  - Using an even lower learning rate (e.g., 0.00001)\\n\")\n",
    "                f.write(\"  - Experimenting with different data augmentations\\n\")\n",
    "                f.write(\"  - Trying a different architecture or hyperparameter configuration\\n\")\n",
    "            \n",
    "            if fid_scores_hist and kid_scores_hist and (fid_improved or kid_improved):\n",
    "                f.write(\"- The continuation strategy was successful. For further improvement:\\n\")\n",
    "                f.write(\"  - Try additional training with current parameters\\n\")\n",
    "                f.write(\"  - Consider minor learning rate adjustments\\n\")\n",
    "                f.write(\"  - Experiment with different critic iteration counts\\n\")\n",
    "            elif fid_scores_hist and kid_scores_hist:\n",
    "                f.write(\"- The continuation strategy did not yield improvements. Consider:\\n\")\n",
    "                f.write(\"  - More significant learning rate adjustments\\n\")\n",
    "                f.write(\"  - Different batch size or critic iterations\\n\")\n",
    "                f.write(\"  - Alternative GAN architecture or training methodology\\n\")\n",
    "            \n",
    "            # Sample Images\n",
    "            f.write(\"\\n## Generated Images\\n\\n\")\n",
    "            f.write(\"Sample images are saved in the `samples` directory.\\n\")\n",
    "            f.write(\"Best samples grid is available in the `analysis_results` directory.\\n\")\n",
    "            \n",
    "            # Plots\n",
    "            f.write(\"\\n## Analysis Plots\\n\\n\")\n",
    "            f.write(\"- Loss plot: `plots/cont_losses_*.png`\\n\")\n",
    "            f.write(\"- FID plot: `plots/cont_fid_*.png`\\n\")\n",
    "            f.write(\"- KID plot: `plots/cont_kid_*.png`\\n\")\n",
    "            f.write(\"- Combined metrics plot: `plots/cont_combined_metrics_*.png`\\n\")\n",
    "            if PLOT_FEATURE_SPACE:\n",
    "                if USE_UMAP and UMAP_AVAILABLE:\n",
    "                    f.write(\"- UMAP feature space visualization: `plots/cont_feature_space_umap_*.png`\\n\")\n",
    "                else:\n",
    "                    f.write(\"- t-SNE feature space visualization: `plots/cont_feature_space_tsne_*.png`\\n\")\n",
    "        \n",
    "        logger.info(f\"Generated markdown report at {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate markdown report: {e}\", exc_info=True)\n",
    "        return False\n",
    "\n",
    "# ==============================================\n",
    "# Initialization Phase\n",
    "# ==============================================\n",
    "logger.info(\"--- Initialization Phase ---\")\n",
    "timestamp_start = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# --- Determine & Load Checkpoint ---\n",
    "original_ckpt_dir = os.path.join(ORIGINAL_OUTPUT_DIR, \"checkpoints\")\n",
    "checkpoint_to_load_path = find_checkpoint_file(original_ckpt_dir)\n",
    "\n",
    "if checkpoint_to_load_path is None:\n",
    "    logger.error(\"No checkpoint found to continue from. Exiting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "checkpoint, history_data = load_checkpoint(checkpoint_to_load_path)\n",
    "if checkpoint is None or history_data is None:\n",
    "    logger.error(\"Failed to load checkpoint data. Exiting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- Load Original Configuration ---\n",
    "original_config = extract_original_config(ORIGINAL_OUTPUT_DIR)\n",
    "\n",
    "# --- Set Effective Configuration ---\n",
    "if USE_ORIGINAL_SETTINGS:\n",
    "    logger.info(\"Using original hyperparameters from checkpoint/config\")\n",
    "    LEARNING_RATE = original_config.get(\"LEARNING_RATE\", 0.00005)\n",
    "    BATCH_SIZE = original_config.get(\"BATCH_SIZE\", 64)\n",
    "    CRITIC_ITERATIONS = original_config.get(\"CRITIC_ITERATIONS\", 5)\n",
    "else:\n",
    "    logger.info(\"Using new hyperparameters for continuation\")\n",
    "    LEARNING_RATE = NEW_LEARNING_RATE\n",
    "    BATCH_SIZE = NEW_BATCH_SIZE\n",
    "    CRITIC_ITERATIONS = NEW_CRITIC_ITERATIONS\n",
    "\n",
    "# Load other necessary parameters from original config\n",
    "NOISE_DIM = original_config.get(\"NOISE_DIM\", 100)\n",
    "CHANNELS_IMG = original_config.get(\"CHANNELS_IMG\", 1)\n",
    "G_FEATURES = original_config.get(\"G_FEATURES\", 64)\n",
    "C_FEATURES = original_config.get(\"C_FEATURES\", 64)\n",
    "IMAGE_SIZE = original_config.get(\"IMAGE_SIZE\", 128)\n",
    "CHECKPOINT_FREQ_EPOCHS = original_config.get(\"CHECKPOINT_FREQ_EPOCHS\", 5)\n",
    "\n",
    "# Override early stopping patience\n",
    "EARLY_STOPPING_PATIENCE = NEW_EARLY_STOPPING_PATIENCE\n",
    "logger.info(f\"Early stopping patience set to {EARLY_STOPPING_PATIENCE}\")\n",
    "\n",
    "# Log effective configuration\n",
    "logger.info(\"\\n=== Continuation Configuration ===\")\n",
    "logger.info(f\"Starting from epoch: {history_data['start_epoch']}\")\n",
    "logger.info(f\"Additional epochs: {ADDITIONAL_EPOCHS}\")\n",
    "logger.info(f\"Learning rate: {LEARNING_RATE}\")\n",
    "logger.info(f\"Batch size: {BATCH_SIZE}\")\n",
    "logger.info(f\"Critic iterations: {CRITIC_ITERATIONS}\")\n",
    "logger.info(f\"Gradient clipping: {USE_GRADIENT_CLIPPING}\")\n",
    "logger.info(f\"Primary evaluation metric: {PRIMARY_EVAL_METRIC}\")\n",
    "logger.info(f\"Early stopping patience: {EARLY_STOPPING_PATIENCE}\")\n",
    "logger.info(f\"Using {'best FID' if USE_BEST_FID_CKPT else 'latest'} checkpoint\")\n",
    "logger.info(\"================================\\n\")\n",
    "\n",
    "# Save continuation configuration\n",
    "cont_config = {\n",
    "    \"ORIGINAL_OUTPUT_DIR\": ORIGINAL_OUTPUT_DIR,\n",
    "    \"CONTINUATION_DIR\": CONTINUATION_DIR,\n",
    "    \"USE_BEST_FID_CKPT\": USE_BEST_FID_CKPT,\n",
    "    \"USE_ORIGINAL_SETTINGS\": USE_ORIGINAL_SETTINGS,\n",
    "    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"CRITIC_ITERATIONS\": CRITIC_ITERATIONS,\n",
    "    \"USE_GRADIENT_CLIPPING\": USE_GRADIENT_CLIPPING,\n",
    "    \"ADDITIONAL_EPOCHS\": ADDITIONAL_EPOCHS,\n",
    "    \"EARLY_STOPPING_PATIENCE\": EARLY_STOPPING_PATIENCE,\n",
    "    \"ORIGINAL_EPOCHS\": history_data['start_epoch'],\n",
    "    \"ORIGINAL_BEST_FID\": float(history_data['best_fid']),\n",
    "    \"ORIGINAL_BEST_KID\": float(history_data['best_kid']) if 'best_kid' in history_data else float('inf'),\n",
    "    \"NOISE_DIM\": NOISE_DIM,\n",
    "    \"CHANNELS_IMG\": CHANNELS_IMG,\n",
    "    \"G_FEATURES\": G_FEATURES,\n",
    "    \"C_FEATURES\": C_FEATURES\n",
    "}\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(CONTINUATION_DIR, f\"{CONTINUATION_PREFIX}config.json\"), 'w') as f:\n",
    "        json.dump(cont_config, f, indent=4, default=str)\n",
    "    logger.info(f\"Saved continuation configuration\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Failed to save continuation configuration: {e}\")\n",
    "\n",
    "# --- Initialize Models ---\n",
    "logger.info(\"Initializing models...\")\n",
    "generator = Generator(NOISE_DIM, CHANNELS_IMG, G_FEATURES).to(device)\n",
    "critic = CriticSN(CHANNELS_IMG, C_FEATURES).to(device)\n",
    "\n",
    "# Load model weights from checkpoint\n",
    "logger.info(\"Loading model weights from checkpoint...\")\n",
    "generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "\n",
    "# Initialize optimizers\n",
    "opt_gen = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "\n",
    "# Load optimizer states from checkpoint\n",
    "opt_gen.load_state_dict(checkpoint['optimizer_gen_state_dict'])\n",
    "opt_critic.load_state_dict(checkpoint['optimizer_critic_state_dict'])\n",
    "\n",
    "# Update learning rates if using new settings\n",
    "if not USE_ORIGINAL_SETTINGS:\n",
    "    for param_group in opt_gen.param_groups:\n",
    "        param_group['lr'] = LEARNING_RATE\n",
    "    for param_group in opt_critic.param_groups:\n",
    "        param_group['lr'] = LEARNING_RATE\n",
    "    logger.info(f\"Updated optimizer learning rates to {LEARNING_RATE}\")\n",
    "\n",
    "# Initialize GradScalers\n",
    "scaler_critic = GradScaler(enabled=AMP_ENABLED)\n",
    "scaler_gen = GradScaler(enabled=AMP_ENABLED)\n",
    "\n",
    "# Load scaler states if they exist in the checkpoint\n",
    "if 'scaler_gen_state_dict' in checkpoint and scaler_gen is not None:\n",
    "    scaler_gen.load_state_dict(checkpoint['scaler_gen_state_dict'])\n",
    "    logger.info(\"Loaded GradScaler state for Generator.\")\n",
    "else:\n",
    "    logger.warning(\"Generator GradScaler state not found in checkpoint.\")\n",
    "\n",
    "if 'scaler_critic_state_dict' in checkpoint and scaler_critic is not None:\n",
    "    scaler_critic.load_state_dict(checkpoint['scaler_critic_state_dict'])\n",
    "    logger.info(\"Loaded GradScaler state for Critic.\")\n",
    "else:\n",
    "    logger.warning(\"Critic GradScaler state not found in checkpoint.\")\n",
    "\n",
    "# --- Setup Dataset and DataLoader ---\n",
    "logger.info(\"Setting up Dataset and DataLoader...\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "try:\n",
    "    dataset = PollenDataset(\n",
    "        root_dir=PREPROCESSED_DATA_DIR, \n",
    "        transform=transform,\n",
    "        image_size=IMAGE_SIZE,      \n",
    "        channels_img=CHANNELS_IMG \n",
    "    )\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        raise ValueError(\"Dataset is empty.\")\n",
    "    \n",
    "    # Optimize worker count based on CPU cores\n",
    "    dataloader_num_workers = min(max(os.cpu_count() // 2, 1), 4)  # Cap at 4\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True, \n",
    "        num_workers=dataloader_num_workers, \n",
    "        pin_memory=(device.type == 'cuda'), \n",
    "        persistent_workers=False,\n",
    "        drop_last=True\n",
    "    ) \n",
    "    \n",
    "    logger.info(f\"DataLoader created with {len(dataloader)} batches per epoch.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create Dataset/DataLoader: {e}\", exc_info=True)\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- Prepare for Metric Calculations ---\n",
    "logger.info(\"Preparing for FID/KID calculation...\")\n",
    "inception_model = None\n",
    "real_mu, real_sigma, real_features = None, None, None\n",
    "\n",
    "if FID_AVAILABLE:\n",
    "    try:\n",
    "        inception_model = get_inception_model(device)\n",
    "        logger.info(\"InceptionV3 model loaded for metrics.\")\n",
    "        \n",
    "        # Setup dataset for metric calculations\n",
    "        fid_transform = transforms.Compose([\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5] * CHANNELS_IMG, [0.5] * CHANNELS_IMG)\n",
    "        ])\n",
    "        \n",
    "        fid_dataset = PollenDataset(\n",
    "            PREPROCESSED_DATA_DIR, \n",
    "            transform=fid_transform, \n",
    "            image_size=IMAGE_SIZE, \n",
    "            channels_img=CHANNELS_IMG\n",
    "        )\n",
    "        \n",
    "        actual_fid_num_images = min(FID_NUM_IMAGES, len(fid_dataset))\n",
    "        if actual_fid_num_images < FID_NUM_IMAGES:\n",
    "            logger.warning(f\"Using {actual_fid_num_images} images for metrics calculation (limited by dataset size).\")\n",
    "        \n",
    "        fid_dataloader = DataLoader(\n",
    "            fid_dataset, \n",
    "            batch_size=FID_BATCH_SIZE, \n",
    "            shuffle=False, \n",
    "            num_workers=dataloader_num_workers, \n",
    "            pin_memory=(device.type == 'cuda')\n",
    "        )\n",
    "        \n",
    "        # Define paths for stats and features\n",
    "        original_real_stats_path = os.path.join(ORIGINAL_OUTPUT_DIR, \"real_fid_stats_10k.npz\")\n",
    "        original_real_features_path = os.path.join(ORIGINAL_OUTPUT_DIR, \"real_inception_features_10k.npy\")\n",
    "        cont_real_stats_path = os.path.join(CONTINUATION_DIR, f\"{CONTINUATION_PREFIX}real_stats.npz\")\n",
    "        cont_real_features_path = os.path.join(CONTINUATION_DIR, f\"{CONTINUATION_PREFIX}real_features.npy\")\n",
    "        \n",
    "        paths = {\n",
    "            'original_real_stats_path': original_real_stats_path,\n",
    "            'original_real_features_path': original_real_features_path,\n",
    "            'real_stats_path': cont_real_stats_path,\n",
    "            'real_features_path': cont_real_features_path\n",
    "        }\n",
    "        \n",
    "        # Get real stats and features\n",
    "        real_mu, real_sigma, real_features = get_real_stats_and_features(\n",
    "            fid_dataloader,\n",
    "            paths,\n",
    "            inception_model,\n",
    "            device,\n",
    "            actual_fid_num_images,\n",
    "            FID_BATCH_SIZE,\n",
    "            FORCE_RECALCULATE_REAL_STATS\n",
    "        )\n",
    "        \n",
    "        if real_mu is None or real_sigma is None or real_features is None:\n",
    "            logger.error(\"Failed to obtain real statistics or features. Metrics will be disabled.\")\n",
    "            FID_AVAILABLE = False\n",
    "            CALCULATE_KID = False\n",
    "        else:\n",
    "            logger.info(\"Successfully loaded/calculated real image statistics and features.\")\n",
    "        \n",
    "        # Clean up dataloader/dataset to free memory\n",
    "        del fid_dataloader, fid_dataset, fid_transform\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during metrics setup: {e}\", exc_info=True)\n",
    "        logger.error(\"Metrics calculation will be disabled.\")\n",
    "        FID_AVAILABLE = False\n",
    "        CALCULATE_KID = False\n",
    "        inception_model = None\n",
    "\n",
    "# --- Initialize Training State Variables ---\n",
    "global_step = history_data.get('global_step', 0)\n",
    "start_epoch = history_data.get('start_epoch', 0)\n",
    "g_losses_hist = history_data.get('g_losses_hist', [])\n",
    "c_losses_hist = history_data.get('c_losses_hist', [])\n",
    "fid_scores_hist = history_data.get('fid_scores_hist', [])\n",
    "fid_epochs_hist = history_data.get('fid_epochs_hist', [])\n",
    "kid_scores_hist = history_data.get('kid_scores_hist', [])\n",
    "kid_std_hist = history_data.get('kid_std_hist', [])\n",
    "kid_epochs_hist = history_data.get('kid_epochs_hist', [])\n",
    "best_fid = history_data.get('best_fid', float('inf'))\n",
    "best_kid = history_data.get('best_kid', float('inf'))\n",
    "\n",
    "# Reset early stopping patience counter for continuation\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# For loss stability monitoring\n",
    "critic_loss_window = deque(maxlen=LOSS_STABILITY_WINDOW)\n",
    "gen_loss_window = deque(maxlen=LOSS_STABILITY_WINDOW)\n",
    "\n",
    "# Fixed noise for sample generation\n",
    "fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(device)\n",
    "\n",
    "# Holds the current best fake features from this continuation run\n",
    "current_best_fake_features = None\n",
    "current_best_epoch = None\n",
    "\n",
    "# ==============================================\n",
    "# Training Loop\n",
    "# ==============================================\n",
    "logger.info(f\"\\n--- Starting Continuation Training from Epoch {start_epoch + 1} ---\")\n",
    "log_gpu_memory_usage(\"Before Training Loop\")\n",
    "\n",
    "# Set models to training mode\n",
    "generator.train()\n",
    "critic.train()\n",
    "\n",
    "# Main training parameters and tracking variables\n",
    "training_start_time = time.time()\n",
    "early_stop_triggered = False\n",
    "stop_reason = \"Completed all epochs\"\n",
    "total_epochs = start_epoch + ADDITIONAL_EPOCHS\n",
    "\n",
    "try:  # Wrap main loop in try/except to handle interruptions\n",
    "    for epoch in range(start_epoch, total_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # Setup progress bar for this epoch\n",
    "        loop_pbar = tqdm.tqdm(enumerate(dataloader), total=len(dataloader), leave=True, \n",
    "                        desc=f\"Epoch [{epoch+1}/{total_epochs}]\")\n",
    "        \n",
    "        # Track average losses for the epoch\n",
    "        avg_loss_c_epoch = 0.0\n",
    "        avg_loss_g_epoch = 0.0\n",
    "        batches_in_epoch = 0\n",
    "\n",
    "        for batch_idx, real_images in loop_pbar:\n",
    "            # --- Heartbeat Log ---\n",
    "            if HEARTBEAT_LOG_FREQ > 0 and global_step % HEARTBEAT_LOG_FREQ == 0:\n",
    "                logger.debug(f\"Heartbeat: Still running Step {global_step} in Epoch {epoch+1}\")\n",
    "\n",
    "            # --- Main Training Step ---\n",
    "            try:\n",
    "                if real_images is None:\n",
    "                    logger.warning(f\"Skipping batch {batch_idx} due to None data.\")\n",
    "                    continue\n",
    "                    \n",
    "                real_images = real_images.to(device)\n",
    "                cur_batch_size = real_images.shape[0]\n",
    "                if cur_batch_size == 0:\n",
    "                    continue\n",
    "\n",
    "                # --- Train Critic ---\n",
    "                critic_loss_accum_iter = 0.0\n",
    "                opt_critic.zero_grad(set_to_none=True)\n",
    "                \n",
    "                for _ in range(CRITIC_ITERATIONS):\n",
    "                    noise = torch.randn(cur_batch_size, NOISE_DIM, 1, 1).to(device)\n",
    "                    \n",
    "                    with autocast(device_type='cuda', enabled=AMP_ENABLED):\n",
    "                        with torch.no_grad():\n",
    "                            fake_images = generator(noise)\n",
    "                        critic_real = critic(real_images).reshape(-1)\n",
    "                        critic_fake = critic(fake_images).reshape(-1)\n",
    "                        loss_critic = torch.mean(critic_fake) - torch.mean(critic_real)\n",
    "                    \n",
    "                    # Check for NaN/Inf in critic loss (MANDATORY)\n",
    "                    if not torch.isfinite(loss_critic):\n",
    "                        logger.critical(f\"Non-finite critic loss detected at Step {global_step}: {loss_critic.item()}. Stopping training.\")\n",
    "                        early_stop_triggered = True\n",
    "                        stop_reason = \"Non-finite loss detected\"\n",
    "                        break\n",
    "                    \n",
    "                    critic_loss_accum_iter += loss_critic.item()\n",
    "                    \n",
    "                    # Backprop critic\n",
    "                    scaler_critic.scale(loss_critic).backward()\n",
    "                \n",
    "                # Skip optimizer step if early stop triggered\n",
    "                if early_stop_triggered:\n",
    "                    break\n",
    "                    \n",
    "                # Unscale for gradient clipping if enabled\n",
    "                if USE_GRADIENT_CLIPPING:\n",
    "                    scaler_critic.unscale_(opt_critic)\n",
    "                    torch.nn.utils.clip_grad_norm_(critic.parameters(), max_norm=1.0)\n",
    "                \n",
    "                # Optimizer step and scaler update\n",
    "                scaler_critic.step(opt_critic)\n",
    "                scaler_critic.update()\n",
    "                \n",
    "                avg_loss_c_iter = critic_loss_accum_iter / CRITIC_ITERATIONS\n",
    "\n",
    "                # --- Train Generator ---\n",
    "                opt_gen.zero_grad(set_to_none=True)\n",
    "                \n",
    "                with autocast(device_type='cuda', enabled=AMP_ENABLED):\n",
    "                    noise_for_g = torch.randn(cur_batch_size, NOISE_DIM, 1, 1).to(device)\n",
    "                    fake_images_for_g = generator(noise_for_g)\n",
    "                    critic_fake_for_gen = critic(fake_images_for_g).reshape(-1)\n",
    "                    loss_gen = -torch.mean(critic_fake_for_gen)\n",
    "                \n",
    "                # Check for NaN/Inf in generator loss (MANDATORY)\n",
    "                if not torch.isfinite(loss_gen):\n",
    "                    logger.critical(f\"Non-finite generator loss detected at Step {global_step}: {loss_gen.item()}. Stopping training.\")\n",
    "                    early_stop_triggered = True\n",
    "                    stop_reason = \"Non-finite loss detected\"\n",
    "                    break\n",
    "                \n",
    "                # Backprop generator\n",
    "                scaler_gen.scale(loss_gen).backward()\n",
    "                \n",
    "                # Unscale for gradient clipping if enabled\n",
    "                if USE_GRADIENT_CLIPPING:\n",
    "                    scaler_gen.unscale_(opt_gen)\n",
    "                    torch.nn.utils.clip_grad_norm_(generator.parameters(), max_norm=1.0)\n",
    "                \n",
    "                # Optimizer step and scaler update\n",
    "                scaler_gen.step(opt_gen)\n",
    "                scaler_gen.update()\n",
    "\n",
    "                # --- Tracking and Logging ---\n",
    "                loss_g_item = loss_gen.item()\n",
    "                avg_loss_c_epoch += avg_loss_c_iter\n",
    "                avg_loss_g_epoch += loss_g_item\n",
    "                batches_in_epoch += 1\n",
    "                \n",
    "                # Update loss stability tracking\n",
    "                critic_loss_window.append(avg_loss_c_iter)\n",
    "                gen_loss_window.append(loss_g_item)\n",
    "                \n",
    "                # Check for loss stability issues\n",
    "                if MONITOR_LOSS_STABILITY and len(critic_loss_window) == LOSS_STABILITY_WINDOW:\n",
    "                    # Calculate mean and std for critic loss\n",
    "                    c_mean = np.mean(list(critic_loss_window)[:-1])  # All but the last\n",
    "                    c_std = np.std(list(critic_loss_window)[:-1])\n",
    "                    c_current = critic_loss_window[-1]\n",
    "                    \n",
    "                    # Check if current loss is an outlier\n",
    "                    if abs(c_current - c_mean) > LOSS_STABILITY_THRESHOLD * c_std:\n",
    "                        logger.warning(f\"Critic loss spike detected at Step {global_step}: {c_current:.4f} \"\n",
    "                                      f\"(mean: {c_mean:.4f}, std: {c_std:.4f})\")\n",
    "                    \n",
    "                    # Same for generator loss\n",
    "                    g_mean = np.mean(list(gen_loss_window)[:-1])\n",
    "                    g_std = np.std(list(gen_loss_window)[:-1])\n",
    "                    g_current = gen_loss_window[-1]\n",
    "                    \n",
    "                    if abs(g_current - g_mean) > LOSS_STABILITY_THRESHOLD * g_std:\n",
    "                        logger.warning(f\"Generator loss spike detected at Step {global_step}: {g_current:.4f} \"\n",
    "                                      f\"(mean: {g_mean:.4f}, std: {g_std:.4f})\")\n",
    "\n",
    "                # Periodic logging (every 100 steps)\n",
    "                if global_step % 100 == 0:\n",
    "                    logger.info(f\"Step {global_step} | Loss C: {avg_loss_c_iter:.4f}, Loss G: {loss_g_item:.4f}\")\n",
    "                    # Track memory usage\n",
    "                    log_gpu_memory_usage(f\"Step {global_step}\")\n",
    "\n",
    "                # Save periodic samples\n",
    "                if global_step % SAMPLE_FREQ_STEPS == 0:\n",
    "                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                    logger.info(f\"Saving samples at step {global_step}\")\n",
    "                    \n",
    "                    generator.eval()\n",
    "                    with torch.no_grad():\n",
    "                        fake_samples = generator(fixed_noise)\n",
    "                        img_grid = vutils.make_grid(fake_samples * 0.5 + 0.5, normalize=False)\n",
    "                        vutils.save_image(img_grid, os.path.join(CONT_SAMPLE_DIR, \n",
    "                                        f\"{CONTINUATION_PREFIX}sample_{epoch+1:04d}_{global_step:07d}_{timestamp}.png\"))\n",
    "                    generator.train()\n",
    "                    \n",
    "                    # Clean up sample generation tensors\n",
    "                    del fake_samples, img_grid\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "                # Update progress bar\n",
    "                loop_pbar.set_description(f\"Epoch [{epoch+1}/{total_epochs}]\")\n",
    "                loop_pbar.set_postfix(loss_C=avg_loss_c_iter, loss_G=loss_g_item, step=global_step)\n",
    "                \n",
    "                # Clean up batch tensors\n",
    "                del real_images, noise, fake_images, critic_real, critic_fake, loss_critic\n",
    "                del noise_for_g, fake_images_for_g, critic_fake_for_gen, loss_gen\n",
    "                \n",
    "                global_step += 1\n",
    "\n",
    "            except RuntimeError as e:  # Handle CUDA OOM and other runtime errors\n",
    "                if \"out of memory\" in str(e).lower():\n",
    "                    logger.error(f\"CUDA out of memory at Step {global_step}! Consider reducing batch size.\")\n",
    "                    logger.warning(\"Attempting to save checkpoint before stopping...\")\n",
    "                    try:\n",
    "                        # Create emergency checkpoint\n",
    "                        checkpoint_state = {\n",
    "                            'epoch': epoch,\n",
    "                            'step': global_step,\n",
    "                            'generator_state_dict': generator.state_dict(),\n",
    "                            'critic_state_dict': critic.state_dict(),\n",
    "                            'optimizer_gen_state_dict': opt_gen.state_dict(),\n",
    "                            'optimizer_critic_state_dict': opt_critic.state_dict(),\n",
    "                            'scaler_gen_state_dict': scaler_gen.state_dict(),\n",
    "                            'scaler_critic_state_dict': scaler_critic.state_dict(),\n",
    "                            'g_losses_history': g_losses_hist,\n",
    "                            'c_losses_history': c_losses_hist,\n",
    "                            'fid_scores_history': fid_scores_hist,\n",
    "                            'fid_epochs_history': fid_epochs_hist,\n",
    "                            'kid_scores_history': kid_scores_hist,\n",
    "                            'kid_std_history': kid_std_hist,\n",
    "                            'kid_epochs_history': kid_epochs_hist,\n",
    "                            'best_fid': best_fid,\n",
    "                            'best_kid': best_kid,\n",
    "                            'epochs_no_improve': epochs_no_improve\n",
    "                        }\n",
    "                        save_checkpoint(checkpoint_state, f\"{CONTINUATION_PREFIX}emergency_oom_{timestamp_start}.pth.tar\")\n",
    "                    except Exception as save_e:\n",
    "                        logger.error(f\"Failed to save emergency checkpoint: {save_e}\")\n",
    "                    \n",
    "                    early_stop_triggered = True\n",
    "                    stop_reason = \"CUDA Out of Memory\"\n",
    "                    break\n",
    "                else:\n",
    "                    logger.error(f\"Runtime error at Step {global_step}: {e}\", exc_info=True)\n",
    "                    early_stop_triggered = True\n",
    "                    stop_reason = f\"Runtime error: {str(e)[:100]}...\"\n",
    "                    break\n",
    "            except Exception as e:  # Handle general exceptions\n",
    "                logger.error(f\"Error at batch {batch_idx}, Step {global_step}: {e}\", exc_info=True)\n",
    "                early_stop_triggered = True\n",
    "                stop_reason = f\"Training error: {str(e)[:100]}...\"\n",
    "                break\n",
    "\n",
    "        # --- End of Batch Loop ---\n",
    "        if early_stop_triggered:\n",
    "            break\n",
    "\n",
    "        # --- End of Epoch ---\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        if batches_in_epoch > 0:\n",
    "            avg_loss_c_epoch /= batches_in_epoch\n",
    "            avg_loss_g_epoch /= batches_in_epoch\n",
    "             \n",
    "        # Append losses to history\n",
    "        g_losses_hist.append(avg_loss_g_epoch)\n",
    "        c_losses_hist.append(avg_loss_c_epoch)\n",
    "             \n",
    "        logger.info(f\"Epoch [{epoch+1}/{total_epochs}] Completed in {epoch_duration:.2f}s | \"\n",
    "                   f\"Avg Loss C: {avg_loss_c_epoch:.4f} | Avg Loss G: {avg_loss_g_epoch:.4f}\")\n",
    "\n",
    "        # --- Memory cleanup ---\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        log_gpu_memory_usage(f\"After Epoch {epoch+1}\")\n",
    "        \n",
    "        # --- Metric Calculation & Evaluation ---\n",
    "        primary_metric_improved_this_epoch = False\n",
    "        best_fid_updated = False\n",
    "        best_kid_updated = False\n",
    "        \n",
    "        if FID_AVAILABLE and inception_model is not None and (epoch + 1) % FID_FREQ_EPOCHS == 0:\n",
    "            current_fid, (current_kid, current_kid_std), fake_features_epoch = calculate_metrics(\n",
    "                generator, \n",
    "                inception_model, \n",
    "                real_mu, \n",
    "                real_sigma,\n",
    "                real_features,\n",
    "                device, \n",
    "                NOISE_DIM, \n",
    "                FID_NUM_IMAGES, \n",
    "                FID_BATCH_SIZE\n",
    "            )\n",
    "            \n",
    "            # Track FID if calculated and valid\n",
    "            if current_fid != float('inf'):\n",
    "                fid_scores_hist.append(current_fid)\n",
    "                fid_epochs_hist.append(epoch + 1)\n",
    "                logger.info(f\"--- FID Score @ Epoch {epoch+1}: {current_fid:.4f} ---\")\n",
    "            \n",
    "            # Track KID if calculated and valid\n",
    "            if CALCULATE_KID and current_kid != float('inf'):\n",
    "                kid_scores_hist.append(current_kid)\n",
    "                kid_std_hist.append(current_kid_std)\n",
    "                kid_epochs_hist.append(epoch + 1)\n",
    "                logger.info(f\"--- KID Score @ Epoch {epoch+1}: {current_kid:.6f} ± {current_kid_std:.6f} ---\")\n",
    "            \n",
    "            # Check if metrics improved\n",
    "            if PRIMARY_EVAL_METRIC == \"FID\" and current_fid != float('inf'):\n",
    "                if current_fid < best_fid:\n",
    "                    logger.info(f\"FID improved: {best_fid:.4f} -> {current_fid:.4f}. Saving best FID checkpoint.\")\n",
    "                    best_fid = current_fid\n",
    "                    best_fid_updated = True\n",
    "                    primary_metric_improved_this_epoch = True\n",
    "                    \n",
    "                    # Save the best fake features for visualization\n",
    "                    if fake_features_epoch is not None:\n",
    "                        current_best_fake_features = fake_features_epoch\n",
    "                        current_best_epoch = epoch + 1\n",
    "                        save_best_fake_features(fake_features_epoch)\n",
    "            \n",
    "            elif PRIMARY_EVAL_METRIC == \"KID\" and CALCULATE_KID and current_kid != float('inf'):\n",
    "                if current_kid < best_kid:\n",
    "                    logger.info(f\"KID improved: {best_kid:.6f} -> {current_kid:.6f}. Saving best KID checkpoint.\")\n",
    "                    best_kid = current_kid\n",
    "                    best_kid_updated = True\n",
    "                    primary_metric_improved_this_epoch = True\n",
    "                    \n",
    "                    # Save the best fake features for visualization\n",
    "                    if fake_features_epoch is not None:\n",
    "                        current_best_fake_features = fake_features_epoch\n",
    "                        current_best_epoch = epoch + 1\n",
    "                        save_best_fake_features(fake_features_epoch)\n",
    "            \n",
    "            # Track non-primary metric improvements too\n",
    "            if PRIMARY_EVAL_METRIC == \"KID\" and current_fid != float('inf'):\n",
    "                if current_fid < best_fid:\n",
    "                    logger.info(f\"FID improved: {best_fid:.4f} -> {current_fid:.4f}. (Not primary metric)\")\n",
    "                    best_fid = current_fid\n",
    "                    best_fid_updated = True\n",
    "            \n",
    "            elif PRIMARY_EVAL_METRIC == \"FID\" and CALCULATE_KID and current_kid != float('inf'):\n",
    "                if current_kid < best_kid:\n",
    "                    logger.info(f\"KID improved: {best_kid:.6f} -> {current_kid:.6f}. (Not primary metric)\")\n",
    "                    best_kid = current_kid\n",
    "                    best_kid_updated = True\n",
    "            \n",
    "            # Define checkpoint state for saving\n",
    "            checkpoint_state = {\n",
    "                'epoch': epoch + 1, \n",
    "                'step': global_step,\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'critic_state_dict': critic.state_dict(),\n",
    "                'optimizer_gen_state_dict': opt_gen.state_dict(),\n",
    "                'optimizer_critic_state_dict': opt_critic.state_dict(),\n",
    "                'scaler_gen_state_dict': scaler_gen.state_dict(),\n",
    "                'scaler_critic_state_dict': scaler_critic.state_dict(),\n",
    "                'g_losses_history': g_losses_hist,\n",
    "                'c_losses_history': c_losses_hist,\n",
    "                'fid_scores_history': fid_scores_hist,\n",
    "                'fid_epochs_history': fid_epochs_hist,\n",
    "                'kid_scores_history': kid_scores_hist,\n",
    "                'kid_std_history': kid_std_hist,\n",
    "                'kid_epochs_history': kid_epochs_hist,\n",
    "                'best_fid': best_fid,\n",
    "                'best_kid': best_kid,\n",
    "                'epochs_no_improve': epochs_no_improve\n",
    "            }\n",
    "            \n",
    "            # --- Save Best State ---\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            \n",
    "            if primary_metric_improved_this_epoch:\n",
    "                # Reset early stopping counter\n",
    "                epochs_no_improve = 0\n",
    "                \n",
    "                # Save best model for inference\n",
    "                model_config = {\n",
    "                    'noise_dim': NOISE_DIM,\n",
    "                    'channels_img': CHANNELS_IMG,\n",
    "                    'features_g': G_FEATURES\n",
    "                }\n",
    "                save_best_model_inference(generator, model_config)\n",
    "                \n",
    "                # Save best samples\n",
    "                save_best_samples(generator, fixed_noise, epoch + 1)\n",
    "            \n",
    "            if best_fid_updated:\n",
    "                # Save best FID checkpoint (overwrite previous best)\n",
    "                save_checkpoint(checkpoint_state, f\"{CONTINUATION_PREFIX}best_fid_checkpoint.pth.tar\")\n",
    "                \n",
    "                # Also save a timestamped version for archiving\n",
    "                if primary_metric_improved_this_epoch and PRIMARY_EVAL_METRIC == \"FID\":\n",
    "                    save_checkpoint(checkpoint_state, \n",
    "                                  f\"{CONTINUATION_PREFIX}best_fid_checkpoint_e{epoch+1:04d}_fid{current_fid:.2f}_{timestamp}.pth.tar\")\n",
    "            \n",
    "            if best_kid_updated:\n",
    "                # Save best KID checkpoint (overwrite previous best)\n",
    "                save_checkpoint(checkpoint_state, f\"{CONTINUATION_PREFIX}best_kid_checkpoint.pth.tar\")\n",
    "                \n",
    "                # Also save a timestamped version for archiving\n",
    "                if primary_metric_improved_this_epoch and PRIMARY_EVAL_METRIC == \"KID\":\n",
    "                    save_checkpoint(checkpoint_state, \n",
    "                                  f\"{CONTINUATION_PREFIX}best_kid_checkpoint_e{epoch+1:04d}_kid{current_kid:.6f}_{timestamp}.pth.tar\")\n",
    "            \n",
    "            # --- Early Stopping Check ---\n",
    "            if not primary_metric_improved_this_epoch:\n",
    "                epochs_no_improve += 1\n",
    "                logger.info(f\"{PRIMARY_EVAL_METRIC} did not improve. \"\n",
    "                          f\"Patience: {epochs_no_improve}/{EARLY_STOPPING_PATIENCE}.\")\n",
    "                \n",
    "                if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
    "                    logger.warning(f\"--- Early stopping triggered after {epochs_no_improve} epochs \"\n",
    "                                  f\"without {PRIMARY_EVAL_METRIC} improvement. ---\")\n",
    "                    stop_reason = f\"Early stopping ({PRIMARY_EVAL_METRIC})\"\n",
    "                    early_stop_triggered = True\n",
    "            \n",
    "            # --- Optional Per-Epoch Plotting ---\n",
    "            if PLOT_PER_EPOCH:\n",
    "                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                \n",
    "                # Generate plots consistently for all metrics regardless of calculation outcome\n",
    "                # This fixes issues with plots not being updated\n",
    "                \n",
    "                # Always plot losses\n",
    "                plot_losses(g_losses_hist, c_losses_hist, CONT_PLOT_DIR, \n",
    "                          f\"{CONTINUATION_PREFIX}losses\", epoch + 1, timestamp)\n",
    "                           \n",
    "                # Plot FID if we have any history\n",
    "                if fid_scores_hist and len(fid_scores_hist) > 0:\n",
    "                    plot_metric(fid_scores_hist, fid_epochs_hist, best_fid, \"FID\", CONT_PLOT_DIR,\n",
    "                              f\"{CONTINUATION_PREFIX}fid\", epoch + 1, timestamp)\n",
    "                          \n",
    "                # Plot KID if we have any history\n",
    "                if CALCULATE_KID and kid_scores_hist and len(kid_scores_hist) > 0:\n",
    "                    plot_metric(kid_scores_hist, kid_epochs_hist, best_kid, \"KID\", CONT_PLOT_DIR,\n",
    "                              f\"{CONTINUATION_PREFIX}kid\", epoch + 1, timestamp, std_devs=kid_std_hist)\n",
    "                \n",
    "                # Only attempt combined plot if both metrics have data and lengths match\n",
    "                if (fid_scores_hist and kid_scores_hist and \n",
    "                    len(fid_scores_hist) > 0 and len(kid_scores_hist) > 0):\n",
    "                    try:\n",
    "                        # Use the shortest history length to avoid mismatch errors\n",
    "                        common_length = min(len(fid_scores_hist), len(kid_scores_hist))\n",
    "                        if common_length > 0:\n",
    "                            fid_subset = fid_scores_hist[:common_length]\n",
    "                            kid_subset = kid_scores_hist[:common_length]\n",
    "                            epochs_subset = fid_epochs_hist[:common_length]  # Use FID epochs as common epochs\n",
    "                            \n",
    "                            plot_combined_metrics(fid_subset, kid_subset, epochs_subset, CONT_PLOT_DIR,\n",
    "                                               f\"{CONTINUATION_PREFIX}combined_metrics\", epoch + 1, timestamp)\n",
    "                    except Exception as plot_e:\n",
    "                        logger.error(f\"Error creating combined metrics plot: {plot_e}\")\n",
    "                        # Continue training even if plotting fails\n",
    "        \n",
    "        # --- Memory cleanup after metrics --- \n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # --- Checkpointing ---\n",
    "        checkpoint_state = {\n",
    "            'epoch': epoch + 1, \n",
    "            'step': global_step,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'critic_state_dict': critic.state_dict(),\n",
    "            'optimizer_gen_state_dict': opt_gen.state_dict(),\n",
    "            'optimizer_critic_state_dict': opt_critic.state_dict(),\n",
    "            'scaler_gen_state_dict': scaler_gen.state_dict(),\n",
    "            'scaler_critic_state_dict': scaler_critic.state_dict(),\n",
    "            'g_losses_history': g_losses_hist,\n",
    "            'c_losses_history': c_losses_hist,\n",
    "            'fid_scores_history': fid_scores_hist,\n",
    "            'fid_epochs_history': fid_epochs_hist,\n",
    "            'kid_scores_history': kid_scores_hist,\n",
    "            'kid_std_history': kid_std_hist,\n",
    "            'kid_epochs_history': kid_epochs_hist,\n",
    "            'best_fid': best_fid,\n",
    "            'best_kid': best_kid,\n",
    "            'epochs_no_improve': epochs_no_improve\n",
    "        }\n",
    "        \n",
    "        # Save checkpoint every N epochs or if it's the last epoch\n",
    "        if (epoch + 1) % CHECKPOINT_FREQ_EPOCHS == 0 or (epoch + 1) == total_epochs:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            save_checkpoint(checkpoint_state, f\"{CONTINUATION_PREFIX}checkpoint_epoch_{epoch+1:04d}_{timestamp}.pth.tar\")\n",
    "            \n",
    "        # Always save the latest checkpoint\n",
    "        save_checkpoint(checkpoint_state, f\"{CONTINUATION_PREFIX}latest_checkpoint.pth.tar\") \n",
    "        \n",
    "        # Check for early stopping\n",
    "        if early_stop_triggered:\n",
    "            break\n",
    "\n",
    "    # --- End of Epoch Loop ---\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logger.warning(\"--- Training Interrupted by User ---\")\n",
    "    stop_reason = \"Manual Interruption\"\n",
    "    \n",
    "    logger.warning(\"Attempting to save checkpoint and generate plots before exit...\")\n",
    "    \n",
    "    # Save emergency checkpoint\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    try:\n",
    "        checkpoint_state = {\n",
    "            'epoch': epoch if 'epoch' in locals() else start_epoch, \n",
    "            'step': global_step,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'critic_state_dict': critic.state_dict(),\n",
    "            'optimizer_gen_state_dict': opt_gen.state_dict(),\n",
    "            'optimizer_critic_state_dict': opt_critic.state_dict(),\n",
    "            'scaler_gen_state_dict': scaler_gen.state_dict(),\n",
    "            'scaler_critic_state_dict': scaler_critic.state_dict(),\n",
    "            'g_losses_history': g_losses_hist,\n",
    "            'c_losses_history': c_losses_hist,\n",
    "            'fid_scores_history': fid_scores_hist,\n",
    "            'fid_epochs_history': fid_epochs_hist,\n",
    "            'kid_scores_history': kid_scores_hist,\n",
    "            'kid_std_history': kid_std_hist,\n",
    "            'kid_epochs_history': kid_epochs_hist,\n",
    "            'best_fid': best_fid,\n",
    "            'best_kid': best_kid,\n",
    "            'epochs_no_improve': epochs_no_improve\n",
    "        }\n",
    "        save_checkpoint(checkpoint_state, f\"{CONTINUATION_PREFIX}interrupted_{timestamp}.pth.tar\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save checkpoint after interruption: {e}\", exc_info=True)\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.critical(f\"Critical error during training: {e}\", exc_info=True)\n",
    "    stop_reason = f\"Error: {str(e)[:100]}...\"\n",
    "    \n",
    "    # Try to save emergency checkpoint\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    try:\n",
    "        checkpoint_state = {\n",
    "            'epoch': epoch if 'epoch' in locals() else start_epoch, \n",
    "            'step': global_step,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'critic_state_dict': critic.state_dict(),\n",
    "            'optimizer_gen_state_dict': opt_gen.state_dict(),\n",
    "            'optimizer_critic_state_dict': opt_critic.state_dict(),\n",
    "            'scaler_gen_state_dict': scaler_gen.state_dict(),\n",
    "            'scaler_critic_state_dict': scaler_critic.state_dict(),\n",
    "            'g_losses_history': g_losses_hist,\n",
    "            'c_losses_history': c_losses_hist,\n",
    "            'fid_scores_history': fid_scores_hist,\n",
    "            'fid_epochs_history': fid_epochs_hist,\n",
    "            'kid_scores_history': kid_scores_hist,\n",
    "            'kid_std_history': kid_std_hist,\n",
    "            'kid_epochs_history': kid_epochs_hist,\n",
    "            'best_fid': best_fid,\n",
    "            'best_kid': best_kid,\n",
    "            'epochs_no_improve': epochs_no_improve\n",
    "        }\n",
    "        save_checkpoint(checkpoint_state, f\"{CONTINUATION_PREFIX}error_{timestamp}.pth.tar\")\n",
    "    except Exception as save_e:\n",
    "        logger.error(f\"Failed to save checkpoint after error: {save_e}\", exc_info=True)\n",
    "\n",
    "# ==============================================\n",
    "# Post-Training Analysis\n",
    "# ==============================================\n",
    "logger.info(\"=\"*80)\n",
    "logger.info(\"--- Post-Training Analysis Phase ---\")\n",
    "\n",
    "# Calculate training duration and final status\n",
    "total_training_time = time.time() - training_start_time\n",
    "final_epoch = epoch if 'epoch' in locals() else start_epoch\n",
    "logger.info(f\"Training finished after {final_epoch-start_epoch} epochs, during Epoch {final_epoch} ({total_training_time:.2f} seconds)\")\n",
    "logger.info(f\"Stop reason: {stop_reason}\")\n",
    "logger.info(f\"Final Global Step: {global_step}\")\n",
    "\n",
    "if fid_scores_hist:\n",
    "    logger.info(f\"Best FID Score: {best_fid:.4f}\")\n",
    "    \n",
    "    # Compare with original best FID\n",
    "    original_best_fid = history_data.get('best_fid', float('inf'))\n",
    "    if best_fid < original_best_fid:\n",
    "        improvement = original_best_fid - best_fid\n",
    "        logger.info(f\"FID improved by {improvement:.4f} points from original best of {original_best_fid:.4f}\")\n",
    "    else:\n",
    "        logger.info(f\"FID did not improve from original best of {original_best_fid:.4f}\")\n",
    "\n",
    "if kid_scores_hist:\n",
    "    logger.info(f\"Best KID Score: {best_kid:.6f}\")\n",
    "    \n",
    "    # Compare with original best KID\n",
    "    original_best_kid = history_data.get('best_kid', float('inf'))\n",
    "    if best_kid < original_best_kid:\n",
    "        improvement = original_best_kid - best_kid\n",
    "        logger.info(f\"KID improved by {improvement:.6f} points from original best of {original_best_kid:.6f}\")\n",
    "    else:\n",
    "        logger.info(f\"KID did not improve from original best of {original_best_kid:.6f}\")\n",
    "\n",
    "# Generate timestamp for final files\n",
    "final_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# --- Generate Final Plots ---\n",
    "logger.info(\"Generating final visualization plots...\")\n",
    "\n",
    "# Generate individual plots\n",
    "plot_losses(g_losses_hist, c_losses_hist, CONT_PLOT_DIR, \n",
    "          f\"{CONTINUATION_PREFIX}losses\", final_epoch+1, final_timestamp, \n",
    "          is_final=True, stop_reason=stop_reason)\n",
    "\n",
    "if fid_scores_hist:\n",
    "    plot_metric(fid_scores_hist, fid_epochs_hist, best_fid, \"FID\", CONT_PLOT_DIR,\n",
    "              f\"{CONTINUATION_PREFIX}fid\", final_epoch+1, final_timestamp, \n",
    "              is_final=True, stop_reason=stop_reason)\n",
    "\n",
    "if kid_scores_hist:\n",
    "    plot_metric(kid_scores_hist, kid_epochs_hist, best_kid, \"KID\", CONT_PLOT_DIR,\n",
    "              f\"{CONTINUATION_PREFIX}kid\", final_epoch+1, final_timestamp, \n",
    "              is_final=True, stop_reason=stop_reason, std_devs=kid_std_hist)\n",
    "    \n",
    "    # Generate combined FID/KID plot if both are available\n",
    "    if fid_scores_hist:\n",
    "        try:\n",
    "            # Use the shortest history length to avoid mismatch errors\n",
    "            common_length = min(len(fid_scores_hist), len(kid_scores_hist))\n",
    "            if common_length > 0:\n",
    "                fid_subset = fid_scores_hist[:common_length]\n",
    "                kid_subset = kid_scores_hist[:common_length]\n",
    "                epochs_subset = fid_epochs_hist[:common_length]  # Use FID epochs as common epochs\n",
    "                \n",
    "                plot_combined_metrics(fid_subset, kid_subset, epochs_subset, CONT_PLOT_DIR,\n",
    "                                   f\"{CONTINUATION_PREFIX}combined_metrics\", final_epoch+1, final_timestamp, \n",
    "                                   is_final=True, stop_reason=stop_reason)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to generate combined metrics plot: {e}\", exc_info=True)\n",
    "\n",
    "# --- Generate Feature Space Visualization ---\n",
    "if PLOT_FEATURE_SPACE and real_features is not None:\n",
    "    # Try to load best fake features if not already in memory\n",
    "    if current_best_fake_features is None:\n",
    "        try:\n",
    "            best_fake_features_path = os.path.join(CONT_ANALYSIS_DIR, f\"{CONTINUATION_PREFIX}best_fake_features.npy\")\n",
    "            if os.path.exists(best_fake_features_path):\n",
    "                current_best_fake_features = np.load(best_fake_features_path)\n",
    "                logger.info(f\"Loaded best fake features for visualization\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to load best fake features: {e}\")\n",
    "    \n",
    "    # If we have fake features, generate visualization\n",
    "    if current_best_fake_features is not None:\n",
    "        if USE_UMAP and UMAP_AVAILABLE:\n",
    "            plot_feature_space(real_features, current_best_fake_features, \"umap\", CONT_PLOT_DIR,\n",
    "                             f\"{CONTINUATION_PREFIX}feature_space\", final_epoch+1, final_timestamp, \n",
    "                             stop_reason=stop_reason)\n",
    "        elif TSNE_AVAILABLE:\n",
    "            plot_feature_space(real_features, current_best_fake_features, \"tsne\", CONT_PLOT_DIR,\n",
    "                             f\"{CONTINUATION_PREFIX}feature_space\", final_epoch+1, final_timestamp, \n",
    "                             stop_reason=stop_reason)\n",
    "        else:\n",
    "            logger.warning(\"Neither UMAP nor t-SNE available. Skipping feature space visualization.\")\n",
    "    else:\n",
    "        logger.warning(\"No fake features available for visualization.\")\n",
    "\n",
    "# --- Generate Final Sample Grid ---\n",
    "logger.info(\"Generating final sample grid...\")\n",
    "generate_final_sample_grid(CONT_SAMPLE_DIR, epoch=final_epoch+1, timestamp=final_timestamp)\n",
    "\n",
    "# --- Generate Markdown Report ---\n",
    "logger.info(\"Generating markdown report...\")\n",
    "training_info = {\n",
    "    'original_epochs': start_epoch,\n",
    "    'current_epoch': final_epoch+1,\n",
    "    'total_additional_epochs': final_epoch+1-start_epoch,\n",
    "    'stop_reason': stop_reason,\n",
    "    'training_time': total_training_time,\n",
    "}\n",
    "\n",
    "report_path = os.path.join(CONT_ANALYSIS_DIR, f\"{CONTINUATION_PREFIX}training_report_{final_timestamp}.md\")\n",
    "generate_markdown_report({\n",
    "    'g_losses_hist': g_losses_hist,\n",
    "    'c_losses_hist': c_losses_hist,\n",
    "    'fid_scores_hist': fid_scores_hist,\n",
    "    'fid_epochs_hist': fid_epochs_hist,\n",
    "    'kid_scores_hist': kid_scores_hist,\n",
    "    'kid_epochs_hist': kid_epochs_hist,\n",
    "    'best_fid': best_fid,\n",
    "    'best_kid': best_kid\n",
    "}, training_info, report_path)\n",
    "\n",
    "# ==============================================\n",
    "# Optional Precision/Recall Calculation\n",
    "# ==============================================\n",
    "try:\n",
    "    logger.info(\"Skipping optional Precision/Recall calculation (not implemented)\")\n",
    "    # This is where you could add code for Precision/Recall metrics\n",
    "    # It would require more libraries and computation\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during Precision/Recall calculation: {e}\")\n",
    "\n",
    "# ==============================================\n",
    "# Final Cleanup\n",
    "# ==============================================\n",
    "logger.info(\"--- Running Final Cleanup ---\")\n",
    "log_gpu_memory_usage(\"Final\")\n",
    "\n",
    "logger.info(\"=\"*80)\n",
    "logger.info(f\"Continuation script execution complete. Results saved in: {CONTINUATION_DIR}\")\n",
    "logger.info(f\"Final best FID: {best_fid:.4f}\")\n",
    "if kid_scores_hist:\n",
    "    logger.info(f\"Final best KID: {best_kid:.6f}\")\n",
    "logger.info(f\"Final Stop Reason: {stop_reason}\")\n",
    "logger.info(\"=\"*80)\n",
    "\n",
    "# Close all open logs\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f704c-2b45-4489-9880-a840cc9a106e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
