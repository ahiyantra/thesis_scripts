{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New 02 - Task 01 - VetCyto - CutSplitStep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Step - Cutting Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def crop_objects_from_image(image_path, json_path, output_dir):\n",
    "    # Null address check\n",
    "    if not (os.path.exists(image_path)):\n",
    "        print(\"The jpeg path is empty! Check for mistakes! \\ninput arguments: \\n\", \"image_path =\", image_path, \"\\n\", \"json_path =\", json_path, \"\\n\", \"output_dir =\", output_dir, \"\\n\")\n",
    "        return\n",
    "    if not (os.path.exists(json_path)):\n",
    "        print(\"The json path is empty! Check for mistakes! \\ninput arguments: \\n\", \"image_path =\", image_path, \"\\n\", \"json_path =\", json_path, \"\\n\", \"output_dir =\", output_dir, \"\\n\")\n",
    "        return\n",
    "\n",
    "    # Check if output directory exists and handle accordingly\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Creating output directory: '{output_dir}'\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load the JSON file containing object annotations\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Increase the maximum allowed image size by modifying the MAX_IMAGE_PIXELS constant in PIL to reduce zip bomb warnings\n",
    "    Image.MAX_IMAGE_PIXELS = 250000000 \n",
    "\n",
    "    # Open the image file\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Get the base name of the original image file (without extension)\n",
    "    original_base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    # Iterate through each shape in the JSON data, with a progress bar\n",
    "    for shape in tqdm(data['shapes'], desc=\"Cropping objects\"):\n",
    "        points = shape['points']\n",
    "        \n",
    "        if shape['shape_type'] == 'rectangle':\n",
    "            # Extract rectangle coordinates\n",
    "            x1, y1 = points[0]\n",
    "            x2, y2 = points[1]\n",
    "\n",
    "            # Calculate the bounding box coordinates\n",
    "            left = min(x1, x2)\n",
    "            upper = min(y1, y2)\n",
    "            right = max(x1, x2)\n",
    "            lower = max(y1, y2)\n",
    "\n",
    "        elif shape['shape_type'] == 'polygon':\n",
    "            # Extract polygon coordinates\n",
    "            x_coords = [point[0] for point in points]\n",
    "            y_coords = [point[1] for point in points]\n",
    "\n",
    "            # Calculate the bounding box coordinates\n",
    "            left = min(x_coords)\n",
    "            upper = min(y_coords)\n",
    "            right = max(x_coords)\n",
    "            lower = max(y_coords)\n",
    "\n",
    "        else:\n",
    "            print(f\"Unsupported shape type: {shape['shape_type']}. Skipping this shape.\")\n",
    "            continue\n",
    "\n",
    "        # Crop the image using the bounding box\n",
    "        cropped_image = image.crop((left, upper, right, lower))\n",
    "\n",
    "        # Generate output filename and handle naming conflicts\n",
    "        label = shape['label']\n",
    "        base_output_path = os.path.join(output_dir, f\"{original_base_name}_{label}_{int(left)}_{int(upper)}.jpg\")\n",
    "        output_path = base_output_path\n",
    "\n",
    "        # Handle naming conflicts by appending numbers in brackets\n",
    "        counter = 1\n",
    "        while os.path.exists(output_path):\n",
    "            output_path = os.path.splitext(base_output_path)[0] + f\"({counter})\" + os.path.splitext(base_output_path)[1]\n",
    "            counter += 1\n",
    "        \n",
    "        cropped_image.save(output_path)\n",
    "\n",
    "def process_directory(image_dir, json_dir, output_base_dir):\n",
    "    # Create subdirectories for 1, 2, 5 and 9 classes\n",
    "    class_names = [\"1\", \"2\", \"5\", \"9\"]\n",
    "    class_dirs = {class_name: os.path.join(output_base_dir, class_name) for class_name in class_names}\n",
    "    for class_dir in class_dirs.values():\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "    # Get lists of all image and json files\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.jpeg')]\n",
    "    json_files = [f for f in os.listdir(json_dir) if f.endswith('.json')]\n",
    "\n",
    "    # Check if no images were found\n",
    "    if len(image_files) == 0:\n",
    "        print(f\"ERROR: No image files (jpg/jpeg) found in directory: {image_dir}\")\n",
    "        return\n",
    "\n",
    "    # Check if no JSON files were found\n",
    "    if len(json_files) == 0:\n",
    "        print(f\"ERROR: No JSON files found in directory: {json_dir}\")\n",
    "        return\n",
    "\n",
    "    # Track the number of successfully processed images\n",
    "    processed_count = 0\n",
    "\n",
    "    for image_file in image_files:\n",
    "        base_name = os.path.splitext(image_file)[0]\n",
    "        json_file = f\"{base_name}.json\"\n",
    "\n",
    "        if json_file in json_files:\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            json_path = os.path.join(json_dir, json_file)\n",
    "\n",
    "            # Determine the class of the image based on its name\n",
    "            if image_file.startswith(\"T\") and len(image_file) > 1:\n",
    "                class_digit = image_file[1]  # Get the character right after \"T\"\n",
    "                if class_digit in class_names:\n",
    "                    output_dir = class_dirs[class_digit]\n",
    "                else:\n",
    "                    print(f\"Warning: Image {image_file} has unsupported class prefix '{class_digit}'. Skipping.\")\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"Warning: Image {image_file} does not start with 'T' or has invalid format. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing image: {image_path} with JSON: {json_path}\")\n",
    "\n",
    "            crop_objects_from_image(image_path, json_path, output_dir)\n",
    "            processed_count += 1\n",
    "        else:\n",
    "            print(f\"Warning: No JSON file found for image: {image_file}\")\n",
    "\n",
    "    # Report final processing status\n",
    "    if processed_count == 0:\n",
    "        print(f\"ERROR: No images could be processed. Check if image names match their corresponding JSON files.\")\n",
    "    else:\n",
    "        print(f\"Successfully processed {processed_count} out of {len(image_files)} images.\")\n",
    "\n",
    "# Example directory paths\n",
    "# default : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\TrainingStepSet\\\\jpg\\\\' ; # alt = '' ;\n",
    "# notes : manual annotations, 100% ;\n",
    "# example 01 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\HM_aligned_to_SC_renamed_files_manual_labels_T_(new_OM_images)'\n",
    "# notes : automated annotations, 100% ;\n",
    "# example 02 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\HM_aligned_to_SC_renamed_files_automated_labels_T'\n",
    "# notes : manual annotations, 125% ;\n",
    "# example 03 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\25_pc_expanded_manual_labels_with_aligned_HM_images_T'\n",
    "# notes : automated annotations, 125% ;\n",
    "# example 04 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\25_pc_expanded_automated_labels_with_aligned_HM_images_T'\n",
    "# notes : manual annotations, 150% ;\n",
    "# example 05 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\50_pc_expanded_manual_labels_with_aligned_HM_images_T'\n",
    "# notes : automated annotations, 150% ;\n",
    "# example 06 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\50_pc_expanded_automated_labels_with_aligned_HM_images_T'\n",
    "# notes : ?\n",
    "# example 07 : ''\n",
    "image_dir = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\50_pc_expanded_automated_labels_with_aligned_HM_images_T' \n",
    "# default = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\TrainingStepSet\\\\new-training-labels-json\\\\' ; # alt = '' ;\n",
    "# notes : manual annotations, 100% ;\n",
    "# example 01 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\HM_aligned_to_SC_renamed_files_manual_labels_T_(new_OM_images)'\n",
    "# notes : automated annotations, 100% ;\n",
    "# example 02 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\HM_aligned_to_SC_renamed_files_automated_labels_T'\n",
    "# notes : manual annotations, 125% ;\n",
    "# example 03 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\25_pc_expanded_manual_labels_with_aligned_HM_images_T'\n",
    "# notes : automated annotations, 125% ;\n",
    "# example 04 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\25_pc_expanded_automated_labels_with_aligned_HM_images_T'\n",
    "# notes : manual annotations, 150% ;\n",
    "# example 05 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\50_pc_expanded_manual_labels_with_aligned_HM_images_T'\n",
    "# notes : automated annotations, 150% ;\n",
    "# example 06 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\50_pc_expanded_automated_labels_with_aligned_HM_images_T'\n",
    "# notes : ?\n",
    "# example 07 : ''\n",
    "json_dir = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\task-04_dataset\\\\50_pc_expanded_automated_labels_with_aligned_HM_images_T' \n",
    "# default : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\new_work_02\\\\vet_images_sliced\\\\TrainingStepSet\\\\' ; # alt = '' ;\n",
    "# notes : manual annotations, 100% ;\n",
    "# example 01 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_manual_labels_T_640_100-pc'\n",
    "# notes : automated annotations, 100% ;\n",
    "# example 02 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_automated_labels_T_640_100-pc'\n",
    "# notes : manual annotations, 125% ;\n",
    "# example 03 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_manual-labels_T_640_125-pc'\n",
    "# notes : automated annotations, 125% ;\n",
    "# example 04 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_automated-labels_T_640_125-pc'\n",
    "# notes : manual annotations, 150% ;\n",
    "# example 05 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_manual-labels_T_640_150-pc'\n",
    "# notes : automated annotations, 150% ;\n",
    "# example 06 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_automated-labels_T_640_150-pc'\n",
    "# notes : ?\n",
    "# example 07 : ''\n",
    "output_base_dir = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_automated-labels_T_640_150-pc' \n",
    "\n",
    "process_directory(image_dir, json_dir, output_base_dir)\n",
    "\n",
    "#image_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\TrainingSet\\\\jpg\\\\T1(2)TAPE.jpg' ; # default = '/Users/gustavszviedris/Desktop/vet_images/Training/9/T95_28.02.jpg' ; alt = 'C:\\\\projects\\\\SlideScanner2_28.2.2024\\\\T95_28.02.jpg' ; \n",
    "#json_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\TrainingSet_(older-data)\\\\labeled\\\\T1(2)TAPE.json' ; # default = '/Users/gustavszviedris/Desktop/Labeled_Slides/Training/9/T95_28.02.json' ; alt = 'C:\\\\projects\\\\Labeled_Slides\\\\T95_28.02.json' ; \n",
    "#output_dir = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\new_work_02\\\\vet_images_sliced\\\\TrainingSet\\\\T1(2)TAPE\\\\' ; # default = '/Users/gustavszviedris/Desktop/vet_images_sliced/Training/9/' ; alt = 'E:\\\\-_EDI_-\\\\notes\\\\havetai+vetcyto\\\\vet_images_sliced\\\\TrainingStep\\\\9' ; \n",
    "\n",
    "#crop_objects_from_image(image_path, json_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Step - Cutting Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def crop_objects_from_image(image_path, json_path, output_dir):\n",
    "    # Null address check\n",
    "    if not (os.path.exists(image_path)):\n",
    "        print(\"The jpeg path is empty! Check for mistakes! \\ninput arguments: \\n\", \"image_path =\", image_path, \"\\n\", \"json_path =\", json_path, \"\\n\", \"output_dir =\", output_dir, \"\\n\")\n",
    "        return\n",
    "    if not (os.path.exists(json_path)):\n",
    "        print(\"The json path is empty! Check for mistakes! \\ninput arguments: \\n\", \"image_path =\", image_path, \"\\n\", \"json_path =\", json_path, \"\\n\", \"output_dir =\", output_dir, \"\\n\")\n",
    "        return\n",
    "\n",
    "    # Check if output directory exists and handle accordingly\n",
    "    if os.path.exists(output_dir):\n",
    "        print(f\"The output directory '{output_dir}' already exists. It'll be replaced.\")\n",
    "        shutil.rmtree(output_dir)\n",
    "    print(f\"Creating output directory: '{output_dir}'\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load the JSON file containing object annotations\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Increase the maximum allowed image size by modifying the MAX_IMAGE_PIXELS constant in PIL to reduce zip bomb warnings\n",
    "    Image.MAX_IMAGE_PIXELS = 250000000 \n",
    "\n",
    "    # Open the image file\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Iterate through each shape in the JSON data, with a progress bar\n",
    "    for shape in tqdm(data['shapes'], desc=\"Cropping objects\"):\n",
    "        points = shape['points']\n",
    "        \n",
    "        if shape['shape_type'] == 'rectangle':\n",
    "            # Extract rectangle coordinates\n",
    "            x1, y1 = points[0]\n",
    "            x2, y2 = points[1]\n",
    "\n",
    "            # Calculate the bounding box coordinates\n",
    "            left = min(x1, x2)\n",
    "            upper = min(y1, y2)\n",
    "            right = max(x1, x2)\n",
    "            lower = max(y1, y2)\n",
    "\n",
    "        elif shape['shape_type'] == 'polygon':\n",
    "            # Extract polygon coordinates\n",
    "            x_coords = [point[0] for point in points]\n",
    "            y_coords = [point[1] for point in points]\n",
    "\n",
    "            # Calculate the bounding box coordinates\n",
    "            left = min(x_coords)\n",
    "            upper = min(y_coords)\n",
    "            right = max(x_coords)\n",
    "            lower = max(y_coords)\n",
    "\n",
    "        else:\n",
    "            print(f\"Unsupported shape type: {shape['shape_type']}. Skipping this shape.\")\n",
    "            continue\n",
    "\n",
    "        # Crop the image using the bounding box\n",
    "        cropped_image = image.crop((left, upper, right, lower))\n",
    "\n",
    "        # Generate output filename and save the cropped image\n",
    "        label = shape['label']\n",
    "        output_path = f\"{output_dir}/{label}_{int(left)}_{int(upper)}.jpg\"\n",
    "        cropped_image.save(output_path)\n",
    "\n",
    "def process_directory(image_dir, json_dir, output_base_dir):\n",
    "    # Get lists of all image and json files\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.jpeg')]\n",
    "    json_files = [f for f in os.listdir(json_dir) if f.endswith('.json')]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        base_name = os.path.splitext(image_file)[0]\n",
    "        json_file = f\"{base_name}.json\"\n",
    "\n",
    "        if json_file in json_files:\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            json_path = os.path.join(json_dir, json_file)\n",
    "            output_dir = os.path.join(output_base_dir, base_name)\n",
    "\n",
    "            print(f\"Processing image: {image_path} with JSON: {json_path}\")\n",
    "\n",
    "            crop_objects_from_image(image_path, json_path, output_dir)\n",
    "        else:\n",
    "            print(f\"Warning: No JSON file found for image: {image_path}\")\n",
    "\n",
    "# Example directory paths\n",
    "image_dir = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\TestingStepSet\\\\jpg\\\\' ; # alt = '' ;\n",
    "json_dir = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\TestingStepSet\\\\labeled\\\\' ; # alt = '' ;\n",
    "output_base_dir = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\new_work_02\\\\vet_images_sliced\\\\TestingStepSet\\\\' ; # alt = '' ;\n",
    "\n",
    "process_directory(image_dir, json_dir, output_base_dir)\n",
    "\n",
    "#image_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\TrainingSet\\\\jpg\\\\T1(2)TAPE.jpg' ; # default = '/Users/gustavszviedris/Desktop/vet_images/Training/9/T95_28.02.jpg' ; alt = 'C:\\\\projects\\\\SlideScanner2_28.2.2024\\\\T95_28.02.jpg' ; \n",
    "#json_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\TrainingSet_(older-data)\\\\labeled\\\\T1(2)TAPE.json' ; # default = '/Users/gustavszviedris/Desktop/Labeled_Slides/Training/9/T95_28.02.json' ; alt = 'C:\\\\projects\\\\Labeled_Slides\\\\T95_28.02.json' ; \n",
    "#output_dir = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\new_work_02\\\\vet_images_sliced\\\\TrainingSet\\\\T1(2)TAPE\\\\' ; # default = '/Users/gustavszviedris/Desktop/vet_images_sliced/Training/9/' ; alt = 'E:\\\\-_EDI_-\\\\notes\\\\havetai+vetcyto\\\\vet_images_sliced\\\\TrainingStep\\\\9' ; \n",
    "\n",
    "#crop_objects_from_image(image_path, json_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Step - Splitting Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_directories(output_path, classes):\n",
    "    # Create train, val, and test directories for each class\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for class_name in classes:\n",
    "            os.makedirs(os.path.join(output_path, split, class_name), exist_ok=True)\n",
    "\n",
    "def split_and_copy_files(source_path, output_path, class_name, train_size=0.7, val_size=0.15, test_size=0.15):\n",
    "    class_path = os.path.join(source_path, class_name)\n",
    "\n",
    "    if not os.path.exists(class_path):\n",
    "        print(f\"WARNING: Directory does not exist: {class_path}\")\n",
    "        return False\n",
    "\n",
    "    files = os.listdir(class_path)\n",
    "    files = [f for f in files if os.path.isfile(os.path.join(class_path, f))]\n",
    "    \n",
    "    print(f\"Class {class_name}: {len(files)} files found\")\n",
    "\n",
    "    if not files:\n",
    "        print(f\"WARNING: No files found in class {class_name}\")\n",
    "        return False\n",
    "\n",
    "    # Split files into train, validation, and test sets\n",
    "    train_files, temp_files = train_test_split(files, test_size=(val_size + test_size), random_state=42)\n",
    "    val_files, test_files = train_test_split(temp_files, test_size=test_size/(val_size + test_size), random_state=42)\n",
    "\n",
    "    # Copy files without progress bars\n",
    "    splits_count = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "    \n",
    "    for split, file_list in [('train', train_files), ('val', val_files), ('test', test_files)]:\n",
    "        for file in file_list:\n",
    "            try:\n",
    "                src = os.path.join(class_path, file)\n",
    "                dst = os.path.join(output_path, split, class_name, file)\n",
    "                os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "                shutil.copy(src, dst)\n",
    "                splits_count[split] += 1\n",
    "            except Exception as e:\n",
    "                print(f\"WARNING: Error copying file {file}: {str(e)}\")\n",
    "    \n",
    "    # Report splits\n",
    "    print(f\"Class {class_name} split: train={splits_count['train']}, val={splits_count['val']}, test={splits_count['test']}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def split_dataset(source_folder, output_folder):\n",
    "    # Get all class names\n",
    "    try:\n",
    "        class_names = [d for d in os.listdir(source_folder) if os.path.isdir(os.path.join(source_folder, d))]\n",
    "    except Exception as e:\n",
    "        print(f\"WARNING: Could not access source folder: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    if not class_names:\n",
    "        print(\"WARNING: No classes found in source folder\")\n",
    "        return\n",
    "    \n",
    "    # Count total files\n",
    "    total_files = 0\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(source_folder, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            files = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "            total_files += len(files)\n",
    "    \n",
    "    print(f\"Total files found: {total_files}\")\n",
    "    print(f\"Classes found: {', '.join(class_names)}\")\n",
    "\n",
    "    # Check if output directory exists and handle accordingly\n",
    "    if os.path.exists(output_folder):\n",
    "        print(f\"The output directory '{output_folder}' already exists. It'll be replaced.\")\n",
    "        shutil.rmtree(output_folder)\n",
    "    print(f\"Creating output directory: '{output_folder}'\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Create the necessary directory structure\n",
    "    create_directories(output_folder, class_names)\n",
    "\n",
    "    # Process each class with a single progress bar\n",
    "    with tqdm(class_names, desc=\"Processing classes\", unit=\"class\", ncols=100) as pbar:\n",
    "        for class_name in pbar:\n",
    "            pbar.set_description(f\"Processing class: {class_name}\")\n",
    "            try:\n",
    "                split_and_copy_files(source_folder, output_folder, class_name)\n",
    "            except Exception as e:\n",
    "                print(f\"WARNING: Processing interrupted for class {class_name}: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "# default = '/Users/gustavszviedris/Desktop/vet_images_sliced_copy/Training' ; \n",
    "# alt 01 = 'E:\\\\-_EDI_-\\\\notes\\\\havetai+vetcyto\\\\vet_images_sliced\\\\Training' ; \n",
    "# alt 02 = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\new_work_02\\\\vet_images_sliced\\\\TrainingStepSet'\n",
    "# notes : manual annotations, 100% ;\n",
    "# example 01 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_manual-labels_T_640_100-pc'\n",
    "# notes : automated annotations, 100% ;\n",
    "# example 02 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_automated-labels_T_640_100-pc'\n",
    "# notes : manual annotations, 125% ;\n",
    "# example 03 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_manual-labels_T_640_125-pc'\n",
    "# notes : automated annotations, 125% ;\n",
    "# example 04 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_automated-labels_T_640_125-pc'\n",
    "# notes : manual annotations, 150% ;\n",
    "# example 05 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_manual-labels_T_640_150-pc'\n",
    "# notes : automated annotations, 150% ;\n",
    "# example 06 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_automated-labels_T_640_150-pc'\n",
    "# notes : ?\n",
    "# example 07 : ''\n",
    "source_folder = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced\\\\TrainingStepSet_automated-labels_T_640_150-pc' ; \n",
    "# default = '/Users/gustavszviedris/Desktop/vet_images_sliced_split' ; \n",
    "# alt 01 = 'E:\\\\-_EDI_-\\\\notes\\\\havetai+vetcyto\\\\vet_images_sliced_split' ; \n",
    "# alt 02 = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\new_work_02\\\\vet_images_sliced_split\\\\TrainingStepSet'\n",
    "# notes : manual annotations, 100% ;\n",
    "# example 01 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_manual-labels_T_640_100-pc'\n",
    "# notes : automated annotations, 100% ;\n",
    "# example 02 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_automated-labels_T_640_100-pc'\n",
    "# notes : manual annotations, 125% ;\n",
    "# example 03 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_manual-labels_T_640_125-pc'\n",
    "# notes : automated annotations, 125% ;\n",
    "# example 04 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_automated-labels_T_640_125-pc'\n",
    "# notes : manual annotations, 150% ;\n",
    "# example 05 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_manual-labels_T_640_150-pc'\n",
    "# notes : automated annotations, 150% ;\n",
    "# example 06 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_automated-labels_T_640_150-pc'\n",
    "# notes : ?\n",
    "# example 07 : ''\n",
    "output_folder = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_automated-labels_T_640_150-pc' ; \n",
    "\n",
    "split_dataset(source_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Step - Splitting Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT NEEDED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes: cleaning up garbage files (such as discarded results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Navigate to the data set folder & delete any read-only folders, in case that they get created by accident\n",
    "! echo \"# test 01\" && cd \"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\" && dir\n",
    "#shutil.rmtree(\"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640\\\\results\")\n",
    "#shutil.rmtree(\"C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640\\\\runs\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
