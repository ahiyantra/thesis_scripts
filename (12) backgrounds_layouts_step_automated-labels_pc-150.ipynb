{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0896e9-931e-4571-a007-bfb6c8eba1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script 1 (Revised v4): Large Image Background Extraction & Layout Analysis\n",
    "# Added per-file statistics printing. Parameters at the end.\n",
    "# \n",
    "# \n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image, ImageStat, UnidentifiedImageError # Pillow for large images\n",
    "import numpy as np\n",
    "import cv2 # OpenCV for greyscale conversion if needed\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm # Use tqdm.notebook for Jupyter!\n",
    "import math\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "# Suppress DecompressionBombWarning if images are huge, but be aware of risks\n",
    "# Image.MAX_IMAGE_PIXELS = None # Uncomment if needed, use with caution\n",
    "\n",
    "# Suppress specific OpenCV warnings if they occur\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='cv2')\n",
    "\n",
    "# --- Helper Functions ---\n",
    "# (Helper functions: get_bbox_from_points, check_object_validity, \n",
    "#  parse_labelme_json_and_analyze, check_slice_overlap, \n",
    "#  is_slice_predominantly_black, save_analysis_plots remain the same as v3)\n",
    "# --- Re-including them here for completeness of the script block ---\n",
    "\n",
    "def get_bbox_from_points(points):\n",
    "    \"\"\"Calculates the bounding box (x1, y1, x2, y2) from a list of points.\"\"\"\n",
    "    if not points or len(points) < 1:\n",
    "        return 0, 0, 0, 0\n",
    "    try:\n",
    "        x_coords = [p[0] for p in points]\n",
    "        y_coords = [p[1] for p in points]\n",
    "        x1 = min(x_coords)\n",
    "        y1 = min(y_coords)\n",
    "        x2 = max(x_coords)\n",
    "        y2 = max(y_coords)\n",
    "        # Ensure coordinates are integers and valid range\n",
    "        return int(x1), int(y1), int(x2), int(y2)\n",
    "    except (IndexError, TypeError): # Handle malformed points\n",
    "        return 0, 0, 0, 0\n",
    "\n",
    "def check_object_validity(image_pil, bbox, black_threshold):\n",
    "    \"\"\"Checks if the center of a bbox is likely in a black area using pixel sampling.\"\"\"\n",
    "    try:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        if x1 >= x2 or y1 >= y2: return False # Invalid bbox\n",
    "        \n",
    "        center_x = int((x1 + x2) / 2)\n",
    "        center_y = int((y1 + y2) / 2)\n",
    "        \n",
    "        # Ensure center is within image bounds before sampling\n",
    "        img_w, img_h = image_pil.size\n",
    "        if not (0 <= center_x < img_w and 0 <= center_y < img_h):\n",
    "             return False # Center outside image, treat as invalid\n",
    "\n",
    "        # Sample pixel - Pillow's getpixel is efficient for single pixels\n",
    "        pixel_value = image_pil.getpixel((center_x, center_y))\n",
    "        \n",
    "        # Handle greyscale vs RGB tuple from getpixel\n",
    "        mean_val = 0\n",
    "        if isinstance(pixel_value, (int, float)): # Greyscale\n",
    "            mean_val = pixel_value\n",
    "        elif isinstance(pixel_value, (tuple, list)) and len(pixel_value) >= 1: # RGB/RGBA etc.\n",
    "             mean_val = pixel_value[0] # Assuming R=G=B or checking first channel is sufficient\n",
    "        else: \n",
    "             return True # Unknown format, assume not black\n",
    "             \n",
    "        # If pixel value is strictly greater than the threshold, it's valid (not black)\n",
    "        return mean_val > black_threshold \n",
    "        \n",
    "    except Exception as e:\n",
    "        # print(f\"  Warning: Error sampling pixel for validity check at ({center_x},{center_y}): {e}\")\n",
    "        return True # Default to valid if sampling fails\n",
    "\n",
    "def parse_labelme_json_and_analyze(json_path, image_pil, black_threshold_object_check):\n",
    "    \"\"\"Parses LabelMe JSON, checks object validity, and collects stats.\"\"\"\n",
    "    object_list = []\n",
    "    image_stats = defaultdict(list)\n",
    "    img_w, img_h = image_pil.size\n",
    "\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f: \n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error reading JSON {json_path}: {e}\")\n",
    "        return [], image_stats # Return empty\n",
    "\n",
    "    for shape in data.get('shapes', []):\n",
    "        points = shape.get('points', [])\n",
    "        label = shape.get('label', 'unknown')\n",
    "\n",
    "        if not points: continue\n",
    "\n",
    "        x1, y1, x2, y2 = get_bbox_from_points(points)\n",
    "        \n",
    "        # Ensure bbox is within image bounds\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(img_w, x2), min(img_h, y2)\n",
    "        \n",
    "        if x1 >= x2 or y1 >= y2: continue # Skip invalid boxes after clipping\n",
    "\n",
    "        bbox = [x1, y1, x2, y2]\n",
    "        # Check validity based on center pixel value\n",
    "        is_valid = check_object_validity(image_pil, bbox, black_threshold_object_check)\n",
    "\n",
    "        obj_data = {'label': label, 'bbox': bbox, 'is_valid': is_valid}\n",
    "        object_list.append(obj_data)\n",
    "\n",
    "        # Only collect stats for objects deemed valid\n",
    "        if is_valid:\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            if width > 0 and height > 0:\n",
    "                image_stats[\"object_widths\"].append(width)\n",
    "                image_stats[\"object_heights\"].append(height)\n",
    "                aspect_ratio = max(width / height, height / width)\n",
    "                image_stats[\"object_aspect_ratios\"].append(aspect_ratio)\n",
    "                image_stats[\"object_centers_x\"].append((x1 + x2) / 2.0)\n",
    "                image_stats[\"object_centers_y\"].append((y1 + y2) / 2.0)\n",
    "                image_stats[\"object_labels\"].append(label) \n",
    "\n",
    "    image_stats[\"num_valid_objects\"] = len(image_stats[\"object_widths\"]) \n",
    "    image_stats[\"num_total_objects\"] = len(object_list) \n",
    "    return object_list, image_stats\n",
    "\n",
    "def check_slice_overlap(slice_bbox, object_list, margin_pixels):\n",
    "    \"\"\"Checks if slice overlaps with any valid object bbox + margin.\"\"\"\n",
    "    sx1, sy1, sx2, sy2 = slice_bbox\n",
    "    for obj in object_list:\n",
    "        if obj['is_valid']: # Only check against valid objects\n",
    "            ox1, oy1, ox2, oy2 = obj['bbox']\n",
    "            # Add margin to object bbox\n",
    "            ox1m = max(0, ox1 - margin_pixels)\n",
    "            oy1m = max(0, oy1 - margin_pixels)\n",
    "            ox2m = ox2 + margin_pixels \n",
    "            oy2m = oy2 + margin_pixels\n",
    "\n",
    "            # Check for overlap \n",
    "            if sx1 < ox2m and sx2 > ox1m and sy1 < oy2m and sy2 > oy1m:\n",
    "                return True # Overlap found\n",
    "    return False # No overlap with any valid object\n",
    "\n",
    "def is_slice_predominantly_black(slice_pixels_np_gray, black_threshold, black_percentage_threshold):\n",
    "    \"\"\"Checks if a NumPy slice is mostly black based on pixel value percentage.\"\"\"\n",
    "    if slice_pixels_np_gray is None or slice_pixels_np_gray.size == 0:\n",
    "        return True # Treat empty/invalid slice as black\n",
    "\n",
    "    try:\n",
    "        # Pixels with value <= threshold are considered black\n",
    "        black_pixel_count = np.sum(slice_pixels_np_gray <= black_threshold)\n",
    "        total_pixels = slice_pixels_np_gray.size\n",
    "        if total_pixels == 0: return True # Avoid division by zero for empty slice\n",
    "\n",
    "        percentage_black = (black_pixel_count / total_pixels) * 100.0\n",
    "        \n",
    "        # Return True if the percentage of black pixels EXCEEDS the threshold\n",
    "        return percentage_black > black_percentage_threshold\n",
    "        \n",
    "    except Exception as e:\n",
    "         print(f\"  Warning: Error calculating black percentage for slice: {e}\")\n",
    "         return True # Treat as black on error\n",
    "\n",
    "def save_analysis_plots(stats_data, output_dir, img_w, img_h):\n",
    "    \"\"\"Generates and saves plots for layout statistics. Requires aggregated data.\"\"\"\n",
    "    stats_plot_dir = os.path.join(output_dir, \"statistics_plots\")\n",
    "    os.makedirs(stats_plot_dir, exist_ok=True)\n",
    "    print(f\"\\nGenerating analysis plots in: {stats_plot_dir}\")\n",
    "\n",
    "    # Aggregate lists from all images\n",
    "    all_num_objects = stats_data.get(\"num_valid_objects_per_image\", []) \n",
    "    all_widths = stats_data.get(\"object_widths\", [])\n",
    "    all_heights = stats_data.get(\"object_heights\", [])\n",
    "    all_aspect_ratios = stats_data.get(\"object_aspect_ratios\", [])\n",
    "    all_centers_x = stats_data.get(\"object_centers_x\", [])\n",
    "    all_centers_y = stats_data.get(\"object_centers_y\", [])\n",
    "\n",
    "    plt.style.use('seaborn-v0_8-darkgrid') \n",
    "\n",
    "    try:\n",
    "        # --- Plotting Section (only if data exists) ---\n",
    "        if all_num_objects:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            max_objs = max(all_num_objects) if all_num_objects else 0\n",
    "            bins = max(1, max_objs // 2 if max_objs > 1 else 1) \n",
    "            sns.histplot(all_num_objects, kde=False, bins=bins)\n",
    "            plt.title('Distribution of Valid Objects per Image')\n",
    "            plt.xlabel('Number of Valid Objects')\n",
    "            plt.ylabel('Frequency (Images)')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(stats_plot_dir, \"valid_objects_per_image_hist.png\"))\n",
    "            plt.close()\n",
    "        \n",
    "        if all_widths and all_heights:\n",
    "            plt.figure(figsize=(12, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            sns.histplot(all_widths, kde=True, bins=50)\n",
    "            plt.title('Distribution of Valid Object Widths')\n",
    "            plt.xlabel('Width (pixels)')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            sns.histplot(all_heights, kde=True, bins=50)\n",
    "            plt.title('Distribution of Valid Object Heights')\n",
    "            plt.xlabel('Height (pixels)')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(stats_plot_dir, \"object_dimensions_hist.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        if all_aspect_ratios:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(all_aspect_ratios, kde=True, bins=50)\n",
    "            plt.title('Distribution of Valid Object Aspect Ratios (max(W/H, H/W))')\n",
    "            plt.xlabel('Aspect Ratio')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(stats_plot_dir, \"object_aspect_ratios_hist.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        if all_centers_x and all_centers_y and img_w > 0 and img_h > 0:\n",
    "            plt.figure(figsize=(10, 10 * img_h / img_w if img_w > 0 else 10)) # Adjust aspect ratio\n",
    "            sns.histplot(x=all_centers_x, y=all_centers_y, bins=100, cbar=True) \n",
    "            plt.title('Heatmap of Valid Object Center Positions')\n",
    "            plt.xlabel('Center X (pixels)')\n",
    "            plt.ylabel('Center Y (pixels)')\n",
    "            plt.xlim(0, img_w) \n",
    "            plt.ylim(img_h, 0) # Invert Y axis\n",
    "            plt.gca().set_aspect('equal', adjustable='box')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(stats_plot_dir, \"object_centers_heatmap.png\"))\n",
    "            plt.close()\n",
    "            \n",
    "        print(\"Analysis plots saved.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating plots: {e}. Skipping plot generation.\")\n",
    "\n",
    "\n",
    "# --- Main Processing Function ---\n",
    "\n",
    "def process_large_images_for_backgrounds(input_path, output_path, \n",
    "                                         slice_size, \n",
    "                                         step_size, \n",
    "                                         margin_pixels,\n",
    "                                         black_threshold, # Combined threshold\n",
    "                                         black_slice_percentage_threshold, # % threshold for slice\n",
    "                                         generate_plots):\n",
    "    \"\"\"\n",
    "    Main function: Processes large images and LabelMe JSONs to extract clean \n",
    "    background slices and analyze layout statistics, avoiding black areas/objects.\n",
    "    Accepts configuration parameters as arguments and prints per-file stats.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Large Image Layout Analysis and Background Extraction (v4) ---\")\n",
    "    # ... (print configuration parameters as before) ...\n",
    "    print(f\"Input Path: {input_path}\")\n",
    "    print(f\"Output Path: {output_path}\")\n",
    "    print(f\"Slice Size: {slice_size}x{slice_size}\")\n",
    "    print(f\"Step Size: {step_size} (Note: Small step size significantly increases runtime!)\")\n",
    "    print(f\"Margin Pixels: {margin_pixels}\")\n",
    "    print(f\"Black Threshold: <= {black_threshold}\")\n",
    "    print(f\"Black Slice Discard %: > {black_slice_percentage_threshold}%\")\n",
    "    print(f\"Generate Plots: {generate_plots}\")\n",
    "    print(f\"---------------------\\n\")\n",
    "\n",
    "\n",
    "    output_bg_dir = os.path.join(output_path, \"backgrounds\")\n",
    "    output_stats_dir = os.path.join(output_path, \"statistics\")\n",
    "    output_stats_file = os.path.join(output_stats_dir, \"layout_statistics.json\")\n",
    "\n",
    "    # --- Create output directories ---\n",
    "    try:\n",
    "        os.makedirs(output_bg_dir, exist_ok=True)\n",
    "        os.makedirs(output_stats_dir, exist_ok=True)\n",
    "        print(f\"Created/Ensured output directories exist.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error creating output directories: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize global statistics storage\n",
    "    global_stats = defaultdict(list)\n",
    "    \n",
    "    # --- Find image/JSON pairs ---\n",
    "    try:\n",
    "        all_files = os.listdir(input_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input path not found: {input_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing files in input path: {e}\")\n",
    "        return\n",
    "        \n",
    "    image_extensions = ('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.tif')\n",
    "    image_filenames = sorted([f for f in all_files if f.lower().endswith(image_extensions)])\n",
    "\n",
    "    if not image_filenames:\n",
    "        print(\"Error: No image files found in the input directory.\")\n",
    "        return\n",
    "\n",
    "    total_bg_extracted_all_images = 0\n",
    "    processed_image_count = 0\n",
    "    max_img_w, max_img_h = 0, 0 \n",
    "\n",
    "    print(f\"\\nFound {len(image_filenames)} potential images. Starting processing...\")\n",
    "    # --- Loop through image/JSON pairs ---\n",
    "    for img_filename in tqdm(image_filenames, desc=\"Processing Images\"): \n",
    "        base_name = os.path.splitext(img_filename)[0]\n",
    "        img_path = os.path.join(input_path, img_filename)\n",
    "        json_filename = base_name + \".json\"\n",
    "        json_path = os.path.join(input_path, json_filename) \n",
    "\n",
    "        if not os.path.exists(json_path):\n",
    "            continue # Silently skip images without JSON labels\n",
    "\n",
    "        # --- Initialize Per-File Stats ---\n",
    "        num_total_objects_this_image = 0\n",
    "        num_valid_objects_this_image = 0\n",
    "        extracted_for_this_image = 0\n",
    "\n",
    "        try:\n",
    "            # --- Open image and get basic info ---\n",
    "            with Image.open(img_path) as img: \n",
    "                img.load() \n",
    "                img_w, img_h = img.size\n",
    "                max_img_w, max_img_h = max(max_img_w, img_w), max(max_img_h, img_h)\n",
    "                \n",
    "                # --- Parse Labels & Analyze ---\n",
    "                object_list, image_stats = parse_labelme_json_and_analyze(json_path, img, black_threshold) \n",
    "                \n",
    "                # Update per-file counts\n",
    "                num_total_objects_this_image = image_stats.get(\"num_total_objects\", 0)\n",
    "                num_valid_objects_this_image = image_stats.get(\"num_valid_objects\", 0)\n",
    "\n",
    "                # Aggregate global stats\n",
    "                processed_image_count += 1\n",
    "                global_stats[\"image_filenames\"].append(img_filename) \n",
    "                global_stats[\"num_valid_objects_per_image\"].append(num_valid_objects_this_image) \n",
    "                for key in [\"object_widths\", \"object_heights\", \"object_aspect_ratios\", \"object_centers_x\", \"object_centers_y\", \"object_labels\"]:\n",
    "                    global_stats[key].extend(image_stats.get(key, []))\n",
    "\n",
    "                # --- Iterate through slices ---\n",
    "                slice_coords_to_check = []\n",
    "                for sy in range(0, img_h - slice_size + 1, step_size): \n",
    "                     for sx in range(0, img_w - slice_size + 1, step_size):\n",
    "                          slice_coords_to_check.append((sx, sy))\n",
    "\n",
    "                # Inner loop for slices (no tqdm here by default to avoid excessive output)\n",
    "                for sx, sy in slice_coords_to_check:\n",
    "                    slice_bbox_pil = (sx, sy, sx + slice_size, sy + slice_size) \n",
    "                    slice_bbox_coords = [sx, sy, sx + slice_size, sy + slice_size] \n",
    "\n",
    "                    overlaps = check_slice_overlap(slice_bbox_coords, object_list, margin_pixels)\n",
    "\n",
    "                    if not overlaps:\n",
    "                        try:\n",
    "                            slice_pil = img.crop(slice_bbox_pil)\n",
    "                            slice_np = np.array(slice_pil)\n",
    "                            \n",
    "                            # Ensure greyscale \n",
    "                            if slice_np.ndim == 3: \n",
    "                                if slice_np.shape[2] >= 3: \n",
    "                                     slice_gray = cv2.cvtColor(slice_np, cv2.COLOR_RGB2GRAY)\n",
    "                                else: continue \n",
    "                            elif slice_np.ndim == 2: \n",
    "                                 slice_gray = slice_np\n",
    "                            else: continue \n",
    "\n",
    "                            # Check if the slice itself is predominantly black\n",
    "                            is_black = is_slice_predominantly_black(\n",
    "                                slice_gray, \n",
    "                                black_threshold, \n",
    "                                black_slice_percentage_threshold\n",
    "                            )\n",
    "\n",
    "                            if not is_black:\n",
    "                                # Save the clean background patch\n",
    "                                output_filename = f\"{base_name}_bg_{sx}_{sy}.png\"\n",
    "                                output_filepath = os.path.join(output_bg_dir, output_filename)\n",
    "                                cv2.imwrite(output_filepath, slice_gray)\n",
    "                                extracted_for_this_image += 1\n",
    "                                \n",
    "                        except Exception as crop_err:\n",
    "                            pass # Ignore errors during cropping/processing individual slices\n",
    "                            \n",
    "            # --- Print Per-File Summary ---\n",
    "            print(f\"Finished: {img_filename} ({img_w}x{img_h}) | \"\n",
    "                  f\"Total Objects: {num_total_objects_this_image} | \"\n",
    "                  f\"Valid Objects: {num_valid_objects_this_image} | \"\n",
    "                  f\"Backgrounds Extracted: {extracted_for_this_image}\")\n",
    "            total_bg_extracted_all_images += extracted_for_this_image\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"  Error: Image file not found at {img_path}, skipping.\")\n",
    "        except UnidentifiedImageError:\n",
    "             print(f\"  Error: Cannot identify image file (corrupt or unsupported format): {img_filename}. Skipping.\")\n",
    "        except Image.DecompressionBombError:\n",
    "             print(f\"  Error: Image {img_filename} is too large or corrupt (DecompressionBombError). Skipping.\")\n",
    "             print(\"  Consider uncommenting 'Image.MAX_IMAGE_PIXELS = None' if needed, but be cautious.\")\n",
    "        except Exception as img_err:\n",
    "            print(f\"  Error processing image {img_filename} or its JSON: {img_err}\")\n",
    "\n",
    "    # --- Final Summary & Saving Stats ---\n",
    "    print(f\"\\n--- Finished Processing All Images ---\")\n",
    "    print(f\"Processed {processed_image_count} images with labels found.\")\n",
    "    print(f\"Total background patches extracted across all images: {total_bg_extracted_all_images}\")\n",
    "    \n",
    "    summary_stats = {}\n",
    "    if global_stats.get(\"object_widths\"): # Check if any valid objects were found\n",
    "        try:\n",
    "            print(\"\\nCalculating final summary statistics for valid objects...\")\n",
    "            # (Calculation logic remains the same as v3)\n",
    "            stats_keys = [\"num_valid_objects_per_image\", \"object_widths\", \"object_heights\", \"object_aspect_ratios\", \"object_centers_x\", \"object_centers_y\"]\n",
    "            for key in stats_keys:\n",
    "                data_list = global_stats.get(key, []) \n",
    "                if data_list: \n",
    "                    data_array = np.array(data_list)\n",
    "                    summary_stats[key] = {\n",
    "                        'mean': float(np.mean(data_array)),\n",
    "                        'std': float(np.std(data_array)),\n",
    "                        'min': float(np.min(data_array)),\n",
    "                        'max': float(np.max(data_array)),\n",
    "                        'median': float(np.median(data_array)),\n",
    "                        'count': len(data_array)\n",
    "                    }\n",
    "                else:\n",
    "                    summary_stats[key] = {'count': 0}\n",
    "            \n",
    "            # Truncate raw data for saving\n",
    "            raw_data_truncated = {}\n",
    "            for k, v in global_stats.items():\n",
    "                 if k not in [\"image_filenames\", \"object_labels\"]:\n",
    "                      raw_data_truncated[k] = v[:min(len(v), 10000)] \n",
    "\n",
    "            stats_to_save = {\n",
    "                 \"parameters_used\": { \n",
    "                     \"slice_size\": slice_size, \"step_size\": step_size, \"margin_pixels\": margin_pixels,\n",
    "                     \"black_threshold\": black_threshold, \"black_slice_percentage_threshold\": black_slice_percentage_threshold\n",
    "                 },\n",
    "                \"summary\": summary_stats,\n",
    "                \"raw_data_truncated\": raw_data_truncated,\n",
    "                 \"image_count_processed\": processed_image_count,\n",
    "                 \"total_valid_objects_found\": summary_stats.get(\"object_widths\", {}).get(\"count\", 0),\n",
    "                 \"total_background_patches_extracted\": total_bg_extracted_all_images\n",
    "            }\n",
    "\n",
    "            # Save layout statistics to JSON file\n",
    "            with open(output_stats_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(stats_to_save, f, indent=4, default=float) \n",
    "            print(f\"Layout statistics saved to {output_stats_file}\")\n",
    "\n",
    "            # Generate Plots (optional)\n",
    "            if generate_plots:\n",
    "                 save_analysis_plots(global_stats, output_path, max_img_w, max_img_h) \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating or saving final statistics: {e}\")\n",
    "    else:\n",
    "        print(\"No valid object data found across all images to calculate statistics.\")\n",
    "\n",
    "    print(\"--- Script Finished ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- User Configuration Section ---\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Define input and output paths \n",
    "#    (Use raw strings r'...' or double backslashes '\\\\' for Windows paths)\n",
    "#    Input path should contain both large image files and corresponding .json LabelMe files.\n",
    "input_path = r\"C:\\Users\\praam\\Desktop\\havetai+vetcyto\\task-04_dataset\\50_pc_expanded_automated_labels_with_aligned_HM_images_T\"\n",
    "output_path = r\"C:\\Users\\praam\\Desktop\\havetai+vetcyto\\task-05_dataset\\backgrounds_layouts_automated_labels_pc_150\"\n",
    "\n",
    "# 2. Define Slicing Parameters\n",
    "slice_size = 640       # Pixel dimension of the square slices/background patches to extract\n",
    "\n",
    "# --- MODIFIED: Step size for moving the slicing window ---\n",
    "# Set to 10 for maximum overlap search (WILL BE VERY SLOW!). \n",
    "# Consider increasing (e.g., 64, 128, 320) for faster processing if needed.\n",
    "step_size = 320         \n",
    "\n",
    "margin_pixels = 15     # Safety margin added around valid object bounding boxes. \n",
    "                       # Slices overlapping this margin area won't be saved as background.\n",
    "\n",
    "# 3. Define Black Area Detection Parameters\n",
    "# Pixel value <= this is considered 'black'. User found '1' optimal.\n",
    "black_threshold = 1    \n",
    "\n",
    "# --- MODIFIED: Discard slice if % of black pixels EXCEEDS this threshold ---\n",
    "# Set to 1.0 for maximum cleanliness (discard if > 1% black pixels).\n",
    "black_slice_percentage_threshold = 1.0 \n",
    "\n",
    "# 4. Optional Plotting\n",
    "# Set to True to generate and save plots visualizing the layout statistics.\n",
    "generate_plots = True  \n",
    "\n",
    "# ==============================================================================\n",
    "# --- Script Execution ---\n",
    "# ==============================================================================\n",
    "\n",
    "print(f\"--- Configuration ---\")\n",
    "print(f\"Input Path: {input_path}\")\n",
    "print(f\"Output Path: {output_path}\")\n",
    "print(f\"Slice Size: {slice_size}\")\n",
    "print(f\"Step Size: {step_size} (Note: Small step size significantly increases runtime!)\")\n",
    "print(f\"Margin Pixels: {margin_pixels}\")\n",
    "print(f\"Black Threshold: <= {black_threshold}\")\n",
    "print(f\"Black Slice Discard %: > {black_slice_percentage_threshold}%\")\n",
    "print(f\"Generate Plots: {generate_plots}\")\n",
    "print(f\"---------------------\\n\")\n",
    "\n",
    "# Run the main processing function with the configured parameters\n",
    "# Ensure all helper functions are defined in previous cells or above this call\n",
    "process_large_images_for_backgrounds(\n",
    "    input_path=input_path, \n",
    "    output_path=output_path,\n",
    "    slice_size=slice_size,\n",
    "    step_size=step_size,\n",
    "    margin_pixels=margin_pixels,\n",
    "    black_threshold=black_threshold, # Used for both object check & slice check\n",
    "    black_slice_percentage_threshold=black_slice_percentage_threshold,\n",
    "    generate_plots=generate_plots\n",
    ")\n",
    "\n",
    "# Check the 'output_path' for 'backgrounds' and 'statistics' folders after execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86aab3-f0ee-490a-854c-db680cf2dabf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
