{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New 02 - Task 01 - VetCyto - MOBILENETv3L - Training Code (Automatically Labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alternative code 03 ~ the pytorch version of the original tensorflow code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "\n",
    "def get_device_config():\n",
    "    \"\"\"\n",
    "    Detect and configure device settings based on available hardware\n",
    "    Returns tuple of (device, batch_size, image_size, device_info)\n",
    "    \"\"\"\n",
    "    device_info = {}\n",
    "    \n",
    "    # Check if CUDA is available\n",
    "    if not torch.cuda.is_available():\n",
    "        device_info = {\n",
    "            \"device_name\": \"CPU\",\n",
    "            \"memory\": \"N/A\",\n",
    "            \"reason\": \"No GPU detected by PyTorch\"\n",
    "        }\n",
    "        print(\"\\nâŒ ERROR: No GPU detected by PyTorch. This script requires a GPU to run.\")\n",
    "        print(\"ðŸ“‹ Debugging information:\")\n",
    "        print(\"  - PyTorch version:\", torch.__version__)\n",
    "        print(\"  - CUDA available:\", torch.cuda.is_available())\n",
    "        print(\"  - Python version:\", sys.version)\n",
    "        \n",
    "        # Try to run nvidia-smi as a fallback detection method\n",
    "        try:\n",
    "            result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "            print(\"\\nðŸ“Š NVIDIA-SMI Output:\")\n",
    "            print(result.stdout)\n",
    "            if result.stderr:\n",
    "                print(\"NVIDIA-SMI Error:\", result.stderr)\n",
    "                \n",
    "            print(\"\\nðŸ’¡ Possible issues:\")\n",
    "            print(\"  - NVIDIA drivers not installed or outdated\")\n",
    "            print(\"  - CUDA/cuDNN not installed or not compatible with PyTorch\")\n",
    "            print(\"  - PyTorch not built with GPU support\")\n",
    "            print(\"\\nðŸ“ Recommendation: Verify GPU installation with 'nvidia-smi' command and ensure PyTorch is properly installed with GPU support\")\n",
    "        except:\n",
    "            print(\"\\nFailed to run nvidia-smi. NVIDIA drivers may not be installed.\")\n",
    "        \n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Get GPU information\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    \n",
    "    # Try to get GPU memory info\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'], \n",
    "                               stdout=subprocess.PIPE, text=True, check=True)\n",
    "        gpu_info = result.stdout.strip().split(',')\n",
    "        gpu_name = gpu_info[0].strip()\n",
    "        gpu_memory = float(gpu_info[1].strip()) / 1024  # Convert MB to GB\n",
    "    except:\n",
    "        # Fallback if nvidia-smi fails\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # Convert bytes to GB\n",
    "        if not gpu_memory:\n",
    "            gpu_memory = 6.0  # Assume 6GB for RTX 3060 based on previous info\n",
    "    \n",
    "    device_info = {\n",
    "        \"device_name\": gpu_name,\n",
    "        \"gpu_memory\": f\"{gpu_memory:.2f} GB\",\n",
    "        \"pytorch_version\": torch.__version__,\n",
    "        \"cuda_version\": torch.version.cuda if hasattr(torch.version, 'cuda') else \"N/A\"\n",
    "    }\n",
    "    \n",
    "    # Set fixed image size of 112x112 as requested\n",
    "    # Only batch size is adjusted based on GPU memory\n",
    "    if gpu_memory >= 8:\n",
    "        batch_size = 32\n",
    "    elif gpu_memory >= 6:  # RTX 3060 with 6GB\n",
    "        batch_size = 24\n",
    "    elif gpu_memory >= 4:\n",
    "        batch_size = 16\n",
    "    else:\n",
    "        batch_size = 8\n",
    "    \n",
    "    # Fixed image size of 112x112 as requested\n",
    "    image_size = 112\n",
    "    \n",
    "    return \"cuda\", batch_size, image_size, device_info\n",
    "\n",
    "def compute_class_weights(directory):\n",
    "    \"\"\"Automatically compute class weights based on class distribution\"\"\"\n",
    "    class_counts = {}\n",
    "    class_dirs = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "    \n",
    "    for class_name in class_dirs:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        class_counts[class_name] = len([f for f in os.listdir(class_dir) \n",
    "                                       if os.path.isfile(os.path.join(class_dir, f))])\n",
    "    \n",
    "    # Convert to format needed for compute_class_weight\n",
    "    class_labels = []\n",
    "    counts = []\n",
    "    for i, (class_name, count) in enumerate(class_counts.items()):\n",
    "        class_labels.extend([i] * count)\n",
    "        counts.append(count)\n",
    "    \n",
    "    # Compute class weights using sklearn\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(class_labels),\n",
    "        y=class_labels\n",
    "    )\n",
    "    \n",
    "    # Create dictionary mapping class indices to weights\n",
    "    class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "    \n",
    "    print(\"Class distribution:\", class_counts)\n",
    "    print(\"Computed class weights:\", class_weight_dict)\n",
    "    \n",
    "    # Convert to PyTorch tensor for loss function\n",
    "    weights_tensor = torch.FloatTensor(list(class_weight_dict.values()))\n",
    "    \n",
    "    return class_weight_dict, weights_tensor\n",
    "\n",
    "def create_dataset(train_folder, val_folder, test_folder, image_size=(112, 112), batch_size=32):\n",
    "    \"\"\"\n",
    "    Create PyTorch DataLoaders for training, validation, and test datasets\n",
    "    Fixed image size of 112x112 pixels as requested\n",
    "    \"\"\"\n",
    "    # Training transforms with augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.RandomRotation(40),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Validation and test transforms (no augmentation)\n",
    "    basic_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = datasets.ImageFolder(root=train_folder, transform=train_transform)\n",
    "    val_dataset = datasets.ImageFolder(root=val_folder, transform=basic_transform)\n",
    "    test_dataset = datasets.ImageFolder(root=test_folder, transform=basic_transform)\n",
    "    \n",
    "    # Create additional augmentation in model\n",
    "    augmentation_layers = nn.Sequential(\n",
    "        # These are handled by transforms above, kept for structure similarity\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_dataset.classes, augmentation_layers\n",
    "\n",
    "def build_model(input_shape=(112, 112, 3), num_classes=4):\n",
    "    \"\"\"\n",
    "    Build MobileNetV3Large model with custom classifier for PyTorch\n",
    "    Fixed input shape of 112x112x3 as requested\n",
    "    \"\"\"\n",
    "    # Load pretrained model with weights parameter instead of deprecated pretrained\n",
    "    model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
    "    \n",
    "    # Freeze the pretrained weights\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Rebuild top with BatchNorm and increased dropout\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.BatchNorm1d(960),\n",
    "        nn.Dropout(p=0.5),  # Increased dropout rate\n",
    "        nn.Linear(960, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def plot_hist(train_hist, val_hist, metric=\"accuracy\", save_path=None):\n",
    "    \"\"\"\n",
    "    Plot training and validation history, save to disk and display\n",
    "    \n",
    "    Parameters:\n",
    "    train_hist, val_hist (dict): Training and validation history\n",
    "    metric (str): Metric to plot (accuracy, loss, etc.)\n",
    "    save_path (str): Directory to save the plot\n",
    "    \"\"\"\n",
    "    # Skip creating a separate loss vs loss plot\n",
    "    if metric == \"loss\":\n",
    "        return\n",
    "        \n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot loss (left side)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_hist['loss'])\n",
    "    plt.plot(val_hist['loss'])\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "\n",
    "    # Plot other metric (right side)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_hist[metric])\n",
    "    plt.plot(val_hist[metric])\n",
    "    plt.title(f\"Model {metric.capitalize()}\")\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot if save_path is provided\n",
    "    if save_path:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = os.path.join(save_path, f\"training_history_loss_vs_{metric}_{timestamp}.png\")\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved training history plot to: {filename}\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix using seaborn, save to disk and display\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: Ground truth labels\n",
    "    y_pred: Predicted labels\n",
    "    class_names: List of class names\n",
    "    save_path (str): Directory to save the plot\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    \n",
    "    # Save the plot if save_path is provided\n",
    "    if save_path:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = os.path.join(save_path, f\"confusion_matrix_{timestamp}.png\")\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved confusion matrix to: {filename}\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    \"\"\"\n",
    "    Unfreeze the last 20 layers of the model for fine-tuning\n",
    "    \"\"\"\n",
    "    # Get all feature modules\n",
    "    features = list(model.features.named_children())\n",
    "    \n",
    "    # Unfreeze the last 20 layers\n",
    "    for i, (name, layer) in enumerate(features):\n",
    "        if i >= len(features) - 20:\n",
    "            if not isinstance(layer, nn.BatchNorm2d):\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "    \n",
    "    # Classifier is already unfrozen\n",
    "\n",
    "def calculate_f1(precision, recall):\n",
    "    \"\"\"Calculate F1 score from precision and recall\"\"\"\n",
    "    return 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, class_weights=None, steps_per_epoch=None):\n",
    "    \"\"\"\n",
    "    Train for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    # Limit batches if steps_per_epoch is specified\n",
    "    batch_count = 0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        if steps_per_epoch is not None and batch_count >= steps_per_epoch:\n",
    "            break\n",
    "            \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        \n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        batch_count += 1\n",
    "    \n",
    "    # Calculate statistics\n",
    "    if total == 0:  # Avoid division by zero\n",
    "        return {\n",
    "            'loss': 0,\n",
    "            'accuracy': 0,\n",
    "            'precision': 0,\n",
    "            'recall': 0,\n",
    "            'f1': 0\n",
    "        }\n",
    "        \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_accuracy = correct / total\n",
    "    \n",
    "    # Compute precision and recall\n",
    "    from sklearn.metrics import precision_score, recall_score\n",
    "    epoch_precision = precision_score(all_targets, all_predictions, average='weighted', zero_division=0)\n",
    "    epoch_recall = recall_score(all_targets, all_predictions, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    epoch_f1 = calculate_f1(epoch_precision, epoch_recall)\n",
    "    \n",
    "    return {\n",
    "        'loss': epoch_loss,\n",
    "        'accuracy': epoch_accuracy,\n",
    "        'precision': epoch_precision,\n",
    "        'recall': epoch_recall,\n",
    "        'f1': epoch_f1\n",
    "    }\n",
    "\n",
    "def validate(model, val_loader, criterion, device, steps=None):\n",
    "    \"\"\"\n",
    "    Validate the model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    # Limit batches if steps is specified\n",
    "    batch_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            if steps is not None and batch_count >= steps:\n",
    "                break\n",
    "                \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            \n",
    "            batch_count += 1\n",
    "    \n",
    "    # Calculate statistics\n",
    "    if total == 0:  # Avoid division by zero\n",
    "        return {\n",
    "            'loss': 0,\n",
    "            'accuracy': 0,\n",
    "            'precision': 0,\n",
    "            'recall': 0,\n",
    "            'f1': 0\n",
    "        }\n",
    "        \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_accuracy = correct / total\n",
    "    \n",
    "    # Compute precision and recall\n",
    "    from sklearn.metrics import precision_score, recall_score\n",
    "    epoch_precision = precision_score(all_targets, all_predictions, average='weighted', zero_division=0)\n",
    "    epoch_recall = recall_score(all_targets, all_predictions, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    epoch_f1 = calculate_f1(epoch_precision, epoch_recall)\n",
    "    \n",
    "    return {\n",
    "        'loss': epoch_loss,\n",
    "        'accuracy': epoch_accuracy,\n",
    "        'precision': epoch_precision,\n",
    "        'recall': epoch_recall,\n",
    "        'f1': epoch_f1,\n",
    "        'predictions': all_predictions,\n",
    "        'targets': all_targets\n",
    "    }\n",
    "\n",
    "def train_and_evaluate(train_folder, val_folder, test_folder, save_path=None, batch_size=32, \n",
    "                      image_size=(112, 112), nbs=None):\n",
    "    \"\"\"\n",
    "    Train and evaluate the model\n",
    "    \"\"\"\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create datasets and loaders\n",
    "    train_loader, val_loader, test_loader, class_names, augmentation_layers = create_dataset(\n",
    "        train_folder, val_folder, test_folder, image_size=image_size, batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    # Calculate validation steps if nbs is provided\n",
    "    steps_per_epoch = nbs\n",
    "    validation_steps = nbs // 2 if nbs is not None else None\n",
    "    \n",
    "    # Compute class weights for balanced training\n",
    "    class_weight_dict, class_weights_tensor = compute_class_weights(train_folder)\n",
    "    class_weights_tensor = class_weights_tensor.to(device)\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model(input_shape=(*image_size, 3), num_classes=len(class_names))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function with class weights\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    \n",
    "    # Define optimizer with weight decay (AdamW equivalent)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "    \n",
    "    # Learning rate scheduler (equivalent to ReduceLROnPlateau)\n",
    "    # Removed verbose parameter to avoid deprecation warning\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    # Initialize history dictionaries\n",
    "    train_hist = {'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    val_hist = {'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    \n",
    "    # Set up for early stopping and checkpointing\n",
    "    checkpoint_path_temp = os.path.join(save_path, \"temporary_checkpoint.pt\")\n",
    "    best_val_accuracy = 0\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    # First training phase\n",
    "    print(\"\\n=== Initial Training Phase ===\")\n",
    "    epochs = 30\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        train_metrics = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, \n",
    "            class_weights=class_weights_tensor, \n",
    "            steps_per_epoch=steps_per_epoch\n",
    "        )\n",
    "        \n",
    "        # Validation phase\n",
    "        val_metrics = validate(model, val_loader, criterion, device, steps=validation_steps)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(val_metrics['loss'])\n",
    "        \n",
    "        # Update history\n",
    "        for metric in ['loss', 'accuracy', 'precision', 'recall', 'f1']:\n",
    "            train_hist[metric].append(train_metrics[metric])\n",
    "            val_hist[metric].append(val_metrics[metric])\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
    "              f\"Train Loss: {train_metrics['loss']:.4f}, Train Acc: {train_metrics['accuracy']:.4f}, \"\n",
    "              f\"Val Loss: {val_metrics['loss']:.4f}, Val Acc: {val_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_metrics['accuracy'] > best_val_accuracy:\n",
    "            best_val_accuracy = val_metrics['accuracy']\n",
    "            torch.save(model.state_dict(), checkpoint_path_temp)\n",
    "            print(f\"    Saving model with validation accuracy: {best_val_accuracy:.4f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_metrics['loss'] < best_val_loss:\n",
    "            best_val_loss = val_metrics['loss']\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    print(\"Phase 1 Training completed\")\n",
    "    print(\"Best val accuracy:\", best_val_accuracy)\n",
    "    \n",
    "    # Save initial histories\n",
    "    frozen_train_hist = train_hist.copy()\n",
    "    frozen_val_hist = val_hist.copy()\n",
    "    \n",
    "    # Load best model from phase 1 (using weights_only=True to avoid warning)\n",
    "    model.load_state_dict(torch.load(checkpoint_path_temp, weights_only=True))\n",
    "    \n",
    "    # Reset histories for phase 2\n",
    "    train_hist = {'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    val_hist = {'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    \n",
    "    # Unfreeze some layers and continue training\n",
    "    print(\"\\n=== Fine-tuning Phase ===\")\n",
    "    unfreeze_model(model)\n",
    "    \n",
    "    # New optimizer with lower learning rate\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
    "    # Removed verbose parameter to avoid deprecation warning\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    # Reset early stopping variables\n",
    "    best_val_accuracy_unfrozen = best_val_accuracy\n",
    "    patience_counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    # Second training phase\n",
    "    epochs_unfreeze = 30\n",
    "    \n",
    "    for epoch in range(epochs_unfreeze):\n",
    "        # Training phase\n",
    "        train_metrics = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, \n",
    "            class_weights=class_weights_tensor, \n",
    "            steps_per_epoch=steps_per_epoch\n",
    "        )\n",
    "        \n",
    "        # Validation phase\n",
    "        val_metrics = validate(model, val_loader, criterion, device, steps=validation_steps)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(val_metrics['loss'])\n",
    "        \n",
    "        # Update history\n",
    "        for metric in ['loss', 'accuracy', 'precision', 'recall']:\n",
    "            train_hist[metric].append(train_metrics[metric])\n",
    "            val_hist[metric].append(val_metrics[metric])\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs_unfreeze}, \"\n",
    "              f\"Train Loss: {train_metrics['loss']:.4f}, Train Acc: {train_metrics['accuracy']:.4f}, \"\n",
    "              f\"Val Loss: {val_metrics['loss']:.4f}, Val Acc: {val_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_metrics['accuracy'] > best_val_accuracy_unfrozen:\n",
    "            best_val_accuracy_unfrozen = val_metrics['accuracy']\n",
    "            torch.save(model.state_dict(), checkpoint_path_temp)\n",
    "            print(f\"    Saving model with validation accuracy: {best_val_accuracy_unfrozen:.4f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_metrics['loss'] < best_val_loss:\n",
    "            best_val_loss = val_metrics['loss']\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    print(\"Phase 2 Training completed\")\n",
    "    print(\"Best val accuracy (unfrozen):\", best_val_accuracy_unfrozen)\n",
    "    \n",
    "    # Find overall best model\n",
    "    all_val_accuracies = frozen_val_hist['accuracy'] + val_hist['accuracy']\n",
    "    max_val_accuracy = max(all_val_accuracies)\n",
    "    epoch_with_max_val_accuracy = all_val_accuracies.index(max_val_accuracy) + 1\n",
    "    \n",
    "    # Rename model file with \"best_model\" in filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    checkpoint_name = f\"best_model_MobileNet_epoch{epoch_with_max_val_accuracy}_acc{int(max_val_accuracy * 100)}_{timestamp}.pt\"\n",
    "    final_checkpoint_path = os.path.join(save_path, checkpoint_name)\n",
    "    os.rename(checkpoint_path_temp, final_checkpoint_path)\n",
    "    \n",
    "    print(f\"\\nBest model: Epoch {epoch_with_max_val_accuracy} with validation accuracy {max_val_accuracy:.4f}\")\n",
    "    print(f\"Saved best model to: {final_checkpoint_path}\")\n",
    "    \n",
    "    # Load best model (using weights_only=True to avoid warning)\n",
    "    model.load_state_dict(torch.load(final_checkpoint_path, weights_only=True))\n",
    "    \n",
    "    # Plot and save training history (combine phase 1 and phase 2)\n",
    "    combined_train_hist = {\n",
    "        'loss': frozen_train_hist['loss'] + train_hist['loss'],\n",
    "        'accuracy': frozen_train_hist['accuracy'] + train_hist['accuracy'],\n",
    "        'precision': frozen_train_hist['precision'] + train_hist['precision'],\n",
    "        'recall': frozen_train_hist['recall'] + train_hist['recall'],\n",
    "        'f1': frozen_train_hist['f1'] + train_hist['f1']\n",
    "    }\n",
    "    \n",
    "    combined_val_hist = {\n",
    "        'loss': frozen_val_hist['loss'] + val_hist['loss'],\n",
    "        'accuracy': frozen_val_hist['accuracy'] + val_hist['accuracy'],\n",
    "        'precision': frozen_val_hist['precision'] + val_hist['precision'],\n",
    "        'recall': frozen_val_hist['recall'] + val_hist['recall'],\n",
    "        'f1': frozen_val_hist['f1'] + val_hist['f1']\n",
    "    }\n",
    "    \n",
    "    # Save training history plots\n",
    "    plot_hist(combined_train_hist, combined_val_hist, metric=\"accuracy\", save_path=save_path)\n",
    "    plot_hist(combined_train_hist, combined_val_hist, metric=\"precision\", save_path=save_path)\n",
    "    plot_hist(combined_train_hist, combined_val_hist, metric=\"recall\", save_path=save_path)\n",
    "    plot_hist(combined_train_hist, combined_val_hist, metric=\"f1\", save_path=save_path)\n",
    "    # Not creating a loss vs loss plot as requested\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\n=== Test Set Evaluation ===\")\n",
    "    test_metrics = validate(model, test_loader, criterion, device)\n",
    "    \n",
    "    test_loss = test_metrics['loss']\n",
    "    test_accuracy = test_metrics['accuracy']\n",
    "    test_precision = test_metrics['precision']\n",
    "    test_recall = test_metrics['recall']\n",
    "    test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall + 1e-10)\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "    \n",
    "    # Generate class report and additional metrics\n",
    "    y_true = test_metrics['targets']\n",
    "    y_pred = test_metrics['predictions']\n",
    "    \n",
    "    # Calculate balanced accuracy\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "    \n",
    "    # Per-class F1 scores\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"F1 Score for class {class_name}: {f1_per_class[i]:.4f}\")\n",
    "    \n",
    "    # Full classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "    print(report)\n",
    "    \n",
    "    # Save classification report to file\n",
    "    report_path = os.path.join(save_path, f\"classification_report_{timestamp}.txt\")\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(f\"Test Loss: {test_loss:.4f}\\n\")\n",
    "        f.write(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "        f.write(f\"Test Precision: {test_precision:.4f}\\n\")\n",
    "        f.write(f\"Test Recall: {test_recall:.4f}\\n\")\n",
    "        f.write(f\"Test F1 Score: {test_f1:.4f}\\n\")\n",
    "        f.write(f\"Balanced Accuracy: {balanced_acc:.4f}\\n\\n\")\n",
    "        f.write(\"Per-class F1 Scores:\\n\")\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            f.write(f\"F1 Score for class {class_name}: {f1_per_class[i]:.4f}\\n\")\n",
    "        f.write(\"\\nClassification Report:\\n\")\n",
    "        f.write(report)\n",
    "    \n",
    "    print(f\"Saved classification report to: {report_path}\")\n",
    "    \n",
    "    # Plot and save confusion matrix\n",
    "    plot_confusion_matrix(y_true, y_pred, class_names, save_path=save_path)\n",
    "    \n",
    "    # Save final (last) model with descriptive name\n",
    "    final_model_path = os.path.join(save_path, f\"last_model_acc{int(test_accuracy * 100)}_{timestamp}.pt\")\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"Saved last model to: {final_model_path}\")\n",
    "    \n",
    "    # Save model in torchscript format for deployment\n",
    "    # Commented out as requested - not needed for current use case\n",
    "    # try:\n",
    "    #     model.eval()\n",
    "    #     scripted_model = torch.jit.script(model)\n",
    "    #     script_path = os.path.join(save_path, f\"model_scripted_{timestamp}.pt\")\n",
    "    #     scripted_model.save(script_path)\n",
    "    #     print(f\"Saved TorchScript model to: {script_path}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Failed to save TorchScript model: {e}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def recommended_nbs(dataset_size, batch_size):\n",
    "    \"\"\"Recommend number of batches per epoch based on dataset size and batch size\"\"\"\n",
    "    # Calculate total number of batches in dataset\n",
    "    total_batches = dataset_size // batch_size\n",
    "    \n",
    "    # For small datasets, use all batches\n",
    "    if total_batches < 100:\n",
    "        return None  # Use all batches\n",
    "    \n",
    "    # For larger datasets, limit to avoid memory issues\n",
    "    return min(total_batches, 200)  # Cap at 200 batches per epoch\n",
    "\n",
    "# Main execution block - moved closer to the end as requested\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration flag to enable/disable user input prompts (default: False)\n",
    "    ENABLE_USER_INPUT = False\n",
    "    \n",
    "    # notes : automated annotations ~ 100% ;\n",
    "    # example 02 A : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_automated-labels_T_640_100-pc\\\\' ~ train/val/test ; \n",
    "    # example 02 B : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\outputMOBILENETv3L_AutomatedAnnotation_100-pc' ;\n",
    "    # notes : automated annotations ~ 125% ;\n",
    "    # example 04 A : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_automated-labels_T_640_125-pc\\\\' ~ train/val/test ; \n",
    "    # example 04 B : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\outputMOBILENETv3L_AutomatedAnnotation_125-pc' ;\n",
    "    # notes : automated annotations ~ 150% ;\n",
    "    # example 06 A : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_automated-labels_T_640_150-pc\\\\' ~ train/val/test ; \n",
    "    # example 06 B : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\outputMOBILENETv3L_AutomatedAnnotation_150-pc' ;\n",
    "    \n",
    "    # default : 'C:/Users/karli/Desktop/vet_images_sliced_split(training)/train' ; \n",
    "    # alt : 'E:\\\\-_EDI_-\\\\notes\\\\havetai+vetcyto\\\\vet_images_sliced_split\\\\train' ;\n",
    "    train_folder = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_automated-labels_T_640_150-pc\\\\train' \n",
    "    # default : 'C:/Users/karli/Desktop/vet_images_sliced_split(training)/val' ; \n",
    "    # alt : 'E:\\\\-_EDI_-\\\\notes\\\\havetai+vetcyto\\\\vet_images_sliced_split\\\\val' ;\n",
    "    val_folder = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_automated-labels_T_640_150-pc\\\\val'      \n",
    "    # default : 'C:/Users/karli/Desktop/vet_images_sliced_split(training)/test' ; \n",
    "    # alt : 'E:\\\\-_EDI_-\\\\notes\\\\havetai+vetcyto\\\\vet_images_sliced_split\\\\test' ;\n",
    "    test_folder = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\vet_images_sliced_split\\\\TrainingStepSet_automated-labels_T_640_150-pc\\\\test'    \n",
    "    # default : 'C:/Users/karli/Desktop/outputMobile' ; \n",
    "    # alt : 'E:\\\\-_EDI_-\\\\notes\\\\havetai+vetcyto\\\\outputMOBILENETv3L' ;\n",
    "    save_model_path = 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th-setup_task-04_new-work-03\\\\outputMOBILENETv3L_AutomatedAnnotation_150-pc'\n",
    "    \n",
    "    # Check if save path exists, if not create it\n",
    "    if not os.path.exists(save_model_path):\n",
    "        os.makedirs(save_model_path)\n",
    "        print(f\"Created output directory: {save_model_path}\")\n",
    "    \n",
    "    # Detect device and get optimal configuration\n",
    "    device, auto_batch_size, auto_image_size, device_info = get_device_config()\n",
    "    \n",
    "    print(\"\\n=== Hardware Configuration ===\")\n",
    "    for key, value in device_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Count total dataset size\n",
    "    dataset_size = 0\n",
    "    for class_name in os.listdir(train_folder):\n",
    "        class_dir = os.path.join(train_folder, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            dataset_size += len([f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))])\n",
    "    \n",
    "    # Calculate optimal parameters\n",
    "    nbs = recommended_nbs(dataset_size, auto_batch_size)\n",
    "    \n",
    "    print(f\"\\n=== Dataset Information ===\")\n",
    "    print(f\"Dataset size: {dataset_size} images\")\n",
    "    print(f\"Optimal configuration for your GPU:\")\n",
    "    print(f\"  - Batch size: {auto_batch_size}\")\n",
    "    print(f\"  - Image size: 112x112 (fixed)\")\n",
    "    print(f\"  - Batches per epoch: {nbs if nbs else 'All'}\")\n",
    "    \n",
    "    # Allow user to override batch size and number of batches if enabled\n",
    "    if ENABLE_USER_INPUT:\n",
    "        user_batch = input(f\"\\nEnter batch size (optimal: {auto_batch_size}, press Enter to use optimal): \")\n",
    "        batch_size = int(user_batch) if user_batch.strip() else auto_batch_size\n",
    "        \n",
    "        user_nbs = input(f\"Enter number of batches per epoch (optimal: {nbs if nbs else 'All'}, press Enter to use optimal): \")\n",
    "        if user_nbs.strip() and user_nbs.lower() != \"all\":\n",
    "            nbs = int(user_nbs)\n",
    "        elif user_nbs.lower() == \"all\":\n",
    "            nbs = None\n",
    "    else:\n",
    "        # Use optimal values without prompting\n",
    "        batch_size = auto_batch_size\n",
    "    \n",
    "    # Fixed image size of 112x112 as requested (not adjustable)\n",
    "    image_size = 112\n",
    "    \n",
    "    print(f\"\\n=== Training Configuration ===\")\n",
    "    print(f\"Using batch size: {batch_size}\")\n",
    "    print(f\"Using image size: 112x112 (fixed)\")\n",
    "    print(f\"Using batches per epoch: {nbs if nbs else 'All'}\")\n",
    "    \n",
    "    # Save configuration for reproducibility\n",
    "    config = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"device_info\": device_info,\n",
    "        \"dataset_size\": dataset_size,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"image_size\": image_size,\n",
    "        \"batches_per_epoch\": nbs if nbs else \"All\",\n",
    "        \"train_folder\": train_folder,\n",
    "        \"val_folder\": val_folder,\n",
    "        \"test_folder\": test_folder,\n",
    "        \"save_path\": save_model_path\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_model_path, \"training_config.json\"), \"w\") as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    print(\"\\n=== Starting Training ===\")\n",
    "    # Clear GPU memory before training\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    model = train_and_evaluate(\n",
    "        train_folder, \n",
    "        val_folder, \n",
    "        test_folder, \n",
    "        save_path=save_model_path, \n",
    "        batch_size=batch_size, \n",
    "        image_size=(image_size, image_size),\n",
    "        nbs=nbs\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== Training Complete ===\")\n",
    "    print(f\"Model and training logs saved to: {save_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
