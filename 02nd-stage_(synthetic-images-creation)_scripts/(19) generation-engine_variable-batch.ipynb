{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bea159c-7c0f-4b3d-bc53-2975f3315a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"generation-engine_XYZ[dot]ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40c846-a5ae-4192-9d54-614f70930078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"generation-engine_XYZ[dot]ipynb\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Generation Engine for Synthetic Pollen Image Generation\n",
    "Script: generation-engine_00.py\n",
    "\n",
    "This enhanced script generates synthetic pollen images by:\n",
    "1. Loading the trained WGAN-SN generator and critic models\n",
    "2. Applying quality filtering using the critic to keep only high-quality samples\n",
    "3. Generating synthetic pollen images (base 128x128) with controlled augmentations\n",
    "4. Optionally placing these images on background patches (640x640) with advanced blending\n",
    "5. Creating YOLO annotation files for object detection\n",
    "6. Analyzing and visualizing the generation results\n",
    "7. Creating comprehensive reports with statistics\n",
    "\n",
    "Improvements over the original composition-engine:\n",
    "- GAN quality filtering using the critic to remove low-quality samples\n",
    "- Advanced blending methods (Poisson, Pyramid)\n",
    "- Fixed geometric transformations (proper scaling without dimension reset)\n",
    "- Dataset statistics matching for realistic distributions\n",
    "- Conditional pipeline execution via boolean flags\n",
    "- Memory management for model loading\n",
    "- Configuration saving and loading\n",
    "- Enhanced reporting and visualization\n",
    "- Parallelized processing with memory management\n",
    "\"\"\"\n",
    "\n",
    "print(\"!!! setting the 'TF_ENABLE_ONEDNN_OPTS' value to '0' for avoiding the 'oneDNN custom operations' message in powershell console !!!\")\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "import gc\n",
    "import traceback\n",
    "import psutil\n",
    "import threading\n",
    "import warnings\n",
    "import pickle\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageOps\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from multiprocessing import Pool, Manager, Queue, cpu_count as mp_cpu_count\n",
    "\n",
    "# --- Add these imports ---\n",
    "import torch.nn.functional as F\n",
    "#from math import ceil # made redundant\n",
    "\n",
    "# --- Import components for feature extraction and evaluation ---\n",
    "try:\n",
    "    from pytorch_fid.inception import InceptionV3\n",
    "    from pytorch_fid.fid_score import calculate_frechet_distance # Keep if FID/KID needed\n",
    "    FID_AVAILABLE = True\n",
    "    print(\"Successfully imported pytorch_fid components.\")\n",
    "except ImportError:\n",
    "    print(\"WARNING: pytorch-fid not found. Feature extraction and FID/KID/PRDC analysis will be disabled.\")\n",
    "    FID_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    NEIGHBORS_AVAILABLE = True\n",
    "    print(\"Successfully imported NearestNeighbors for PRDC.\")\n",
    "except ImportError:\n",
    "    print(\"WARNING: scikit-learn NearestNeighbors not found. Custom P/R/D/C will be disabled.\")\n",
    "    NEIGHBORS_AVAILABLE = False\n",
    "\n",
    "# Optional torch-fidelity import\n",
    "try:\n",
    "    import torch_fidelity\n",
    "    TORCH_FIDELITY_AVAILABLE = True\n",
    "    print(\"Successfully imported torch-fidelity.\")\n",
    "except ImportError:\n",
    "    print(\"INFO: torch-fidelity not found. Will use custom P/R/D/C implementation if available.\")\n",
    "    TORCH_FIDELITY_AVAILABLE = False\n",
    "\n",
    "# Ensure sklearn manifold and preprocessing are imported (likely already there)\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.preprocessing import StandardScaler # We might remove its usage later for consistency\n",
    "    TSNE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"WARNING: scikit-learn TSNE/StandardScaler not found.\")\n",
    "    TSNE_AVAILABLE = False\n",
    "\n",
    "# Ensure UMAP is checked (already done in the original script)\n",
    "# HAS_UMAP flag should be set correctly\n",
    "\n",
    "# --- Make sure these are also present ---\n",
    "\n",
    "import torchvision.transforms as transforms # Needed for image loading/processing\n",
    "\n",
    "# --- Add these imports ---\n",
    "import torch.nn.functional as F\n",
    "#from math import ceil # made redundant\n",
    "# Add KID calculation dependency\n",
    "try:\n",
    "    from sklearn.metrics.pairwise import polynomial_kernel\n",
    "    SKLEARN_KERNELS_AVAILABLE = True\n",
    "    print(\"Successfully imported sklearn kernels for KID.\")\n",
    "except ImportError:\n",
    "    print(\"WARNING: scikit-learn polynomial_kernel not found. Custom KID calculation will be disabled.\")\n",
    "    SKLEARN_KERNELS_AVAILABLE = False\n",
    "# Add scipy if needed for matrix sqrt in FID\n",
    "try:\n",
    "    from scipy import linalg\n",
    "    SCIPY_LINALG_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"WARNING: SciPy linalg not found. FID calculation might fail for non-positive definite covariance matrices.\")\n",
    "    SCIPY_LINALG_AVAILABLE = False\n",
    "\n",
    "def create_elliptical_mask(img_pil, blur_amount=10):\n",
    "    \"\"\"\n",
    "    Creates a soft, centered elliptical mask matching the input image dimensions.\n",
    "\n",
    "    Args:\n",
    "        img_pil (PIL.Image.Image): The PIL image defining the mask dimensions.\n",
    "        blur_amount (int):          Controls the softness of the mask edge (Gaussian blur sigma).\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image: A grayscale PIL Image mask (mode 'L'), or None on error.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"GenerationEngine\") # Assumes logger is configured\n",
    "    try:\n",
    "        width, height = img_pil.size\n",
    "        if width <= 0 or height <= 0:\n",
    "             logger.warning(\"Cannot create elliptical mask for zero-sized image.\")\n",
    "             return None\n",
    "\n",
    "        # Create a black background using numpy\n",
    "        mask_np = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "        # Define ellipse parameters (centered, slightly smaller than image bounds)\n",
    "        center_x = width // 2\n",
    "        center_y = height // 2\n",
    "        # Make axes slightly smaller than half-dimensions to avoid sharp cutoff at edges\n",
    "        axis_x = max(1, int(center_x * 0.95))\n",
    "        axis_y = max(1, int(center_y * 0.95))\n",
    "\n",
    "        # Draw the filled white ellipse using OpenCV\n",
    "        cv2.ellipse(mask_np, center=(center_x, center_y), axes=(axis_x, axis_y),\n",
    "                    angle=0, startAngle=0, endAngle=360, color=255, thickness=-1)\n",
    "\n",
    "        # Apply Gaussian blur for soft edges\n",
    "        # Kernel size must be odd and positive\n",
    "        k_size = blur_amount * 2 + 1\n",
    "        if k_size < 1: k_size = 1 # Ensure positive kernel size\n",
    "        \n",
    "        # Apply blur only if blur_amount > 0\n",
    "        if blur_amount > 0:\n",
    "            blurred_mask = cv2.GaussianBlur(mask_np, (k_size, k_size), 0)\n",
    "        else:\n",
    "            blurred_mask = mask_np # No blur if amount is 0 or less\n",
    "\n",
    "        # Convert the final numpy array back to PIL Image\n",
    "        mask_pil = Image.fromarray(blurred_mask, mode='L')\n",
    "        # logger.debug(f\"Created elliptical mask ({width}x{height}) with blur amount {blur_amount}\") # Optional debug log\n",
    "        return mask_pil\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating elliptical mask: {e}\", exc_info=True)\n",
    "        return None # Return None on error\n",
    "    \n",
    "# --- NEW FID/KID Calculation Function ---\n",
    "\n",
    "def calculate_fid_kid(real_features, fake_features, config, logger, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Calculate FID and KID between two sets of features.\n",
    "    KID calculation is now chunked to save memory.\n",
    "\n",
    "    Args:\n",
    "        real_features (np.ndarray): Features from real images (N_real, D_features).\n",
    "        fake_features (np.ndarray): Features from fake images (N_fake, D_features).\n",
    "        config (Config): Configuration object.\n",
    "        logger (logging.Logger): Logger instance.\n",
    "        eps (float): Small epsilon value for numerical stability.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing 'fid' and 'kid' scores, or None if calculation fails.\n",
    "    \"\"\"\n",
    "    results = {'fid': None, 'kid': None}\n",
    "    min_samples = min(len(real_features), len(fake_features))\n",
    "\n",
    "    if not FID_AVAILABLE:\n",
    "        logger.warning(\"pytorch-fid not available, skipping FID calculation.\")\n",
    "    \n",
    "    if not SKLEARN_KERNELS_AVAILABLE:\n",
    "        logger.warning(\"sklearn kernels not available, skipping KID calculation.\")\n",
    "\n",
    "    if min_samples < 10: # Need at least a few samples\n",
    "        logger.warning(f\"Too few samples ({min_samples}) to reliably calculate FID/KID.\")\n",
    "        return results\n",
    "    \n",
    "    try:\n",
    "        # --- FID Calculation --- (Keep existing code)\n",
    "        logger.debug(f\"Calculating FID using {min_samples} samples per set.\")\n",
    "        # Use the same number of samples from each set for fair comparison\n",
    "        real_f = real_features[:min_samples]\n",
    "        fake_f = fake_features[:min_samples]\n",
    "\n",
    "        mu_real = np.mean(real_f, axis=0)\n",
    "        sigma_real = np.cov(real_f, rowvar=False)\n",
    "        mu_fake = np.mean(fake_f, axis=0)\n",
    "        sigma_fake = np.cov(fake_f, rowvar=False)\n",
    "\n",
    "        # Use calculate_frechet_distance from pytorch-fid\n",
    "        fid_value = calculate_frechet_distance(mu_real, sigma_real, mu_fake, sigma_fake, eps=eps)\n",
    "        results['fid'] = float(fid_value)\n",
    "        logger.info(f\"Calculated FID: {results['fid']:.3f}\")\n",
    "\n",
    "        # Clean up FID calculation variables to free memory before KID calculation\n",
    "        del mu_real, sigma_real, mu_fake, sigma_fake\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating FID: {e}\", exc_info=True)\n",
    "        results['fid'] = None\n",
    "\n",
    "    try:\n",
    "        # --- NEW: CHUNKED KID Calculation ---\n",
    "        if SKLEARN_KERNELS_AVAILABLE:\n",
    "            logger.info(f\"Calculating KID using chunked approach to save memory\")\n",
    "            \n",
    "            # Use same feature subsets from FID calculation\n",
    "            real_f_kid = real_features[:min_samples]\n",
    "            fake_f_kid = fake_features[:min_samples]\n",
    "            \n",
    "            # Define chunk size - adjust based on available memory\n",
    "            kid_chunk_size = 2000  # Try 1000-5000 depending on available RAM\n",
    "            \n",
    "            # Kernel parameters (standard for KID)\n",
    "            degree = 3\n",
    "            gamma = None  # Defaults to 1/n_features in sklearn\n",
    "            coef0 = 1\n",
    "            \n",
    "            # Initialize accumulators for kernel sums\n",
    "            sum_k_rr = 0.0\n",
    "            sum_k_ff = 0.0\n",
    "            sum_k_rf = 0.0\n",
    "            \n",
    "            num_chunks = math.ceil(min_samples / kid_chunk_size)\n",
    "            logger.info(f\"Processing KID in {num_chunks} chunks (size: {kid_chunk_size})...\")\n",
    "            \n",
    "            # --- Calculate K_real_real sum (chunked) ---\n",
    "            with tqdm(total=min_samples, desc=\"KID Real-Real\") as pbar_rr:\n",
    "                for i in range(0, min_samples, kid_chunk_size):\n",
    "                    chunk_end = min(i + kid_chunk_size, min_samples)\n",
    "                    real_chunk = real_f_kid[i:chunk_end]\n",
    "                    chunk_size = len(real_chunk)\n",
    "                    \n",
    "                    if chunk_size == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # Calculate kernel for this chunk vs all real features\n",
    "                    k_rr_chunk = polynomial_kernel(\n",
    "                        real_chunk, real_f_kid, \n",
    "                        degree=degree, gamma=gamma, coef0=coef0\n",
    "                    )\n",
    "                    \n",
    "                    # Add to running sum\n",
    "                    sum_k_rr += np.sum(k_rr_chunk)\n",
    "                    \n",
    "                    # Update progress\n",
    "                    pbar_rr.update(chunk_size)\n",
    "                    \n",
    "                    # Clean up chunk variables\n",
    "                    del k_rr_chunk, real_chunk\n",
    "                    if i % (2 * kid_chunk_size) == 0:  # Less frequent cleanup\n",
    "                        gc.collect()\n",
    "            \n",
    "            # --- Calculate K_fake_fake sum (chunked) ---\n",
    "            with tqdm(total=min_samples, desc=\"KID Fake-Fake\") as pbar_ff:\n",
    "                for i in range(0, min_samples, kid_chunk_size):\n",
    "                    chunk_end = min(i + kid_chunk_size, min_samples)\n",
    "                    fake_chunk = fake_f_kid[i:chunk_end]\n",
    "                    chunk_size = len(fake_chunk)\n",
    "                    \n",
    "                    if chunk_size == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # Calculate kernel for this chunk vs all fake features\n",
    "                    k_ff_chunk = polynomial_kernel(\n",
    "                        fake_chunk, fake_f_kid, \n",
    "                        degree=degree, gamma=gamma, coef0=coef0\n",
    "                    )\n",
    "                    \n",
    "                    # Add to running sum\n",
    "                    sum_k_ff += np.sum(k_ff_chunk)\n",
    "                    \n",
    "                    # Update progress\n",
    "                    pbar_ff.update(chunk_size)\n",
    "                    \n",
    "                    # Clean up chunk variables\n",
    "                    del k_ff_chunk, fake_chunk\n",
    "                    if i % (2 * kid_chunk_size) == 0:  # Less frequent cleanup\n",
    "                        gc.collect()\n",
    "            \n",
    "            # --- Calculate K_real_fake sum (chunked) ---\n",
    "            with tqdm(total=min_samples, desc=\"KID Real-Fake\") as pbar_rf:\n",
    "                for i in range(0, min_samples, kid_chunk_size):\n",
    "                    chunk_end = min(i + kid_chunk_size, min_samples)\n",
    "                    real_chunk = real_f_kid[i:chunk_end]\n",
    "                    chunk_size = len(real_chunk)\n",
    "                    \n",
    "                    if chunk_size == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # Calculate kernel for this chunk vs all fake features\n",
    "                    k_rf_chunk = polynomial_kernel(\n",
    "                        real_chunk, fake_f_kid, \n",
    "                        degree=degree, gamma=gamma, coef0=coef0\n",
    "                    )\n",
    "                    \n",
    "                    # Add to running sum\n",
    "                    sum_k_rf += np.sum(k_rf_chunk)\n",
    "                    \n",
    "                    # Update progress\n",
    "                    pbar_rf.update(chunk_size)\n",
    "                    \n",
    "                    # Clean up chunk variables\n",
    "                    del k_rf_chunk, real_chunk\n",
    "                    if i % (2 * kid_chunk_size) == 0:  # Less frequent cleanup\n",
    "                        gc.collect()\n",
    "            \n",
    "            # Calculate final means and KID value\n",
    "            n_elements = min_samples * min_samples\n",
    "            mean_k_rr = sum_k_rr / n_elements\n",
    "            mean_k_ff = sum_k_ff / n_elements\n",
    "            mean_k_rf = sum_k_rf / n_elements\n",
    "            \n",
    "            # Calculate MMD^2\n",
    "            mmd2 = mean_k_rr + mean_k_ff - 2 * mean_k_rf\n",
    "            \n",
    "            # KID is often reported as MMD * 100 (standard scaling)\n",
    "            kid_value = np.sqrt(max(0, mmd2)) * 100\n",
    "            results['kid'] = float(kid_value)\n",
    "            logger.info(f\"Calculated KID: {results['kid']:.3f}\")\n",
    "            \n",
    "            # Clean up KID calculation variables\n",
    "            del real_f_kid, fake_f_kid\n",
    "        else:\n",
    "             results['kid'] = None\n",
    "             \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating KID: {e}\", exc_info=True)\n",
    "        results['kid'] = None\n",
    "\n",
    "    # Final cleanup\n",
    "    force_memory_cleanup(config)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# --- NEW FID/KID Plotting Function ---\n",
    "def plot_fid_kid_comparison(analysis_results, output_path, logger):\n",
    "    \"\"\"\n",
    "    Creates a bar chart comparing FID and KID scores for filtered vs unfiltered generated images.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Generating FID/KID comparison plot: {output_path}\")\n",
    "    try:\n",
    "        fid_kid_f = analysis_results.get('fid_kid_filtered')\n",
    "        fid_kid_u = analysis_results.get('fid_kid_unfiltered')\n",
    "\n",
    "        if not fid_kid_f and not fid_kid_u:\n",
    "            logger.warning(\"No FID/KID data available for plotting.\")\n",
    "            return False\n",
    "\n",
    "        labels = ['Filtered', 'Unfiltered']\n",
    "        fid_scores = [fid_kid_f.get('fid') if fid_kid_f else None,\n",
    "                      fid_kid_u.get('fid') if fid_kid_u else None]\n",
    "        kid_scores = [fid_kid_f.get('kid') if fid_kid_f else None,\n",
    "                      fid_kid_u.get('kid') if fid_kid_u else None]\n",
    "\n",
    "        # Filter out None values for plotting\n",
    "        valid_labels_fid = [labels[i] for i, v in enumerate(fid_scores) if v is not None]\n",
    "        valid_fid = [v for v in fid_scores if v is not None]\n",
    "        valid_labels_kid = [labels[i] for i, v in enumerate(kid_scores) if v is not None]\n",
    "        valid_kid = [v for v in kid_scores if v is not None]\n",
    "\n",
    "        if not valid_fid and not valid_kid:\n",
    "             logger.warning(\"No valid FID or KID scores found to plot.\")\n",
    "             return False\n",
    "\n",
    "        plt.style.use('seaborn-v0_8-darkgrid')\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=False) # Separate y-axes might be needed\n",
    "        fig.suptitle('FID and KID Comparison (Lower is Better)', fontsize=16)\n",
    "\n",
    "        # --- FID Plot ---\n",
    "        if valid_fid:\n",
    "            ax = axes[0]\n",
    "            bars = ax.bar(valid_labels_fid, valid_fid, color=['orange', 'lightgreen'])\n",
    "            ax.set_ylabel('FID Score')\n",
    "            ax.set_title('Fréchet Inception Distance (FID)')\n",
    "            ax.bar_label(bars, fmt='%.3f')\n",
    "            # Dynamically set ylim based on data range\n",
    "            if valid_fid:\n",
    "                 min_fid = min(valid_fid)\n",
    "                 max_fid = max(valid_fid)\n",
    "                 ax.set_ylim(max(0, min_fid * 0.9), max_fid * 1.1)\n",
    "\n",
    "        else:\n",
    "            axes[0].text(0.5, 0.5, 'FID Scores Not Available', horizontalalignment='center', verticalalignment='center', transform=axes[0].transAxes)\n",
    "            axes[0].set_title('Fréchet Inception Distance (FID)')\n",
    "\n",
    "\n",
    "        # --- KID Plot ---\n",
    "        if valid_kid:\n",
    "            ax = axes[1]\n",
    "            bars = ax.bar(valid_labels_kid, valid_kid, color=['orange', 'lightgreen'])\n",
    "            ax.set_ylabel('KID Score (x100)')\n",
    "            ax.set_title('Kernel Inception Distance (KID)')\n",
    "            ax.bar_label(bars, fmt='%.3f')\n",
    "            # Dynamically set ylim based on data range\n",
    "            if valid_kid:\n",
    "                 min_kid = min(valid_kid)\n",
    "                 max_kid = max(valid_kid)\n",
    "                 ax.set_ylim(max(0, min_kid * 0.9), max_kid * 1.1)\n",
    "        else:\n",
    "            axes[1].text(0.5, 0.5, 'KID Scores Not Available', horizontalalignment='center', verticalalignment='center', transform=axes[1].transAxes)\n",
    "            axes[1].set_title('Kernel Inception Distance (KID)')\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to make room for suptitle\n",
    "        plt.savefig(output_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        logger.info(f\"Saved FID/KID comparison plot to {output_path}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating FID/KID comparison plot: {e}\", exc_info=True)\n",
    "        # Attempt to close plot even if saving failed\n",
    "        try: plt.close(fig)\n",
    "        except: pass\n",
    "        return False\n",
    "\n",
    "def plot_combined_radar_chart(metrics_set1, metrics_set2, label1, label2, title, output_path):\n",
    "    \"\"\"\n",
    "    Create a radar chart comparing two sets of P/R/D/C metrics.\n",
    "\n",
    "    Args:\n",
    "        metrics_set1 (dict): First metrics result (e.g., filtered), expected to contain\n",
    "                             'individual' or 'mean' keys, or be a flat dict.\n",
    "        metrics_set2 (dict): Second metrics result (e.g., unfiltered).\n",
    "        label1 (str): Label for the first dataset (e.g., \"Filtered\").\n",
    "        label2 (str): Label for the second dataset (e.g., \"Unfiltered\").\n",
    "        title (str): Title for the chart.\n",
    "        output_path (str): Path to save the chart image.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"GenerationEngine\")\n",
    "    plt.style.use('seaborn-v0_8-darkgrid') # Optional: use a nice style\n",
    "\n",
    "    try:\n",
    "        # Extract 'individual' metrics by default, fallback to mean or flat dict\n",
    "        def get_plot_data(metrics_data):\n",
    "            if isinstance(metrics_data, dict):\n",
    "                if 'individual' in metrics_data and metrics_data['individual']:\n",
    "                    return metrics_data['individual']\n",
    "                elif 'mean' in metrics_data and metrics_data['mean']:\n",
    "                     logger.warning(f\"Using 'mean' metrics for plotting in '{title}' as 'individual' is empty/missing.\")\n",
    "                     return metrics_data['mean']\n",
    "                else: # Assume flat dict if keys 'individual'/'mean' are missing\n",
    "                     return metrics_data\n",
    "            return {} # Return empty if input is not dict\n",
    "\n",
    "        data1 = get_plot_data(metrics_set1)\n",
    "        data2 = get_plot_data(metrics_set2)\n",
    "\n",
    "        if not data1 or not data2:\n",
    "            logger.error(f\"Insufficient metrics data to generate combined radar chart '{title}'.\")\n",
    "            return False\n",
    "\n",
    "        # Define metrics for the radar\n",
    "        #categories = ['precision', 'recall', 'density', 'coverage']\n",
    "        categories = ['precision', 'recall', 'coverage']\n",
    "        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "        angles += angles[:1] # Close the loop\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "        # --- Plot Set 1 (e.g., Filtered) ---\n",
    "        values1 = [data1.get(cat, 0.0) for cat in categories]\n",
    "        values1 += values1[:1] # Close the loop\n",
    "        ax.plot(angles, values1, 'o-', linewidth=2, color='orange', alpha=0.8, label=label1)\n",
    "        ax.fill(angles, values1, alpha=0.1, color='orange')\n",
    "\n",
    "        # --- Plot Set 2 (e.g., Unfiltered) ---\n",
    "        values2 = [data2.get(cat, 0.0) for cat in categories]\n",
    "        values2 += values2[:1] # Close the loop\n",
    "        ax.plot(angles, values2, 'o-', linewidth=2, color='lightgreen', alpha=0.8, label=label2)\n",
    "        ax.fill(angles, values2, alpha=0.1, color='lightgreen')\n",
    "\n",
    "        # Customize the chart\n",
    "        ax.set_thetagrids(np.degrees(angles[:-1]), [c.capitalize() for c in categories])\n",
    "        ax.set_ylim(0, 1.05) # Set ylim slightly > 1.0 for visibility\n",
    "        ax.grid(True)\n",
    "        plt.title(title, fontsize=16, y=1.1) # Increase title size and spacing\n",
    "        # Position legend outside the plot area\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "\n",
    "        plt.tight_layout() # Adjust layout\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight') # Use bbox_inches='tight'\n",
    "        plt.close(fig)\n",
    "\n",
    "        logger.info(f\"Saved combined radar chart to {output_path}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating combined radar chart '{title}': {e}\", exc_info=True)\n",
    "        return False\n",
    "\n",
    "# --- Add/Ensure these helper functions ---\n",
    "\n",
    "def log_memory_usage(logger, step=''): # Pass logger explicitly\n",
    "    \"\"\"Log current memory usage.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / (1024 ** 3) # GB\n",
    "        reserved = torch.cuda.memory_reserved() / (1024 ** 3)  # GB\n",
    "        logger.info(f\"GPU Memory [{step}]: Allocated: {allocated:.3f} GB | Reserved: {reserved:.3f} GB\")\n",
    "\n",
    "    try:\n",
    "        import psutil\n",
    "        process = psutil.Process(os.getpid())\n",
    "        memory_info = process.memory_info()\n",
    "        memory_gb = memory_info.rss / (1024 ** 3)\n",
    "        logger.info(f\"CPU Memory [{step}]: {memory_gb:.3f} GB\")\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "# Ensure force_memory_cleanup exists and uses CLEAR_CUDA_CACHE\n",
    "def force_memory_cleanup(config=None): # Optional config for CLEAR_CUDA_CACHE flag\n",
    "    \"\"\"Force aggressive memory cleanup.\"\"\"\n",
    "    gc.collect()\n",
    "    clear_cache_flag = True\n",
    "    if config and hasattr(config, 'CLEAR_CUDA_CACHE'):\n",
    "        clear_cache_flag = config.CLEAR_CUDA_CACHE\n",
    "\n",
    "    if torch.cuda.is_available() and clear_cache_flag:\n",
    "        torch.cuda.empty_cache()\n",
    "        if hasattr(torch.cuda, 'memory_summary'):\n",
    "             torch.cuda.synchronize()\n",
    "\n",
    "def get_inception_model(config):\n",
    "    \"\"\"Load the InceptionV3 model for feature extraction.\"\"\"\n",
    "    if not FID_AVAILABLE:\n",
    "        raise ImportError(\"pytorch-fid InceptionV3 not available\")\n",
    "\n",
    "    print(\"Loading InceptionV3 model for feature extraction...\") # Use print or logger\n",
    "    block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[config.FEATURE_DIMS]\n",
    "    model = InceptionV3([block_idx]).to(config.DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Suppress PIL DecompressionBombWarning for large images\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*weights_only.*\")\n",
    "\n",
    "# Add these functions to improve error handling and ensure errors display in Jupyter\n",
    "\n",
    "def configure_exception_handler():\n",
    "    \"\"\"Configure Python to display full exception tracebacks in Jupyter.\"\"\"\n",
    "    import sys\n",
    "    \n",
    "    def custom_excepthook(exc_type, exc_value, exc_traceback):\n",
    "        \"\"\"Custom exception handler to ensure errors are displayed in Jupyter.\"\"\"\n",
    "        import traceback\n",
    "        print(\"\".join(traceback.format_exception(exc_type, exc_value, exc_traceback)))\n",
    "    \n",
    "    # Set the custom exception handler\n",
    "    sys.excepthook = custom_excepthook\n",
    "\n",
    "# Model Inspection\n",
    "def inspect_checkpoint(checkpoint_path, logger=None):\n",
    "    \"\"\"Inspect a checkpoint file and print its structure for debugging.\"\"\"\n",
    "    try:\n",
    "        # Load checkpoint\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "        \n",
    "        # Print top-level keys\n",
    "        print(f\"Checkpoint keys: {list(checkpoint.keys())}\")\n",
    "        \n",
    "        # If there's a generator_state_dict, analyze its structure\n",
    "        if 'generator_state_dict' in checkpoint:\n",
    "            gen_dict = checkpoint['generator_state_dict']\n",
    "            print(\"\\nGenerator state dict:\")\n",
    "            for key, tensor in gen_dict.items():\n",
    "                print(f\"  {key}: shape={tensor.shape}, dtype={tensor.dtype}\")\n",
    "        \n",
    "        # If there's a critic_state_dict, analyze its structure\n",
    "        if 'critic_state_dict' in checkpoint:\n",
    "            critic_dict = checkpoint['critic_state_dict']\n",
    "            print(\"\\nCritic state dict:\")\n",
    "            for key, tensor in critic_dict.items():\n",
    "                print(f\"  {key}: shape={tensor.shape}, dtype={tensor.dtype}\")\n",
    "        \n",
    "        # Check for other potentially useful keys\n",
    "        for key in ['epoch', 'best_fid', 'best_kid']:\n",
    "            if key in checkpoint:\n",
    "                print(f\"\\n{key}: {checkpoint[key]}\")\n",
    "                \n",
    "        return checkpoint\n",
    "    except Exception as e:\n",
    "        print(f\"Error inspecting checkpoint: {e}\")\n",
    "        if logger:\n",
    "            logger.error(f\"Error inspecting checkpoint: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Configuration Class ---\n",
    "class Config:\n",
    "    \"\"\"Configuration class with all parameters and boolean flags.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # --- Pipeline Control Flags ---\n",
    "        self.CLEAN_OUTPUT_BEFORE_RUN = True # New flag, default to False for safety\n",
    "        self.USE_GPU = True  # Use GPU if available\n",
    "        self.CALCULATE_REAL_STATS = True  # Calculate statistics from real images\n",
    "        self.USE_STATS_CACHE = True  # Use cached statistics if available\n",
    "        self.GENERATE_INDIVIDUAL_POLLEN = True  # Generate individual pollen images\n",
    "        self.GENERATE_COMPOSED_IMAGES = True  # Generate composed images with backgrounds\n",
    "        self.SAVE_CHECKPOINTS = True  # Save generation checkpoints for resuming\n",
    "        self.GENERATE_REPORTS = True  # Generate markdown reports\n",
    "        self.PERFORM_ANALYSIS = True  # Perform statistical analysis on generated images\n",
    "        \n",
    "        # --- Memory Management Flags ---\n",
    "        self.OPTIMIZE_MEMORY_USAGE = True  # Apply memory optimization techniques\n",
    "        self.LOAD_GENERATOR_TO_CPU = False  # Load generator to CPU first, then transfer to GPU when needed\n",
    "        self.LOAD_CRITIC_TO_CPU = False  # Load critic to CPU to save GPU memory ~ default : True ; alt : False ;\n",
    "        self.MONITOR_MEMORY = True  # Track memory usage during execution\n",
    "        \n",
    "        # --- Quality Control Flags ---\n",
    "        self.USE_QUALITY_FILTERING = True  # Use critic for quality filtering\n",
    "        self.USE_STATS_MATCHING_SIZE = True  # Match size distributions from real data\n",
    "        self.USE_STATS_MATCHING_HISTOGRAM = False  # Match histogram distributions from real data ~ default : True (causes issues with poisson blending)\n",
    "        \n",
    "        # --- Augmentation Flags ---\n",
    "        self.USE_CONTINUOUS_ROTATION = False  # Force discrete rotations (0, 90, 180, 270 only)\n",
    "        self.USE_RANDOM_SCALES = True  # Apply random scaling to pollen images\n",
    "        \n",
    "        # --- Blending Flags ---\n",
    "        self.USE_ADVANCED_BLENDING = True  # Use advanced blending methods\n",
    "        self.USE_CONTENT_AWARE_MASKS = True  # Generate content-aware masks for blending\n",
    "        \n",
    "        # --- Parallelization Flags ---\n",
    "        self.USE_PARALLEL_PROCESSING = True  # Use parallel processing for composed image generation\n",
    "        self.USE_SEPARATE_PROCESS_PER_BATCH = False  # Use a separate process for each batch\n",
    "        \n",
    "        # --- Paths ---\n",
    "        self.CHECKPOINT_PATH = r\"C:\\Users\\praam\\Desktop\\havetai+vetcyto\\task-05_dataset\\WGAN-SN_training-output_v2-151_flawed-04\\continuation-enhanced_00\\checkpoints\\cont_best_fid_checkpoint.pth.tar\"\n",
    "        self.PREPROCESSED_REAL_DATA_PATH = r\"C:\\Users\\praam\\Desktop\\havetai+vetcyto\\task-05_dataset\\pre-processing_px-128_step_automated-labels_pc-150_mixed\"\n",
    "        self.RAW_REAL_DATA_PATH = r\"C:\\Users\\praam\\Desktop\\havetai+vetcyto\\task-05_dataset\\vet_images_sliced\\TrainingStepSet_automated-labels_T_full-size_150-pc_undivided_categorized\\all-classes-mixed\\uniform\"\n",
    "        self.BACKGROUND_DIR = r\"C:\\Users\\praam\\Desktop\\havetai+vetcyto\\task-05_dataset\\backgrounds_layouts_step_automated-labels_pc-150\\step_size_320\\backgrounds\"\n",
    "        self.STATISTICS_DIR = r\"C:\\Users\\praam\\Desktop\\havetai+vetcyto\\task-05_dataset\\backgrounds_layouts_step_automated-labels_pc-150\\step_size_320\\statistics\"\n",
    "        self.OUTPUT_DIR = r\"C:\\Users\\praam\\Desktop\\havetai+vetcyto\\task-05_dataset\\generation-engine_XYZ\"\n",
    "        \n",
    "        # --- Output Subdirectories ---\n",
    "        self.POLLEN_SUBDIR = \"synthetic_pollen\"\n",
    "        self.COMPOSED_SUBDIR = \"synthetic_composed_XYZ\"\n",
    "        self.LABELS_SUBDIR = \"synthetic_labels_XYZ\"\n",
    "        self.LOG_SUBDIR = \"logs_XYZ\"\n",
    "        self.REPORT_SUBDIR = \"reports_XYZ\"\n",
    "        self.GRAPH_SUBDIR = \"graphs_XYZ\"\n",
    "        self.STATS_SUBDIR = \"stats_XYZ\"\n",
    "        self.CONFIG_SUBDIR = \"configs_XYZ\"\n",
    "        self.CHECKPOINT_SUBDIR = \"checkpoints_XYZ\"\n",
    "        \n",
    "        # --- Model Parameters ---\n",
    "        self.NOISE_DIM = 100\n",
    "        self.G_FEATURES = 64\n",
    "        self.C_FEATURES = 64  # Critic features\n",
    "        self.CHANNELS_IMG = 1\n",
    "        \n",
    "        # --- Generation Targets ---\n",
    "        self.TARGET_POLLEN_IMAGES = 62492  # Number of 128x128 images to generate ~ default pre-processed : 61671 ; alt : 145 ; new : 1450 ; newer : 14500 ; default raw : 62492 ; needed : 87467 ;\n",
    "        self.TARGET_COMPOSED_IMAGES = 4363  # Number of 640x640 images to generate ~ default : 4363 ; alt : 10 ; new : 100 ; newer : 1000 ; needed : 6108 ;\n",
    "        self.AVG_POLLEN_PER_IMAGE = 14.32     # Average pollen per composed image ~ 14 as default ; 14.13 with pre-processed ; 14.32 with raw ;\n",
    "        \n",
    "        # --- Quality Filtering Parameters ---\n",
    "        self.FILTERING_SURPLUS_FACTOR = 2.0  # Generate extra XYZ % for filtering ~ reason: 1.25 * 0.8 = 1.0 ; alt (A) : 2.0 * 0.5 = 1.0 ; alt (B) : 4.0 * 0.25 = 1.0 ;\n",
    "        self.QUALITY_THRESHOLD_PERCENTILE = 50.0  # Keep top XYZ % by quality score ~ reason: 1.25 * 0.8 = 1.0 ; alt (A) : 2.0 * 0.5 = 1.0 ; alt (B) : 4.0 * 0.25 = 1.0 ;\n",
    "        \n",
    "        # --- Image Parameters ---\n",
    "        self.BG_SIZE = 640                 # Background image size\n",
    "        self.POLLEN_SIZE_BASE = 128        # Base pollen image size\n",
    "        self.OBJECT_CLASS = 0              # YOLO class for pollen objects\n",
    "        \n",
    "        # --- Augmentation Parameters ---\n",
    "        self.SCALE_RANGE = (0.75, 1.25)    # Allow 25% scaling in each direction\n",
    "        self.ROTATION_ANGLES = [0, 90, 180, 270]  # Discrete rotation angles (if not continuous)\n",
    "        self.MARGIN = 15                   # Margin from image edges (in pixels)\n",
    "        \n",
    "        # --- Blending Parameters ---\n",
    "        self.BLENDING_METHOD = \"alpha\"   # Options: \"poisson\"/\"pyramid\"/\"alpha\" ~ default : \"poisson\" ; complex : \"pyramid\" ; simple: \"alpha\" ;\n",
    "        self.PYRAMID_LEVELS = 4            # Levels for Laplacian pyramid blending\n",
    "        self.FEATHER_AMOUNT = 15          # Used for blur/feathering in content/ellipse masks\n",
    "\n",
    "        # --- Performance Parameters ---\n",
    "        self.BATCH_SIZE = 64\n",
    "        self.SCORING_BATCH_SIZE = 128 # Used for critic scoring\n",
    "        self.FEATURE_EXTRACTION_BATCH_SIZE = 64 # New: Batch size for InceptionV3\n",
    "        self.NUM_WORKERS = max(1, mp_cpu_count() - 1)\n",
    "        self.CHUNK_SIZE = 50\n",
    "        self.MEMORY_CHECK_INTERVAL = 100\n",
    "        self.GPU_MEMORY_THRESHOLD = 0.9\n",
    "        self.RAM_MEMORY_THRESHOLD = 0.9\n",
    "        self.CLEANUP_INTERVAL = 500\n",
    "        self.PIN_MEMORY = True # Added from evaluator\n",
    "        self.CLEAR_CUDA_CACHE = True # Added from evaluator\n",
    "\n",
    "        # --- Analysis Parameters ---\n",
    "        self.ANALYSIS_SAMPLE_SIZE = 60000 # Max samples for analysis ~ default pre-processed : 60000 ; alt : 100 ; new : 1000 ; newer : 10000 ; default raw : 60000 ;\n",
    "        self.VISUALIZATION_SAMPLE_SIZE = 15000 # New: Max samples for t-SNE/UMAP plots (adjust as needed) ~ balance real & fake counts\n",
    "        self.MEASURE_FID = True # Keep if needed later\n",
    "        self.MEASURE_KID = True # Keep if needed later\n",
    "        self.MEASURE_PRDC = True\n",
    "        self.VISUALIZE_TSNE = True # New flag to control visualization\n",
    "        self.VISUALIZE_UMAP = True # New flag to control visualization\n",
    "        self.FEATURE_DIMS = 2048   # Inception feature dimensions\n",
    "        self.PR_K_VALUE = 6        # k-value for PRDC calculation (for torch-fidelity and maybe custom)\n",
    "        self.MANIFOLD_K = 6        # k-value for custom PRDC manifold estimation\n",
    "        self.DISTANCE_MULTIPLIER = 1.2 # Multiplier for custom PRDC distance thresholds\n",
    "        self.SUBSAMPLE_MANIFOLD = True # Whether to subsample for custom PRDC manifold estimation\n",
    "        self.RANDOM_SEED = 42      # Added from evaluator for reproducibility\n",
    "\n",
    "        # --- Device Configuration ---\n",
    "        self.DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() and self.USE_GPU else \"cpu\")\n",
    "\n",
    "        \n",
    "    def save(self, filename=None):\n",
    "        \"\"\"Save configuration to a file.\"\"\"\n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = os.path.join(self.OUTPUT_DIR, self.CONFIG_SUBDIR, f\"config_{timestamp}.json\")\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        \n",
    "        # Convert config to dict, excluding device (not serializable)\n",
    "        config_dict = {k: v for k, v in vars(self).items() if k != 'DEVICE'}\n",
    "        \n",
    "        # Save to file\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(config_dict, f, indent=4)\n",
    "        \n",
    "        return filename\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        \"\"\"Load configuration from a file.\"\"\"\n",
    "        with open(filename, 'r') as f:\n",
    "            config_dict = json.load(f)\n",
    "        \n",
    "        # Create new config object\n",
    "        config = cls()\n",
    "        \n",
    "        # Update with loaded values\n",
    "        for k, v in config_dict.items():\n",
    "            if hasattr(config, k):\n",
    "                setattr(config, k, v)\n",
    "        \n",
    "        # Re-compute device\n",
    "        config.DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() and config.USE_GPU else \"cpu\")\n",
    "        \n",
    "        return config\n",
    "    \n",
    "    def get_real_data_path(self):\n",
    "        \"\"\"Return the appropriate real data path based on configuration.\"\"\"\n",
    "        #return self.PREPROCESSED_REAL_DATA_PATH if os.path.exists(self.PREPROCESSED_REAL_DATA_PATH) else self.RAW_REAL_DATA_PATH\n",
    "        return self.RAW_REAL_DATA_PATH if os.path.exists(self.RAW_REAL_DATA_PATH) else self.PREPROCESSED_REAL_DATA_PATH\n",
    "    \n",
    "    def get_all_output_dirs(self):\n",
    "        \"\"\"Return a dictionary with all output directories.\"\"\"\n",
    "        return {\n",
    "            'pollen': os.path.join(self.OUTPUT_DIR, self.POLLEN_SUBDIR),\n",
    "            'composed': os.path.join(self.OUTPUT_DIR, self.COMPOSED_SUBDIR),\n",
    "            'labels': os.path.join(self.OUTPUT_DIR, self.LABELS_SUBDIR),\n",
    "            'logs': os.path.join(self.OUTPUT_DIR, self.LOG_SUBDIR),\n",
    "            'reports': os.path.join(self.OUTPUT_DIR, self.REPORT_SUBDIR),\n",
    "            'graphs': os.path.join(self.OUTPUT_DIR, self.GRAPH_SUBDIR),\n",
    "            'stats': os.path.join(self.OUTPUT_DIR, self.STATS_SUBDIR),\n",
    "            'configs': os.path.join(self.OUTPUT_DIR, self.CONFIG_SUBDIR),\n",
    "            'checkpoints': os.path.join(self.OUTPUT_DIR, self.CHECKPOINT_SUBDIR)\n",
    "        }\n",
    "\n",
    "\n",
    "# --- Dependency Check and Installation ---\n",
    "def check_and_install_dependencies():\n",
    "    \"\"\"Check for required dependencies and install if missing.\"\"\"\n",
    "    dependencies = {\n",
    "        'opencv-python': 'cv2',\n",
    "        'scikit-image': 'skimage',\n",
    "        'scikit-learn': 'sklearn'\n",
    "    }\n",
    "    \n",
    "    missing = []\n",
    "    for package, module in dependencies.items():\n",
    "        try:\n",
    "            __import__(module)\n",
    "        except ImportError:\n",
    "            missing.append(package)\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"Installing missing dependencies: {', '.join(missing)}\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + missing)\n",
    "            print(\"Dependencies installed successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error installing dependencies: {e}\")\n",
    "            print(\"Please install the following packages manually:\")\n",
    "            print(\", \".join(missing))\n",
    "            sys.exit(1)\n",
    "\n",
    "# Import dependencies after checking\n",
    "try:\n",
    "    import cv2\n",
    "    from skimage.exposure import match_histograms\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "except ImportError:\n",
    "    check_and_install_dependencies()\n",
    "    import cv2\n",
    "    from skimage.exposure import match_histograms\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "try:\n",
    "    from umap import UMAP\n",
    "    HAS_UMAP = True\n",
    "except ImportError:\n",
    "    HAS_UMAP = False\n",
    "    print(\"UMAP not available. t-SNE will be used for dimensionality reduction.\")\n",
    "\n",
    "# --- Logging Setup ---\n",
    "def setup_logging(config):\n",
    "    \"\"\"Configure logging for console and file output.\"\"\"\n",
    "    log_dir = os.path.join(config.OUTPUT_DIR, config.LOG_SUBDIR)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_filename = os.path.join(log_dir, f\"generation_engine_{timestamp}.log\")\n",
    "    \n",
    "    # Configure logger\n",
    "    logger = logging.getLogger(\"GenerationEngine\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Clear existing handlers\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "    \n",
    "    # Create file handler with detailed formatting\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "    file_handler.setLevel(logging.DEBUG)  # File gets everything\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    # Create console handler with minimal formatting\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "    console_handler.setLevel(logging.INFO)  # Console gets INFO and above\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    logger.info(f\"Logging initialized. Log file: {log_filename}\")\n",
    "    return logger\n",
    "\n",
    "# --- Memory Management ---\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage statistics for RAM and GPU.\"\"\"\n",
    "    memory_stats = {\n",
    "        'ram_used_percent': 0,\n",
    "        'ram_available_gb': 0,\n",
    "        'gpu_used_percent': 0,\n",
    "        'gpu_used_gb': 0,\n",
    "        'gpu_total_gb': 0\n",
    "    }\n",
    "    \n",
    "    # Get RAM usage\n",
    "    try:\n",
    "        ram = psutil.virtual_memory()\n",
    "        memory_stats['ram_used_percent'] = ram.percent\n",
    "        memory_stats['ram_available_gb'] = ram.available / (1024**3)  # Convert to GB\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Get GPU usage if available\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            current_device = torch.cuda.current_device()\n",
    "            memory_stats['gpu_total_gb'] = torch.cuda.get_device_properties(current_device).total_memory / (1024**3)\n",
    "            memory_stats['gpu_used_gb'] = (torch.cuda.memory_allocated(current_device) + \n",
    "                                          torch.cuda.memory_reserved(current_device)) / (1024**3)\n",
    "            memory_stats['gpu_used_percent'] = (memory_stats['gpu_used_gb'] / memory_stats['gpu_total_gb']) * 100\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    return memory_stats\n",
    "\n",
    "def memory_monitor(config, logger, stop_event):\n",
    "    \"\"\"Background thread to monitor memory usage.\"\"\"\n",
    "    logger.info(\"Starting memory monitoring thread\")\n",
    "    \n",
    "    stats_dir = os.path.join(config.OUTPUT_DIR, config.STATS_SUBDIR)\n",
    "    os.makedirs(stats_dir, exist_ok=True)\n",
    "    \n",
    "    memory_log = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        while not stop_event.is_set():\n",
    "            timestamp = time.time() - start_time\n",
    "            memory_stats = get_memory_usage()\n",
    "            \n",
    "            log_entry = {\n",
    "                'timestamp': timestamp,\n",
    "                **memory_stats\n",
    "            }\n",
    "            memory_log.append(log_entry)\n",
    "            \n",
    "            # Log to console periodically\n",
    "            if len(memory_log) % 10 == 0:\n",
    "                logger.debug(f\"Memory usage - RAM: {memory_stats['ram_used_percent']:.1f}%, \"\n",
    "                           f\"GPU: {memory_stats['gpu_used_percent']:.1f}% \"\n",
    "                           f\"({memory_stats['gpu_used_gb']:.3f}/{memory_stats['gpu_total_gb']:.3f} GB)\")\n",
    "            \n",
    "            # Check if memory usage is critical\n",
    "            if (memory_stats['ram_used_percent'] > config.RAM_MEMORY_THRESHOLD * 100 or\n",
    "                memory_stats['gpu_used_percent'] > config.GPU_MEMORY_THRESHOLD * 100):\n",
    "                logger.warning(f\"HIGH MEMORY USAGE - RAM: {memory_stats['ram_used_percent']:.1f}%, \"\n",
    "                              f\"GPU: {memory_stats['gpu_used_percent']:.1f}%\")\n",
    "            \n",
    "            # Save to file periodically\n",
    "            if len(memory_log) % 30 == 0:\n",
    "                try:\n",
    "                    with open(os.path.join(stats_dir, \"memory_usage.json\"), 'w') as f:\n",
    "                        json.dump(memory_log, f, indent=2)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error saving memory log: {e}\")\n",
    "            \n",
    "            # Sleep for monitoring interval\n",
    "            time.sleep(10)  # Check every 10 seconds\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in memory monitor thread: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Save final memory log\n",
    "        try:\n",
    "            with open(os.path.join(stats_dir, \"memory_usage.json\"), 'w') as f:\n",
    "                json.dump(memory_log, f, indent=2)\n",
    "            \n",
    "            # Plot memory usage\n",
    "            if memory_log:\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                timestamps = [entry['timestamp'] / 60 for entry in memory_log]  # Convert to minutes\n",
    "                \n",
    "                plt.plot(timestamps, [entry['ram_used_percent'] for entry in memory_log], \n",
    "                         label='RAM Usage %', color='blue')\n",
    "                \n",
    "                if memory_log[0]['gpu_total_gb'] > 0:\n",
    "                    plt.plot(timestamps, [entry['gpu_used_percent'] for entry in memory_log], \n",
    "                             label='GPU Usage %', color='red')\n",
    "                \n",
    "                plt.xlabel('Time (minutes)')\n",
    "                plt.ylabel('Usage (%)')\n",
    "                plt.title('Memory Usage During Generation')\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.savefig(os.path.join(stats_dir, \"memory_usage.png\"))\n",
    "                plt.close()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error finalizing memory log: {e}\")\n",
    "        \n",
    "        logger.info(\"Memory monitoring thread stopped\")\n",
    "\n",
    "def check_memory_safe(config, logger):\n",
    "    \"\"\"Check if memory usage is below thresholds and safe to continue.\"\"\"\n",
    "    memory_stats = get_memory_usage()\n",
    "    \n",
    "    ram_safe = memory_stats['ram_used_percent'] < config.RAM_MEMORY_THRESHOLD * 100\n",
    "    gpu_safe = memory_stats['gpu_used_percent'] < config.GPU_MEMORY_THRESHOLD * 100\n",
    "    \n",
    "    if not ram_safe:\n",
    "        logger.warning(f\"RAM usage critical: {memory_stats['ram_used_percent']:.1f}% > \"\n",
    "                      f\"{config.RAM_MEMORY_THRESHOLD * 100}% threshold\")\n",
    "    \n",
    "    if not gpu_safe and torch.cuda.is_available():\n",
    "        logger.warning(f\"GPU memory usage critical: {memory_stats['gpu_used_percent']:.1f}% > \"\n",
    "                      f\"{config.GPU_MEMORY_THRESHOLD * 100}% threshold\")\n",
    "    \n",
    "    return ram_safe and gpu_safe\n",
    "\n",
    "#def force_memory_cleanup():\n",
    "#    \"\"\"Force aggressive memory cleanup.\"\"\"\n",
    "#    gc.collect()\n",
    "#    if torch.cuda.is_available():\n",
    "#        torch.cuda.empty_cache()\n",
    "        # Extra measures for more aggressive cleanup\n",
    "#        if hasattr(torch.cuda, 'memory_summary'):\n",
    "#            torch.cuda.synchronize()\n",
    "\n",
    "# --- Create Output Directories ---\n",
    "def create_output_directories(config):\n",
    "    \"\"\"Create all necessary output directories.\"\"\"\n",
    "    dirs = config.get_all_output_dirs()\n",
    "    \n",
    "    for name, path in dirs.items():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "    return dirs\n",
    "\n",
    "# --- Model Definitions ---\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator Network for WGAN-SN (DCGAN-style architecture).\"\"\"\n",
    "    def __init__(self, noise_dim, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        # Input: N x noise_dim x 1 x 1\n",
    "        self.net = nn.Sequential(\n",
    "            # Z -> FEATURES_G*16 x 4 x 4\n",
    "            self._block(noise_dim, features_g * 16, 4, 1, 0), \n",
    "            # -> FEATURES_G*8 x 8 x 8\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1), \n",
    "            # -> FEATURES_G*4 x 16 x 16\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1), \n",
    "            # -> FEATURES_G*2 x 32 x 32\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1), \n",
    "            # -> FEATURES_G x 64 x 64\n",
    "            self._block(features_g * 2, features_g, 4, 2, 1), \n",
    "            # -> CHANNELS_IMG x 128 x 128\n",
    "            nn.ConvTranspose2d(features_g, channels_img, kernel_size=4, stride=2, padding=1), \n",
    "            # Output image in [-1, 1] range\n",
    "            nn.Tanh() \n",
    "        )\n",
    "    \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        \"\"\"Helper for creating a Generator block (ConvTranspose2d + BatchNorm + ReLU).\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels), \n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the Generator.\"\"\"\n",
    "        return self.net(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"WGAN-SN Critic Network with Spectral Normalization.\"\"\"\n",
    "    def __init__(self, channels_img, features_c):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        # The error message shows this model uses spectral normalization (weight_u, weight_v, weight_orig)\n",
    "        # and has a different structure than our original implementation\n",
    "        self.net = nn.Sequential(\n",
    "            # Layer 0: First conv with spectral norm\n",
    "            nn.utils.spectral_norm(\n",
    "                nn.Conv2d(channels_img, features_c, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "            ),  # 64x64\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Layer 2: Second conv with spectral norm\n",
    "            nn.utils.spectral_norm(\n",
    "                nn.Conv2d(features_c, features_c * 2, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "            ),  # 32x32\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Layer 4: Third conv with spectral norm\n",
    "            nn.utils.spectral_norm(\n",
    "                nn.Conv2d(features_c * 2, features_c * 4, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "            ),  # 16x16\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Layer 6: Fourth conv with spectral norm\n",
    "            nn.utils.spectral_norm(\n",
    "                nn.Conv2d(features_c * 4, features_c * 8, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "            ),  # 8x8\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Layer 8: Fifth conv with spectral norm\n",
    "            nn.utils.spectral_norm(\n",
    "                nn.Conv2d(features_c * 8, features_c * 16, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "            ),  # 4x4\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Layer 10: Output layer with spectral norm\n",
    "            nn.utils.spectral_norm(\n",
    "                nn.Conv2d(features_c * 16, 1, kernel_size=4, stride=1, padding=0, bias=True)\n",
    "            ),  # 1x1\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the Critic.\"\"\"\n",
    "        return self.net(x)\n",
    "\n",
    "# --- Model Loading ---\n",
    "def load_models(config, logger):\n",
    "    \"\"\"Load generator and critic models from checkpoint with memory optimization.\"\"\"\n",
    "    logger.info(f\"Loading models from checkpoint: {config.CHECKPOINT_PATH}\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize models\n",
    "        generator = Generator(\n",
    "            noise_dim=config.NOISE_DIM,\n",
    "            channels_img=config.CHANNELS_IMG,\n",
    "            features_g=config.G_FEATURES\n",
    "        )\n",
    "        \n",
    "        critic = None\n",
    "        if config.USE_QUALITY_FILTERING:\n",
    "            critic = Critic(\n",
    "                channels_img=config.CHANNELS_IMG,\n",
    "                features_c=config.C_FEATURES\n",
    "            )\n",
    "        \n",
    "        # Determine loading devices based on memory management settings\n",
    "        gen_device = torch.device('cpu') if config.LOAD_GENERATOR_TO_CPU else config.DEVICE\n",
    "        critic_device = torch.device('cpu') if config.LOAD_CRITIC_TO_CPU else config.DEVICE\n",
    "        \n",
    "        # Load checkpoint\n",
    "        logger.info(f\"Loading checkpoint (with weights_only=False)...\")\n",
    "        checkpoint = torch.load(config.CHECKPOINT_PATH, map_location='cpu', weights_only=False)\n",
    "        \n",
    "        # Load generator\n",
    "        if 'generator_state_dict' in checkpoint:\n",
    "            generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "            logger.info(\"Generator loaded from generator_state_dict\")\n",
    "        elif 'model_state_dict' in checkpoint:\n",
    "            generator.load_state_dict(checkpoint['model_state_dict'])\n",
    "            logger.info(\"Generator loaded from model_state_dict\")\n",
    "        else:\n",
    "            raise KeyError(\"No recognized generator state dict found in checkpoint\")\n",
    "        \n",
    "        # Load critic (if requested and available)\n",
    "        if config.USE_QUALITY_FILTERING and critic is not None:\n",
    "            try:\n",
    "                if 'critic_state_dict' in checkpoint:\n",
    "                    critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "                    logger.info(\"Critic loaded from critic_state_dict\")\n",
    "                else:\n",
    "                    logger.warning(\"No critic_state_dict found in checkpoint, quality filtering will be disabled\")\n",
    "                    config.USE_QUALITY_FILTERING = False\n",
    "                    critic = None\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to load critic: {e}\")\n",
    "                logger.warning(\"Quality filtering will be disabled\")\n",
    "                config.USE_QUALITY_FILTERING = False\n",
    "                critic = None\n",
    "        \n",
    "        # Move models to appropriate devices\n",
    "        generator = generator.to(gen_device)\n",
    "        if critic is not None:\n",
    "            critic = critic.to(critic_device)\n",
    "            critic.eval()  # Set to evaluation mode\n",
    "        \n",
    "        # Set generator to evaluation mode\n",
    "        generator.eval()\n",
    "        \n",
    "        logger.info(f\"Generator on {gen_device}, Critic on {'N/A' if critic is None else critic_device}\")\n",
    "        logger.info(f\"Quality filtering is {'enabled' if config.USE_QUALITY_FILTERING else 'disabled'}\")\n",
    "        \n",
    "        return generator, critic, checkpoint\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading models: {e}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        raise\n",
    "\n",
    "# Add this function to convert NumPy types to native Python types\n",
    "def convert_numpy_types(obj):\n",
    "    \"\"\"Convert NumPy types in a dictionary to standard Python types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_numpy_types(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_types(item) for item in obj]\n",
    "    elif isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return convert_numpy_types(obj.tolist())\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Then update the calculate_real_data_stats function by replacing the JSON saving part:\n",
    "\n",
    "# --- Real Data Statistics ---\n",
    "def calculate_real_data_stats(config, logger):\n",
    "    \"\"\"Calculate statistics from real pollen images.\"\"\"\n",
    "    logger.info(\"Calculating statistics from real pollen images...\")\n",
    "    \n",
    "    stats_cache_path = os.path.join(config.OUTPUT_DIR, config.STATS_SUBDIR, \"real_data_stats.json\")\n",
    "    \n",
    "    # Try to load cached stats if allowed\n",
    "    if config.USE_STATS_CACHE and os.path.exists(stats_cache_path):\n",
    "        try:\n",
    "            logger.info(f\"Loading cached statistics from {stats_cache_path}\")\n",
    "            with open(stats_cache_path, 'r') as f:\n",
    "                stats = json.load(f)\n",
    "            return stats\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error loading cached statistics: {e}. Recalculating...\")\n",
    "    \n",
    "    # Get path to real data\n",
    "    real_data_path = config.get_real_data_path()\n",
    "    logger.info(f\"Using real data from: {real_data_path}\")\n",
    "    \n",
    "    # Find all image files\n",
    "    image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff']\n",
    "    image_paths = []\n",
    "    for ext in image_extensions:\n",
    "        image_paths.extend(list(Path(real_data_path).glob(f\"*{ext}\")))\n",
    "    \n",
    "    if not image_paths:\n",
    "        logger.error(f\"No images found in {real_data_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Sample a subset of images for faster processing\n",
    "    max_images = min(len(image_paths), 20000) # default : 5000 ; alt : 20000 ; new : 60000 ;\n",
    "    sampled_paths = random.sample(image_paths, max_images)\n",
    "    \n",
    "    # Initialize statistics containers\n",
    "    widths = []\n",
    "    heights = []\n",
    "    sizes = []\n",
    "    brightness_values = []\n",
    "    contrast_values = []\n",
    "    histograms = []\n",
    "    \n",
    "    # Process each image\n",
    "    logger.info(f\"Processing {len(sampled_paths)} real images for statistics...\")\n",
    "    for path in tqdm(sampled_paths, desc=\"Analyzing real images\"):\n",
    "        try:\n",
    "            # Open image\n",
    "            img = Image.open(path)\n",
    "            \n",
    "            # Convert to grayscale if needed\n",
    "            if img.mode != 'L':\n",
    "                img = img.convert('L')\n",
    "            \n",
    "            # Record size statistics\n",
    "            width, height = img.size\n",
    "            widths.append(width)\n",
    "            heights.append(height)\n",
    "            sizes.append(width * height)\n",
    "            \n",
    "            # Convert to numpy for pixel analysis\n",
    "            img_np = np.array(img)\n",
    "            \n",
    "            # Calculate brightness (mean pixel value)\n",
    "            brightness = np.mean(img_np)\n",
    "            brightness_values.append(brightness)\n",
    "            \n",
    "            # Calculate contrast (standard deviation of pixel values)\n",
    "            contrast = np.std(img_np)\n",
    "            contrast_values.append(contrast)\n",
    "            \n",
    "            # Calculate histogram\n",
    "            hist, _ = np.histogram(img_np.flatten(), bins=256, range=(0, 255), density=True)\n",
    "            histograms.append(hist)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error processing image {path}: {e}\")\n",
    "    \n",
    "    # Compute summary statistics\n",
    "    if not widths:\n",
    "        logger.error(\"No valid images processed for statistics\")\n",
    "        return None\n",
    "    \n",
    "    stats = {\n",
    "        \"size_statistics\": {\n",
    "            \"width\": {\n",
    "                \"mean\": np.mean(widths),\n",
    "                \"std\": np.std(widths),\n",
    "                \"min\": np.min(widths),\n",
    "                \"max\": np.max(widths),\n",
    "                \"percentiles\": {\n",
    "                    \"25\": np.percentile(widths, 25),\n",
    "                    \"50\": np.percentile(widths, 50),\n",
    "                    \"75\": np.percentile(widths, 75)\n",
    "                }\n",
    "            },\n",
    "            \"height\": {\n",
    "                \"mean\": np.mean(heights),\n",
    "                \"std\": np.std(heights),\n",
    "                \"min\": np.min(heights),\n",
    "                \"max\": np.max(heights),\n",
    "                \"percentiles\": {\n",
    "                    \"25\": np.percentile(heights, 25),\n",
    "                    \"50\": np.percentile(heights, 50),\n",
    "                    \"75\": np.percentile(heights, 75)\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"pixel_statistics\": {\n",
    "            \"brightness\": {\n",
    "                \"mean\": np.mean(brightness_values),\n",
    "                \"std\": np.std(brightness_values)\n",
    "            },\n",
    "            \"contrast\": {\n",
    "                \"mean\": np.mean(contrast_values),\n",
    "                \"std\": np.std(contrast_values)\n",
    "            }\n",
    "        },\n",
    "        \"histogram\": {\n",
    "            \"mean\": np.mean(histograms, axis=0).tolist(),\n",
    "            \"std\": np.std(histograms, axis=0).tolist()\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"num_images_analyzed\": len(widths),\n",
    "            \"data_path\": real_data_path,\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Convert NumPy types to Python native types for JSON serialization\n",
    "    stats = convert_numpy_types(stats)\n",
    "    \n",
    "    # Save stats to cache file\n",
    "    os.makedirs(os.path.dirname(stats_cache_path), exist_ok=True)\n",
    "    with open(stats_cache_path, 'w') as f:\n",
    "        json.dump(stats, f, indent=4)\n",
    "    \n",
    "    logger.info(f\"Statistics calculated and saved to {stats_cache_path}\")\n",
    "    return stats\n",
    "\n",
    "# --- Load Layout Statistics ---\n",
    "def load_layout_statistics(config, logger):\n",
    "    \"\"\"Load layout statistics from JSON file.\"\"\"\n",
    "    try:\n",
    "        stats_file = os.path.join(config.STATISTICS_DIR, \"layout_statistics.json\")\n",
    "        logger.info(f\"Loading layout statistics from: {stats_file}\")\n",
    "        \n",
    "        if not os.path.exists(stats_file):\n",
    "            logger.warning(f\"Statistics file not found: {stats_file}\")\n",
    "            logger.info(\"Using default layout parameters based on provided averages\")\n",
    "            return None\n",
    "        \n",
    "        with open(stats_file, 'r') as f:\n",
    "            stats = json.load(f)\n",
    "        \n",
    "        logger.info(\"Layout statistics loaded successfully\")\n",
    "        return stats\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading layout statistics: {e}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        return None\n",
    "\n",
    "# --- Load Background Images ---\n",
    "def load_background_images(config, logger):\n",
    "    \"\"\"Load available background images from directory.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Loading background images from: {config.BACKGROUND_DIR}\")\n",
    "        bg_paths = []\n",
    "        \n",
    "        # Find all image files in background directory\n",
    "        for ext in ['.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff']:\n",
    "            bg_paths.extend(list(Path(config.BACKGROUND_DIR).glob(f\"*{ext}\")))\n",
    "        \n",
    "        if not bg_paths:\n",
    "            raise FileNotFoundError(f\"No background images found in {config.BACKGROUND_DIR}\")\n",
    "        \n",
    "        logger.info(f\"Found {len(bg_paths)} background images\")\n",
    "        return bg_paths\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading background images: {e}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        raise\n",
    "\n",
    "# --- Image Generation and Transformation ---\n",
    "@torch.no_grad()\n",
    "def generate_pollen_batch(generator, config, batch_size, device=None, noise_dim=None):\n",
    "    \"\"\"Generate a batch of pollen images with robust parameter handling.\"\"\"\n",
    "    # Handle device parameter\n",
    "    if device is None:\n",
    "        device = getattr(config, 'DEVICE', torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    \n",
    "    # Handle noise_dim parameter\n",
    "    if noise_dim is None:\n",
    "        noise_dim = getattr(config, 'NOISE_DIM', 100)  # Default to 100 if not specified\n",
    "    \n",
    "    # Check if generator should be moved to device\n",
    "    gen_device = next(generator.parameters()).device\n",
    "    temp_device_change = False\n",
    "    \n",
    "    if gen_device.type == 'cpu' and device.type == 'cuda' and getattr(config, 'LOAD_GENERATOR_TO_CPU', False):\n",
    "        generator = generator.to(device)\n",
    "        temp_device_change = True\n",
    "    \n",
    "    # Generate images\n",
    "    try:\n",
    "        # Generate random noise\n",
    "        noise = torch.randn(batch_size, noise_dim, 1, 1, device=device)\n",
    "        \n",
    "        # Generate image batch\n",
    "        fake_batch = generator(noise)\n",
    "        \n",
    "        # Convert tensor batch to list of PIL Images\n",
    "        images = []\n",
    "        for i in range(batch_size):\n",
    "            # Convert to numpy array\n",
    "            img_np = fake_batch[i].cpu().numpy()\n",
    "            \n",
    "            # Rescale from [-1, 1] to [0, 255]\n",
    "            img_np = ((img_np * 0.5 + 0.5) * 255).astype(np.uint8)\n",
    "            \n",
    "            # Convert to PIL Image (squeeze channel dimension)\n",
    "            img = Image.fromarray(img_np.squeeze(0), mode='L')\n",
    "            images.append(img)\n",
    "        \n",
    "        return images\n",
    "    finally:\n",
    "        # Move generator back to CPU if it was temporarily moved\n",
    "        if temp_device_change:\n",
    "            generator = generator.to(torch.device('cpu'))\n",
    "            # Force cleanup\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "@torch.no_grad()\n",
    "def score_pollen_batch(critic, images, config, device=None):\n",
    "    \"\"\"\n",
    "    Score a batch of PIL images using the critic model, processing in smaller chunks.\n",
    "    \"\"\"\n",
    "    if critic is None or not getattr(config, 'USE_QUALITY_FILTERING', False):\n",
    "        logger.warning(\"Critic scoring skipped (critic unavailable or filtering disabled). Returning NaNs.\")\n",
    "        return np.full(len(images), np.nan)\n",
    "\n",
    "    logger = logging.getLogger(\"GenerationEngine\") # Get logger\n",
    "    if device is None:\n",
    "        # Get device from config, ensure it's a torch.device object\n",
    "        device_setting = getattr(config, 'DEVICE', \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if isinstance(device_setting, str):\n",
    "             device = torch.device(device_setting)\n",
    "        elif isinstance(device_setting, torch.device):\n",
    "             device = device_setting\n",
    "        else: # Fallback if type is unexpected\n",
    "             logger.warning(f\"Unexpected device type in config: {type(device_setting)}. Falling back.\")\n",
    "             device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    elif isinstance(device, str): # Handle if device is passed as string argument\n",
    "        device = torch.device(device)\n",
    "    # Ensure device is a torch.device object now\n",
    "    if not isinstance(device, torch.device):\n",
    "         logger.error(f\"Device is not a torch.device object after processing: {device}. Defaulting to CPU.\")\n",
    "         device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "    # Get scoring batch size from config, default if not present\n",
    "    scoring_batch_size = getattr(config, 'SCORING_BATCH_SIZE', 128)\n",
    "    # Removed redundant logging of batch size here, happens inside loop now if needed\n",
    "\n",
    "    # If critic is on CPU but we need GPU, move temporarily\n",
    "    critic_device = next(critic.parameters()).device\n",
    "    temp_device_change = False\n",
    "    original_critic_device = critic_device # Store original device\n",
    "\n",
    "    # Check if critic needs moving (compare device types)\n",
    "    if critic_device.type == 'cpu' and device.type == 'cuda' and getattr(config, 'LOAD_CRITIC_TO_CPU', False):\n",
    "        logger.debug(f\"Temporarily moving critic to {device} for scoring.\")\n",
    "        critic.to(device)\n",
    "        temp_device_change = True\n",
    "        critic_device = device # Update current device\n",
    "\n",
    "    all_scores = []\n",
    "    try:\n",
    "        num_images = len(images)\n",
    "        # Add leave=False to the tqdm call here\n",
    "        #for i in tqdm(range(0, num_images, scoring_batch_size), desc=\"Scoring images\", leave=False): # <--- MODIFIED HERE\n",
    "        for i in range(0, num_images, scoring_batch_size): # <--- REPLACEMENT LINE (tqdm wrapper removed)\n",
    "            batch_images = images[i : min(i + scoring_batch_size, num_images)]\n",
    "            if not batch_images: continue\n",
    "\n",
    "            batch_tensors = []\n",
    "            for img in batch_images:\n",
    "                img_np = np.array(img, dtype=np.float32) / 255.0\n",
    "                img_np = (img_np - 0.5) / 0.5\n",
    "                # Add channel dim if it's grayscale\n",
    "                if len(img_np.shape) == 2:\n",
    "                    img_np = np.expand_dims(img_np, axis=0) # Add channel dim -> (1, H, W)\n",
    "\n",
    "                # Handle resizing if needed (shouldn't be needed for raw generated)\n",
    "                h, w = img_np.shape[1], img_np.shape[2]\n",
    "                base_h, base_w = config.POLLEN_SIZE_BASE, config.POLLEN_SIZE_BASE\n",
    "                if h != base_h or w != base_w:\n",
    "                    # Need to convert back to PIL temporarily for resize, then back to numpy/tensor\n",
    "                    # This is inefficient, avoid passing transformed images if possible\n",
    "                    img_pil_tmp = Image.fromarray(((img_np * 0.5 + 0.5) * 255).astype(np.uint8).squeeze()).resize((base_w, base_h), Image.BILINEAR)\n",
    "                    img_np = (np.array(img_pil_tmp, dtype=np.float32) / 255.0 - 0.5) / 0.5\n",
    "                    if len(img_np.shape) == 2: img_np = np.expand_dims(img_np, axis=0) # Re-add channel if lost\n",
    "\n",
    "                img_tensor = torch.from_numpy(img_np)\n",
    "                batch_tensors.append(img_tensor)\n",
    "\n",
    "\n",
    "            if not batch_tensors: continue\n",
    "\n",
    "            try:\n",
    "                # Stack tensors for the CURRENT BATCH ONLY\n",
    "                batch_tensor = torch.stack(batch_tensors).to(device) # Move batch to device\n",
    "            except RuntimeError as stack_err:\n",
    "                 logger.error(f\"Error stacking tensors during scoring: {stack_err}\")\n",
    "                 logger.error(f\"Shapes in batch: {[t.shape for t in batch_tensors]}\")\n",
    "                 all_scores.append(np.full(len(batch_images), np.nan)) # Append NaNs for this failed batch\n",
    "                 continue # Skip this batch\n",
    "\n",
    "            # Get critic scores for the current batch\n",
    "            try:\n",
    "                scores = critic(batch_tensor).squeeze().cpu().numpy()\n",
    "                if scores.ndim == 0: scores = np.array([scores.item()])\n",
    "                all_scores.append(scores)\n",
    "            except torch.OutOfMemoryError as oom_err:\n",
    "                 logger.error(f\"OOM Error during critic forward pass with batch size {len(batch_tensor)}. Try reducing SCORING_BATCH_SIZE.\")\n",
    "                 logger.error(f\"OOM Details: {oom_err}\")\n",
    "                 raise oom_err # Re-raise OOM\n",
    "            except Exception as forward_err:\n",
    "                 logger.error(f\"Error during critic forward pass: {forward_err}\", exc_info=True)\n",
    "                 all_scores.append(np.full(len(batch_tensor), np.nan))\n",
    "\n",
    "            # Cleanup GPU memory for the batch\n",
    "            del batch_tensor, batch_tensors, scores\n",
    "            if device.type == 'cuda': # <-- Now device is guaranteed to be torch.device\n",
    "                 force_memory_cleanup(config)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred during batched scoring: {e}\", exc_info=True)\n",
    "        return np.full(len(images), np.nan)\n",
    "    finally:\n",
    "        # Move critic back to original device if it was temporarily moved\n",
    "        if temp_device_change:\n",
    "            logger.debug(f\"Moving critic back to {original_critic_device}.\")\n",
    "            critic.to(original_critic_device)\n",
    "            if device.type == 'cuda': force_memory_cleanup(config) # <-- Check works now\n",
    "\n",
    "    # Concatenate scores from all batches\n",
    "    if not all_scores:\n",
    "        logger.warning(\"No scores were generated.\")\n",
    "        return np.array([])\n",
    "\n",
    "    try:\n",
    "        final_scores = np.concatenate(all_scores)\n",
    "        if len(final_scores) != len(images):\n",
    "             logger.warning(f\"Number of scores ({len(final_scores)}) does not match number of images ({len(images)}). Padding with NaN.\")\n",
    "             padded_scores = np.full(len(images), np.nan)\n",
    "             length_to_copy = min(len(final_scores), len(images))\n",
    "             padded_scores[:length_to_copy] = final_scores[:length_to_copy]\n",
    "             return padded_scores\n",
    "        return final_scores\n",
    "    except ValueError as concat_err:\n",
    "         logger.error(f\"Error concatenating scores: {concat_err}\")\n",
    "         # logger.error(f\"Score list content (lengths): {[len(s) if isinstance(s, np.ndarray) else 'NaN_batch' for s in all_scores]}\")\n",
    "         return np.full(len(images), np.nan)\n",
    "\n",
    "def filter_pollen_batch(scores, images, num_required, config):\n",
    "    \"\"\"Filter pollen images based on critic scores using percentile threshold.\"\"\"\n",
    "    if not getattr(config, 'USE_QUALITY_FILTERING', False):\n",
    "        # Return the first num_required images if filtering is disabled\n",
    "        return images[:num_required]\n",
    "    \n",
    "    # Ensure we have enough images\n",
    "    if len(images) < num_required:\n",
    "        return images\n",
    "    \n",
    "    # Get percentile threshold or default to 80%\n",
    "    threshold_percentile = getattr(config, 'QUALITY_THRESHOLD_PERCENTILE', 80.0)\n",
    "    \n",
    "    # Calculate threshold based on percentile\n",
    "    threshold = np.percentile(scores, 100 - threshold_percentile)\n",
    "    \n",
    "    # Get indices of images above threshold\n",
    "    quality_indices = np.where(scores >= threshold)[0]\n",
    "    \n",
    "    # If we have enough quality images, use them\n",
    "    if len(quality_indices) >= num_required:\n",
    "        # Sort the quality indices by score (highest first)\n",
    "        sorted_quality_indices = quality_indices[np.argsort(scores[quality_indices])[::-1]]\n",
    "        # Take the top num_required\n",
    "        selected_indices = sorted_quality_indices[:num_required]\n",
    "    else:\n",
    "        # If not enough quality images, sort all and take top num_required\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "        selected_indices = sorted_indices[:num_required]\n",
    "    \n",
    "    # Return the selected images\n",
    "    return [images[i] for i in selected_indices]\n",
    "\n",
    "def apply_geometric_transforms(img_pil, config, real_stats=None):\n",
    "    \"\"\"Apply geometric transformations to a pollen image with independent width/height scaling.\"\"\"\n",
    "    img = img_pil.copy()\n",
    "    \n",
    "    # --- 1. Apply rotation ---\n",
    "    # Only use 0, 90, 180, 270 degree rotations\n",
    "    rotation = random.choice([0, 90, 180, 270])\n",
    "    if rotation > 0:\n",
    "        img = img.rotate(rotation, resample=Image.BICUBIC, expand=False)\n",
    "    \n",
    "    # --- 2. Apply scaling with different aspect ratios ---\n",
    "    if config.USE_RANDOM_SCALES:\n",
    "        if config.USE_STATS_MATCHING_SIZE and real_stats and 'size_statistics' in real_stats:\n",
    "            # Use real statistics to guide scaling\n",
    "            size_stats = real_stats['size_statistics']\n",
    "            \n",
    "            # Get mean and std from statistics\n",
    "            mean_width = size_stats['width']['mean']\n",
    "            std_width = size_stats['width']['std']\n",
    "            mean_height = size_stats['height']['mean']\n",
    "            std_height = size_stats['height']['std']\n",
    "            \n",
    "            # Sample width and height independently to get rectangular images\n",
    "            target_width = max(10, np.random.normal(mean_width, std_width/2))\n",
    "            target_height = max(10, np.random.normal(mean_height, std_height/2))\n",
    "            \n",
    "            # Calculate separate scale factors for width and height\n",
    "            scale_x = target_width / img.width\n",
    "            scale_y = target_height / img.height\n",
    "        else:\n",
    "            # Use uniform random scaling with independent x/y scales\n",
    "            scale_x = random.uniform(config.SCALE_RANGE[0], config.SCALE_RANGE[1])\n",
    "            scale_y = random.uniform(config.SCALE_RANGE[0], config.SCALE_RANGE[1])\n",
    "        \n",
    "        # Apply scaling (if different from original)\n",
    "        if scale_x != 1.0 or scale_y != 1.0:\n",
    "            new_width = int(img.width * scale_x)\n",
    "            new_height = int(img.height * scale_y)\n",
    "            img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Also update the Config class to use proper rotation settings\n",
    "\n",
    "def apply_histogram_matching(source_img, reference_img, config):\n",
    "    \"\"\"Apply histogram matching to make source image match reference histogram.\"\"\"\n",
    "    if not config.USE_STATS_MATCHING_HISTOGRAM:\n",
    "        return source_img\n",
    "    \n",
    "    try:\n",
    "        # Convert PIL images to numpy arrays\n",
    "        source_np = np.array(source_img)\n",
    "        reference_np = np.array(reference_img)\n",
    "        \n",
    "        # Apply histogram matching\n",
    "        matched_np = match_histograms(source_np, reference_np)\n",
    "        \n",
    "        # Convert back to PIL\n",
    "        matched_img = Image.fromarray(matched_np.astype(np.uint8))\n",
    "        return matched_img\n",
    "    except Exception as e:\n",
    "        # On error, return original image\n",
    "        return source_img\n",
    "\n",
    "# --- Blending Functions ---\n",
    "def create_binary_mask(img):\n",
    "    \"\"\"Create a binary mask from a grayscale image.\"\"\"\n",
    "    img_np = np.array(img)\n",
    "    # Threshold to create binary mask (non-zero pixels become 255)\n",
    "    mask_np = (img_np > 10).astype(np.uint8) * 255\n",
    "    return Image.fromarray(mask_np, mode='L')\n",
    "\n",
    "def create_content_aware_mask(img, feather_amount=10):\n",
    "    \"\"\"Create a content-aware mask with feathered edges.\"\"\"\n",
    "    if not img:\n",
    "        return None\n",
    "    \n",
    "    # Create initial binary mask\n",
    "    img_np = np.array(img)\n",
    "    _, binary_mask = cv2.threshold(img_np, 10, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Apply edge detection\n",
    "    edges = cv2.Canny(binary_mask, 100, 200)\n",
    "    \n",
    "    # Dilate edges\n",
    "    kernel = np.ones((feather_amount, feather_amount), np.uint8)\n",
    "    edge_zone = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # Create distance transform inside the mask\n",
    "    dist_transform = cv2.distanceTransform(binary_mask, cv2.DIST_L2, 3)\n",
    "    \n",
    "    # Normalize distance transform to 0-255\n",
    "    cv2.normalize(dist_transform, dist_transform, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Create soft mask by combining binary mask and feathered edges\n",
    "    soft_mask = binary_mask.copy()\n",
    "    soft_mask[edge_zone > 0] = dist_transform[edge_zone > 0].astype(np.uint8)\n",
    "    \n",
    "    # Apply Gaussian blur for smoother transition\n",
    "    soft_mask = cv2.GaussianBlur(soft_mask, (feather_amount*2+1, feather_amount*2+1), 0)\n",
    "    \n",
    "    return Image.fromarray(soft_mask, mode='L')\n",
    "\n",
    "def convert_to_3channel(img):\n",
    "    \"\"\"Convert single-channel grayscale image to 3-channel.\"\"\"\n",
    "    if img.mode == 'L':\n",
    "        return Image.merge('RGB', (img, img, img))\n",
    "    return img\n",
    "\n",
    "def apply_alpha_blending(background, foreground, position, mask):\n",
    "    \"\"\"Apply alpha blending using a mask.\"\"\"\n",
    "    # Convert to RGB if grayscale\n",
    "    bg = convert_to_3channel(background)\n",
    "    fg = convert_to_3channel(foreground)\n",
    "    \n",
    "    # Create a copy of background\n",
    "    result = bg.copy()\n",
    "    \n",
    "    # Paste using the mask\n",
    "    result.paste(fg, position, mask)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def apply_poisson_blending(background, foreground, position, mask=None):\n",
    "    \"\"\"Apply seamless cloning (Poisson blending) using OpenCV.\"\"\"\n",
    "    # Convert PIL to CV2 format (RGB to BGR)\n",
    "    bg_cv = cv2.cvtColor(np.array(background), cv2.COLOR_RGB2BGR)\n",
    "    fg_cv = cv2.cvtColor(np.array(foreground), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Create mask if not provided\n",
    "    if mask is None:\n",
    "        mask_cv = create_binary_mask(foreground)\n",
    "        mask_cv = np.array(mask_cv)\n",
    "    else:\n",
    "        mask_cv = np.array(mask)\n",
    "    \n",
    "    # Check if mask is valid\n",
    "    if mask_cv.max() == 0:\n",
    "        # No valid mask points, fall back to alpha blending\n",
    "        return apply_alpha_blending(background, foreground, position, mask)\n",
    "    \n",
    "    # Define center point for seamless cloning\n",
    "    center = (position[0] + foreground.width // 2, position[1] + foreground.height // 2)\n",
    "    \n",
    "    try:\n",
    "        # Apply seamless cloning\n",
    "        result_cv = cv2.seamlessClone(\n",
    "            fg_cv, bg_cv, mask_cv, center, cv2.MIXED_CLONE\n",
    "        ) # default : \"cv2.MIXED_CLONE' (causes issues upon use after histogram matching) ; alt : cv2.NORMAL_CLONE (causes issues even without histogram matching)\n",
    "        \n",
    "        # Convert back to PIL\n",
    "        result = Image.fromarray(cv2.cvtColor(result_cv, cv2.COLOR_BGR2RGB))\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        # If seamless cloning fails, fall back to alpha blending\n",
    "        return apply_alpha_blending(background, foreground, position, mask)\n",
    "\n",
    "def apply_pyramid_blending(background, foreground, position, mask, levels=4):\n",
    "    \"\"\"Apply Laplacian pyramid blending.\"\"\"\n",
    "    # Convert PIL to numpy\n",
    "    bg_np = np.array(convert_to_3channel(background))\n",
    "    fg_np = np.array(convert_to_3channel(foreground))\n",
    "    mask_np = np.array(mask)\n",
    "    \n",
    "    # Create region of interest in background\n",
    "    x, y = position\n",
    "    h, w = fg_np.shape[:2]\n",
    "    \n",
    "    # Ensure coordinates are within bounds\n",
    "    if x < 0 or y < 0 or x + w > bg_np.shape[1] or y + h > bg_np.shape[0]:\n",
    "        # If out of bounds, fall back to alpha blending\n",
    "        return apply_alpha_blending(background, foreground, position, mask)\n",
    "    \n",
    "    # Extract ROI from background\n",
    "    roi = bg_np[y:y+h, x:x+w].copy()\n",
    "    \n",
    "    # Ensure all images have the same dimensions\n",
    "    if roi.shape[:2] != fg_np.shape[:2] or roi.shape[:2] != mask_np.shape:\n",
    "        # Resize to match\n",
    "        fg_np = cv2.resize(fg_np, (roi.shape[1], roi.shape[0]))\n",
    "        mask_np = cv2.resize(mask_np, (roi.shape[1], roi.shape[0]))\n",
    "    \n",
    "    # Normalize mask to range [0, 1]\n",
    "    mask_np = mask_np.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Add channel dimension to mask if needed\n",
    "    if len(mask_np.shape) == 2:\n",
    "        mask_np = np.stack([mask_np] * 3, axis=2)\n",
    "    \n",
    "    try:\n",
    "        # Apply pyramid blending to each channel\n",
    "        result_np = np.zeros_like(roi)\n",
    "        \n",
    "        for ch in range(3):\n",
    "            # Build Gaussian pyramid for each image\n",
    "            bg_pyr = [roi[:,:,ch]]\n",
    "            fg_pyr = [fg_np[:,:,ch]]\n",
    "            mask_pyr = [mask_np[:,:,ch]]\n",
    "            \n",
    "            for i in range(levels):\n",
    "                bg_pyr.append(cv2.pyrDown(bg_pyr[-1]))\n",
    "                fg_pyr.append(cv2.pyrDown(fg_pyr[-1]))\n",
    "                mask_pyr.append(cv2.pyrDown(mask_pyr[-1]))\n",
    "            \n",
    "            # Build Laplacian pyramid for bg and fg\n",
    "            bg_lap = []\n",
    "            fg_lap = []\n",
    "            \n",
    "            for i in range(levels, 0, -1):\n",
    "                bg_lap.append(bg_pyr[i-1] - cv2.pyrUp(cv2.resize(bg_pyr[i], (bg_pyr[i-1].shape[1], bg_pyr[i-1].shape[0]))))\n",
    "                fg_lap.append(fg_pyr[i-1] - cv2.pyrUp(cv2.resize(fg_pyr[i], (fg_pyr[i-1].shape[1], fg_pyr[i-1].shape[0]))))\n",
    "            \n",
    "            # Add deepest level\n",
    "            bg_lap.append(bg_pyr[-1])\n",
    "            fg_lap.append(fg_pyr[-1])\n",
    "            \n",
    "            # Blend pyramids\n",
    "            blended_pyr = []\n",
    "            for i in range(len(bg_lap)):\n",
    "                blended_pyr.append(mask_pyr[min(i, len(mask_pyr)-1)] * fg_lap[i] + \n",
    "                                  (1 - mask_pyr[min(i, len(mask_pyr)-1)]) * bg_lap[i])\n",
    "            \n",
    "            # Reconstruct blended image\n",
    "            blended = blended_pyr[-1]\n",
    "            for i in range(len(blended_pyr)-2, -1, -1):\n",
    "                blended = cv2.pyrUp(cv2.resize(blended, (blended_pyr[i].shape[1], blended_pyr[i].shape[0])))\n",
    "                blended = cv2.add(blended, blended_pyr[i])\n",
    "            \n",
    "            result_np[:,:,ch] = blended\n",
    "        \n",
    "        # Insert blended result into background\n",
    "        result_full = bg_np.copy()\n",
    "        result_full[y:y+h, x:x+w] = result_np\n",
    "        \n",
    "        # Convert back to PIL\n",
    "        result = Image.fromarray(result_full.astype(np.uint8))\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        # If pyramid blending fails, fall back to alpha blending\n",
    "        return apply_alpha_blending(background, foreground, position, mask)\n",
    "\n",
    "def blend_pollen_onto_background(background, pollen, position, config):\n",
    "    \"\"\"Apply the selected blending method.\"\"\"\n",
    "    logger = logging.getLogger(\"GenerationEngine\") # Ensure logger is accessible\n",
    "    mask = None # Initialize mask\n",
    "\n",
    "    # --- Optional Pre-adjust contrast if you add it back later ---\n",
    "    # adjusted_pollen = pollen\n",
    "    # if getattr(config, 'ADJUST_POLLEN_CONTRAST', False):\n",
    "    #    # ... (contrast adjustment code would go here) ...\n",
    "    #    # Pass adjusted_pollen below instead of pollen if implemented\n",
    "    # else:\n",
    "    #    adjusted_pollen = pollen # Use original if no adjustment\n",
    "    # For now, we use the original 'pollen' input directly\n",
    "    adjusted_pollen = pollen\n",
    "    # ---\n",
    "\n",
    "    if config.BLENDING_METHOD == \"poisson\":\n",
    "        mask = create_binary_mask(pollen) # Poisson uses binary mask\n",
    "        if mask is None:\n",
    "             logger.error(\"Failed to create binary mask for Poisson blending.\")\n",
    "             return background # Return original background on failure\n",
    "        return apply_poisson_blending(background, adjusted_pollen, position, mask)\n",
    "\n",
    "    elif config.BLENDING_METHOD == \"pyramid\":\n",
    "        # Use content-aware mask if flag is set, otherwise fallback to binary\n",
    "        # Passing None to apply_pyramid_blending is likely incorrect, so always create a mask.\n",
    "        if getattr(config, 'USE_CONTENT_AWARE_MASKS', False): # Check if attr exists and is True\n",
    "             mask = create_content_aware_mask(pollen, config.FEATHER_AMOUNT)\n",
    "        else:\n",
    "             mask = create_binary_mask(pollen) # Fallback for pyramid if content aware is off\n",
    "\n",
    "        if mask is None:\n",
    "             logger.error(\"Failed to create mask for Pyramid blending.\")\n",
    "             return background # Return original background on failure\n",
    "        return apply_pyramid_blending(background, adjusted_pollen, position, mask, config.PYRAMID_LEVELS)\n",
    "\n",
    "    else:  # Alpha blending or fallback\n",
    "        logger.debug(\"Using Alpha blending with Elliptical mask.\")\n",
    "        # --- MODIFIED HERE: Always use elliptical mask for alpha/fallback ---\n",
    "        mask = create_elliptical_mask(adjusted_pollen, config.FEATHER_AMOUNT)\n",
    "        # --- End Modification ---\n",
    "\n",
    "        # Check if mask creation succeeded\n",
    "        if mask is None:\n",
    "             logger.error(\"Failed to create elliptical mask for Alpha blending. Returning original background.\")\n",
    "             # Attempt fallback to binary mask if elliptical failed? Optional.\n",
    "             # mask = create_binary_mask(pollen)\n",
    "             # if mask is None: return background\n",
    "             return background # Return original background if mask fails\n",
    "\n",
    "        # Apply alpha blending using the generated elliptical mask\n",
    "        return apply_alpha_blending(background, adjusted_pollen, position, mask)\n",
    "\n",
    "# --- Position Generation ---\n",
    "def generate_non_overlapping_positions(count, img_size, min_obj_size, margin):\n",
    "    \"\"\"Generate non-overlapping positions for placing pollen on the background.\"\"\"\n",
    "    positions = []\n",
    "    max_attempts = count * 10  # Limit attempts to avoid infinite loops\n",
    "    \n",
    "    # Effective area for placement\n",
    "    valid_min = margin\n",
    "    valid_max = img_size - min_obj_size - margin\n",
    "    \n",
    "    if valid_max <= valid_min:\n",
    "        raise ValueError(f\"Can't place objects: margin ({margin}) too large for image size ({img_size}) and object size ({min_obj_size})\")\n",
    "    \n",
    "    attempt = 0\n",
    "    while len(positions) < count and attempt < max_attempts:\n",
    "        attempt += 1\n",
    "        \n",
    "        # Generate random position\n",
    "        x = random.randint(valid_min, valid_max)\n",
    "        y = random.randint(valid_min, valid_max)\n",
    "        \n",
    "        # Check for overlap with existing positions\n",
    "        overlap = False\n",
    "        for existing_x, existing_y in positions:\n",
    "            # Calculate center-to-center distance\n",
    "            distance = np.sqrt((x - existing_x)**2 + (y - existing_y)**2)\n",
    "            \n",
    "            # Check if distance is less than the minimum object size with a small buffer\n",
    "            if distance < min_obj_size * 0.9:\n",
    "                overlap = True\n",
    "                break\n",
    "        \n",
    "        if not overlap:\n",
    "            positions.append((x, y))\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def determine_pollen_count(layout_stats=None, avg_count=None):\n",
    "    \"\"\"Determine how many pollen to place on each background.\"\"\"\n",
    "    if layout_stats and 'summary' in layout_stats:\n",
    "        # Get mean and std from statistics\n",
    "        mean = layout_stats['summary']['num_valid_objects_per_image']['mean']\n",
    "        std = layout_stats['summary']['num_valid_objects_per_image']['std']\n",
    "        \n",
    "        # Generate a random count based on normal distribution\n",
    "        count = max(1, int(np.random.normal(mean, std / 4)))  # Divide std by 4 to avoid extreme values\n",
    "    elif avg_count:\n",
    "        # Generate a random count around the average\n",
    "        count = max(1, int(np.random.normal(avg_count, avg_count / 4)))\n",
    "    else:\n",
    "        # Fallback to a reasonable default range\n",
    "        count = random.randint(5, 25)\n",
    "    \n",
    "    return count\n",
    "\n",
    "def generate_yolo_annotation(positions_and_sizes, img_size, obj_class=0):\n",
    "    \"\"\"Generate YOLO annotation format for object detection.\"\"\"\n",
    "    annotations = []\n",
    "    \n",
    "    for (x, y), (width, height) in positions_and_sizes:\n",
    "        # Calculate center coordinates and normalized dimensions\n",
    "        center_x = (x + width / 2) / img_size\n",
    "        center_y = (y + height / 2) / img_size\n",
    "        norm_width = width / img_size\n",
    "        norm_height = height / img_size\n",
    "        \n",
    "        # Format: class x_center y_center width height\n",
    "        annotations.append(f\"{obj_class} {center_x:.6f} {center_y:.6f} {norm_width:.6f} {norm_height:.6f}\")\n",
    "    \n",
    "    return \"\\n\".join(annotations)\n",
    "\n",
    "# --- Analysis and Visualization ---\n",
    "\n",
    "#def extract_image_features(images, batch_size=64, device=None):\n",
    "#    \"\"\"Extract features from images using a feature extractor network.\"\"\"\n",
    "\n",
    "# --- Replace the old extract_image_features function ---\n",
    "\n",
    "def extract_features(data, inception_model, config, is_real=False):\n",
    "    \"\"\"\n",
    "    Extract features from real or generated images using InceptionV3.\n",
    "    Handles both list of file paths and list of PIL Images.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"GenerationEngine\") # Get logger instance\n",
    "    num_samples = len(data)\n",
    "    desc = \"Processing real images\" if is_real else \"Processing generated images\"\n",
    "    logger.info(f\"Extracting features from {num_samples} {desc.split(' ')[1]} images...\")\n",
    "    log_memory_usage(logger, f\"Before {desc} features\")\n",
    "\n",
    "    all_features = []\n",
    "    batch_size = config.FEATURE_EXTRACTION_BATCH_SIZE\n",
    "    device = config.DEVICE\n",
    "\n",
    "    # Define transforms (consistent with model-evaluation)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((config.POLLEN_SIZE_BASE, config.POLLEN_SIZE_BASE)), # Use base pollen size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5] * config.CHANNELS_IMG, [0.5] * config.CHANNELS_IMG) # Match GAN output range\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(0, num_samples, batch_size), desc=desc, leave=True):\n",
    "                batch_data = data[i:min(i + batch_size, num_samples)]\n",
    "                batch_tensors = []\n",
    "\n",
    "                for item in batch_data:\n",
    "                    try:\n",
    "                        # Fixed code\n",
    "                        if isinstance(item, (str, Path)):  # It's a path (string or Path object)\n",
    "                            img = Image.open(str(item)).convert('L' if config.CHANNELS_IMG == 1 else 'RGB')\n",
    "                        elif isinstance(item, Image.Image):  # It's a PIL image\n",
    "                            img = item.convert('L' if config.CHANNELS_IMG == 1 else 'RGB')\n",
    "                        else:\n",
    "                            logger.warning(f\"Skipping unsupported data type: {type(item)}\")\n",
    "                            continue\n",
    "                        img_tensor = transform(img)\n",
    "                        batch_tensors.append(img_tensor)\n",
    "                    except Exception as e:\n",
    "                         logger.warning(f\"Error loading/transforming image {item}: {e}. Skipping.\")\n",
    "                         continue # Skip problematic images\n",
    "\n",
    "                if not batch_tensors:\n",
    "                    continue\n",
    "\n",
    "                batch = torch.stack(batch_tensors).to(device)\n",
    "\n",
    "                # Handle grayscale (Inception expects RGB)\n",
    "                if batch.shape[1] == 1:\n",
    "                    batch = batch.repeat(1, 3, 1, 1)\n",
    "\n",
    "                # --- IMPORTANT: Normalization for Inception ---\n",
    "                # The model-evaluation script used (batch + 1) / 2.\n",
    "                # This assumes the Inception model expects [0, 1] range.\n",
    "                # We replicate that here for consistency.\n",
    "                batch = (batch + 1) / 2\n",
    "\n",
    "                # Get features\n",
    "                features = inception_model(batch)[0]\n",
    "\n",
    "                # Pool features\n",
    "                if features.shape[2] != 1 or features.shape[3] != 1:\n",
    "                    features = F.adaptive_avg_pool2d(features, output_size=(1, 1))\n",
    "\n",
    "                # Reshape and move to CPU\n",
    "                features = features.squeeze(-1).squeeze(-1).cpu().numpy()\n",
    "                all_features.append(features)\n",
    "\n",
    "                # Memory cleanup\n",
    "                del batch, features, batch_tensors\n",
    "                if i % 10 == 0: # Cleanup less frequently than every batch\n",
    "                    force_memory_cleanup(config)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "         logger.error(f\"Error during feature extraction: {e}\", exc_info=True)\n",
    "         return None # Indicate failure\n",
    "    finally:\n",
    "         force_memory_cleanup(config) # Final cleanup\n",
    "\n",
    "    if not all_features:\n",
    "        logger.error(f\"Failed to extract any features for {desc}\")\n",
    "        return None\n",
    "\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    logger.info(f\"Extracted features from {all_features.shape[0]} images, shape: {all_features.shape}\")\n",
    "    log_memory_usage(logger, f\"After {desc} features\")\n",
    "    return all_features\n",
    "\n",
    "#def generate_tsne_plot(real_features, gen_features, title, output_path):\n",
    "#    \"\"\"Generate t-SNE visualization of real vs. generated image features.\"\"\"\n",
    "\n",
    "# --- Modify generate_tsne_plot ---\n",
    "def generate_tsne_plot(real_features, gen_features, title, output_path, config):\n",
    "    \"\"\"Generate t-SNE visualization of real vs. generated image features.\"\"\"\n",
    "    logger = logging.getLogger(\"GenerationEngine\")\n",
    "    if not TSNE_AVAILABLE:\n",
    "        logger.error(\"Cannot generate t-SNE plot: scikit-learn TSNE not available.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        num_points = len(real_features) + len(gen_features)\n",
    "        logger.info(f\"Preparing {num_points} points ({len(real_features)} real vs {len(gen_features)} generated) for t-SNE...\")\n",
    "        all_features = np.vstack([real_features, gen_features])\n",
    "\n",
    "        # Apply t-SNE (using config seed)\n",
    "        logger.info(f\"Computing t-SNE (perplexity=30, init='pca', lr='auto', n_jobs=-1)... (Check console for verbose progress)\")\n",
    "        tsne_start_time = time.time() # Time the calculation\n",
    "        tsne = TSNE(n_components=2, perplexity=30,\n",
    "                    learning_rate='auto',\n",
    "                    init='pca',\n",
    "                    random_state=config.RANDOM_SEED,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=1) # <<<--- SET verbose=1 FOR PROGRESS OUTPUT\n",
    "        embeddings = tsne.fit_transform(all_features)\n",
    "        tsne_duration = time.time() - tsne_start_time\n",
    "        logger.info(f\"t-SNE computation finished in {tsne_duration:.3f} seconds.\")\n",
    "\n",
    "        # Split back into real and generated\n",
    "        real_count = real_features.shape[0]\n",
    "        real_embeddings = embeddings[:real_count]\n",
    "        gen_embeddings = embeddings[real_count:]\n",
    "\n",
    "        # Plot\n",
    "        logger.info(f\"Generating plot file: {output_path}\")\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.scatter(real_embeddings[:, 0], real_embeddings[:, 1], alpha=0.7,\n",
    "                    s=5, label='Real Images', c='blue')\n",
    "        plt.scatter(gen_embeddings[:, 0], gen_embeddings[:, 1], alpha=0.7,\n",
    "                    s=5, label='Generated Images', c='red')\n",
    "\n",
    "        plt.title(f't-SNE Visualization: {title}\\n({num_points} points)') # Add point count to title\n",
    "        plt.legend(markerscale=3)\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path, dpi=300)\n",
    "        plt.close()\n",
    "        logger.info(f\"Saved t-SNE plot to {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating t-SNE plot: {e}\", exc_info=True)\n",
    "        # Attempt to clean up figure in case of error during saving\n",
    "        try:\n",
    "            plt.close()\n",
    "        except:\n",
    "            pass\n",
    "        return False\n",
    "\n",
    "#def generate_umap_plot(real_features, gen_features, title, output_path):\n",
    "#    \"\"\"Generate UMAP visualization of real vs. generated image features.\"\"\"\n",
    "\n",
    "# --- Modify generate_umap_plot ---\n",
    "def generate_umap_plot(real_features, gen_features, title, output_path, config): # Add config\n",
    "    \"\"\"Generate UMAP visualization of real vs. generated image features.\"\"\"\n",
    "    logger = logging.getLogger(\"GenerationEngine\")\n",
    "    if not HAS_UMAP:\n",
    "         logger.error(\"Cannot generate UMAP plot: umap-learn not available.\")\n",
    "         return False\n",
    "\n",
    "    try:\n",
    "        num_points = len(real_features) + len(gen_features)\n",
    "        logger.info(f\"Starting UMAP calculation for {num_points} points...\")\n",
    "        start_time = time.time()\n",
    "        # Combine features\n",
    "        all_features = np.vstack([real_features, gen_features])\n",
    "\n",
    "        # --- REMOVED StandardScaler ---\n",
    "        # scaler = StandardScaler()\n",
    "        # all_features = scaler.fit_transform(all_features)\n",
    "\n",
    "        # Apply UMAP (using config seed)\n",
    "        logger.info(\"Computing UMAP embedding...\")\n",
    "        reducer = UMAP(n_neighbors=15, min_dist=0.1, n_components=2,\n",
    "                       metric='euclidean', # Match evaluator\n",
    "                       random_state=config.RANDOM_SEED,\n",
    "                       verbose=True) # <-- Add verbosity\n",
    "                       \n",
    "        embeddings = reducer.fit_transform(all_features)\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "        logger.info(f\"UMAP calculation finished in {duration:.3f} seconds.\")\n",
    "\n",
    "        # Split back into real and generated\n",
    "        real_count = real_features.shape[0]\n",
    "        real_embeddings = embeddings[:real_count]\n",
    "        gen_embeddings = embeddings[real_count:]\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.scatter(real_embeddings[:, 0], real_embeddings[:, 1], alpha=0.7,\n",
    "                    s=5, label='Real Images', c='blue') # Smaller points\n",
    "        plt.scatter(gen_embeddings[:, 0], gen_embeddings[:, 1], alpha=0.7,\n",
    "                    s=5, label='Generated Images', c='red') # Smaller points\n",
    "\n",
    "        plt.title(f'UMAP Visualization: {title}')\n",
    "        plt.legend(markerscale=3) # Match legend style\n",
    "        plt.grid(alpha=0.3)      # Match grid style\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path, dpi=300)\n",
    "        plt.close()\n",
    "        logger.info(f\"Saved UMAP plot to {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating UMAP plot: {e}\", exc_info=True)\n",
    "        return False\n",
    "\n",
    "#def calculate_prdc_metrics(real_features, gen_features, nearest_k=5):\n",
    "#    \"\"\"Calculate Precision, Recall, Density, and Coverage metrics.\"\"\"\n",
    "\n",
    "# --- Replace the old calculate_prdc_metrics function ---\n",
    "\n",
    "def calculate_prdc_metrics(real_features, fake_features, config):\n",
    "    \"\"\"\n",
    "    Calculate Precision, Recall, Density and Coverage metrics.\n",
    "    Adapted from model-evaluation.ipynb.\n",
    "    Uses torch-fidelity if available, otherwise custom implementation.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"GenerationEngine\") # Get logger instance\n",
    "    metrics_results = {'individual': {}, 'mean': {}}\n",
    "\n",
    "    # Ensure features are numpy arrays\n",
    "    if not isinstance(real_features, np.ndarray): real_features = np.array(real_features)\n",
    "    if not isinstance(fake_features, np.ndarray): fake_features = np.array(fake_features)\n",
    "\n",
    "    # --- Try torch-fidelity first ---\n",
    "    if TORCH_FIDELITY_AVAILABLE:\n",
    "        try:\n",
    "            logger.info(\"Calculating P/R/D/C metrics using torch-fidelity...\")\n",
    "            eval_dir = os.path.join(config.OUTPUT_DIR, config.STATS_SUBDIR) # Save temp files here\n",
    "            os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "            real_features_path = os.path.join(eval_dir, \"temp_real_features.npz\")\n",
    "            fake_features_path = os.path.join(eval_dir, \"temp_fake_features.npz\")\n",
    "\n",
    "            np.savez(real_features_path, features=real_features)\n",
    "            np.savez(fake_features_path, features=fake_features)\n",
    "\n",
    "            metrics_dict = torch_fidelity.calculate_metrics(\n",
    "                input1=fake_features_path, # Input1 is usually fake/generated\n",
    "                input2=real_features_path, # Input2 is usually real\n",
    "                cuda=torch.cuda.is_available() and config.USE_GPU,\n",
    "                isc=False, fid=False, kid=False, verbose=False,\n",
    "                prc=True, # Calculate Precision-Recall-Coverage\n",
    "                prc_k=config.PR_K_VALUE, # Use K from config\n",
    "                cache=False\n",
    "            )\n",
    "\n",
    "            # Clean up temporary files\n",
    "            for path in [real_features_path, fake_features_path]:\n",
    "                if os.path.exists(path):\n",
    "                    try: os.remove(path)\n",
    "                    except OSError as e: logger.warning(f\"Could not remove temp file {path}: {e}\")\n",
    "\n",
    "            # Extract metrics\n",
    "            metrics = {\n",
    "                'precision': metrics_dict.get('precision', 0.0),\n",
    "                'recall': metrics_dict.get('recall', 0.0),\n",
    "                'density': metrics_dict.get('density', 0.0), # Density/Coverage might not always be calculated\n",
    "                'coverage': metrics_dict.get('coverage', 0.0)\n",
    "            }\n",
    "\n",
    "            if metrics_dict.get('precision') is not None and metrics_dict.get('recall') is not None:\n",
    "                 logger.info(f\"torch-fidelity P/R/D/C: P={metrics['precision']:.4f}, R={metrics['recall']:.4f}, D={metrics['density']:.6f}, C={metrics['coverage']:.4f}\")\n",
    "                 # Store results for both 'individual' and 'mean' keys for compatibility with report format\n",
    "                 metrics_results['individual'] = metrics.copy()\n",
    "                 metrics_results['mean'] = metrics.copy()\n",
    "                 return metrics_results\n",
    "            else:\n",
    "                logger.warning(\"torch-fidelity did not return precision/recall metrics. Falling back to custom.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"torch-fidelity calculation failed: {e}\")\n",
    "            logger.info(\"Falling back to custom P/R/D/C implementation...\")\n",
    "            # Clean up temp files in case of error\n",
    "            for path in [real_features_path, fake_features_path]:\n",
    "                if os.path.exists(path):\n",
    "                     try: os.remove(path)\n",
    "                     except OSError as e: logger.warning(f\"Could not remove temp file {path}: {e}\")\n",
    "\n",
    "    #\n",
    "    # --- Custom Implementation Fallback ---\n",
    "    if not NEIGHBORS_AVAILABLE:\n",
    "         logger.error(\"Cannot calculate custom P/R/D/C: sklearn.neighbors not available.\")\n",
    "         metrics_results['individual'] = {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
    "         metrics_results['mean'] = {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
    "         return metrics_results\n",
    "\n",
    "    try:\n",
    "        k = config.MANIFOLD_K\n",
    "        multiplier = config.DISTANCE_MULTIPLIER\n",
    "        subsample = config.SUBSAMPLE_MANIFOLD\n",
    "        num_real = len(real_features)\n",
    "        num_fake = len(fake_features)\n",
    "        subsample_size = 10000  # Size to subsample to if enabled\n",
    "        query_chunk_size = 5000  # Size for chunked queries, adjust based on memory\n",
    "\n",
    "        logger.info(f\"Calculating custom P/R/D/C (k={k}, multiplier={multiplier}, subsample={subsample})\")\n",
    "\n",
    "        # Subsampling logic - no change\n",
    "        if subsample and num_real > subsample_size:\n",
    "            logger.info(f\"Subsampling real features from {num_real} to {subsample_size} for manifold estimation\")\n",
    "            indices_real = np.random.choice(num_real, subsample_size, replace=False)\n",
    "            real_for_manifold = real_features[indices_real]\n",
    "        else:\n",
    "            real_for_manifold = real_features\n",
    "\n",
    "        if subsample and num_fake > subsample_size:\n",
    "            logger.info(f\"Subsampling fake features from {num_fake} to {subsample_size} for manifold estimation\")\n",
    "            indices_fake = np.random.choice(num_fake, subsample_size, replace=False)\n",
    "            fake_for_manifold = fake_features[indices_fake]\n",
    "        else:\n",
    "            fake_for_manifold = fake_features\n",
    "\n",
    "        # Calculate real manifold radii - no change\n",
    "        logger.debug(\"Fitting real manifold NN...\")\n",
    "        real_nn = NearestNeighbors(n_neighbors=k + 1, algorithm='ball_tree', n_jobs=-1)\n",
    "        real_nn.fit(real_for_manifold)\n",
    "        real_distances, _ = real_nn.kneighbors(real_for_manifold)\n",
    "        real_radii = real_distances[:, k] if k > 0 else np.zeros(len(real_for_manifold))\n",
    "\n",
    "        # Calculate fake manifold radii - no change\n",
    "        logger.debug(\"Fitting fake manifold NN...\")\n",
    "        fake_nn = NearestNeighbors(n_neighbors=k + 1, algorithm='ball_tree', n_jobs=-1)\n",
    "        fake_nn.fit(fake_for_manifold)\n",
    "        fake_distances, _ = fake_nn.kneighbors(fake_for_manifold)\n",
    "        fake_radii = fake_distances[:, k] if k > 0 else np.zeros(len(fake_for_manifold))\n",
    "\n",
    "        # --- Individual Distances Method (CHUNKED) ---\n",
    "        logger.info(\"Calculating metrics using individual distances (chunked)...\")\n",
    "\n",
    "        # --- CHUNKED Precision Calculation ---\n",
    "        logger.debug(\"Calculating precision (individual, chunked)...\")\n",
    "        real_nn_query = NearestNeighbors(n_neighbors=1, algorithm='ball_tree', n_jobs=-1)\n",
    "        real_nn_query.fit(real_for_manifold)  # Fit on manifold\n",
    "        \n",
    "        precision_in_threshold_count = 0\n",
    "        total_fake_samples = 0\n",
    "        \n",
    "        # Calculate number of chunks for progress reporting\n",
    "        fake_chunks = math.ceil(len(fake_features) / query_chunk_size)\n",
    "        logger.info(f\"Processing precision in {fake_chunks} chunks...\")\n",
    "        \n",
    "        # Process in chunks\n",
    "        with tqdm(total=len(fake_features), desc=\"PRDC Precision\") as pbar:\n",
    "            for i in range(0, len(fake_features), query_chunk_size):\n",
    "                chunk_end = min(i + query_chunk_size, len(fake_features))\n",
    "                fake_chunk = fake_features[i:chunk_end]\n",
    "                chunk_size = len(fake_chunk)\n",
    "                \n",
    "                if chunk_size == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Query nearest neighbors for this chunk\n",
    "                precision_distances, closest_real_idx = real_nn_query.kneighbors(fake_chunk)\n",
    "                \n",
    "                # Get the radii for these nearest neighbors\n",
    "                if subsample and num_real > subsample_size:\n",
    "                    # Map indices back to the subsampled manifold\n",
    "                    closest_real_radii = np.array([real_radii[idx] for idx in closest_real_idx.flatten()])\n",
    "                else:\n",
    "                    closest_real_radii = np.array([real_radii[idx] for idx in closest_real_idx.flatten()])\n",
    "                \n",
    "                # Calculate thresholds for this chunk\n",
    "                threshold_precision = closest_real_radii * multiplier\n",
    "                \n",
    "                # Count samples within threshold\n",
    "                in_threshold = np.sum(precision_distances.flatten() <= threshold_precision)\n",
    "                precision_in_threshold_count += in_threshold\n",
    "                total_fake_samples += chunk_size\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.update(chunk_size)\n",
    "                \n",
    "                # Clean up chunk data\n",
    "                del fake_chunk, precision_distances, closest_real_idx, closest_real_radii, threshold_precision\n",
    "                if i % (2 * query_chunk_size) == 0:  # Less frequent cleanup\n",
    "                    gc.collect()\n",
    "        \n",
    "        # Calculate final precision\n",
    "        precision_individual = precision_in_threshold_count / total_fake_samples if total_fake_samples > 0 else 0.0\n",
    "        \n",
    "        # --- CHUNKED Recall Calculation ---\n",
    "        logger.debug(\"Calculating recall (individual, chunked)...\")\n",
    "        fake_nn_query = NearestNeighbors(n_neighbors=1, algorithm='ball_tree', n_jobs=-1)\n",
    "        fake_nn_query.fit(fake_for_manifold)  # Fit on manifold\n",
    "        \n",
    "        recall_in_threshold_count = 0\n",
    "        total_real_samples = 0\n",
    "        \n",
    "        # Calculate number of chunks for progress reporting\n",
    "        real_chunks = math.ceil(len(real_features) / query_chunk_size)\n",
    "        logger.info(f\"Processing recall in {real_chunks} chunks...\")\n",
    "        \n",
    "        # Process in chunks\n",
    "        with tqdm(total=len(real_features), desc=\"PRDC Recall\") as pbar:\n",
    "            for i in range(0, len(real_features), query_chunk_size):\n",
    "                chunk_end = min(i + query_chunk_size, len(real_features))\n",
    "                real_chunk = real_features[i:chunk_end]\n",
    "                chunk_size = len(real_chunk)\n",
    "                \n",
    "                if chunk_size == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Query nearest neighbors for this chunk\n",
    "                recall_distances, closest_fake_idx = fake_nn_query.kneighbors(real_chunk)\n",
    "                \n",
    "                # Get the radii for these nearest neighbors\n",
    "                if subsample and num_fake > subsample_size:\n",
    "                    # Map indices back to the subsampled manifold\n",
    "                    closest_fake_radii = np.array([fake_radii[idx] for idx in closest_fake_idx.flatten()])\n",
    "                else:\n",
    "                    closest_fake_radii = np.array([fake_radii[idx] for idx in closest_fake_idx.flatten()])\n",
    "                \n",
    "                # Calculate thresholds for this chunk\n",
    "                threshold_recall = closest_fake_radii * multiplier\n",
    "                \n",
    "                # Count samples within threshold\n",
    "                in_threshold = np.sum(recall_distances.flatten() <= threshold_recall)\n",
    "                recall_in_threshold_count += in_threshold\n",
    "                total_real_samples += chunk_size\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.update(chunk_size)\n",
    "                \n",
    "                # Clean up chunk data\n",
    "                del real_chunk, recall_distances, closest_fake_idx, closest_fake_radii, threshold_recall\n",
    "                if i % (2 * query_chunk_size) == 0:  # Less frequent cleanup\n",
    "                    gc.collect()\n",
    "        \n",
    "        # Calculate final recall\n",
    "        recall_individual = recall_in_threshold_count / total_real_samples if total_real_samples > 0 else 0.0\n",
    "        coverage_individual = recall_individual  # Coverage = Recall in this implementation\n",
    "        \n",
    "        # --- CHUNKED Density Calculation with Mean Threshold ---\n",
    "        # Using mean fake radius to reduce memory needs\n",
    "        logger.debug(\"Calculating density (mean threshold, chunked)...\")\n",
    "        fake_mean_radius = np.mean(fake_radii) * multiplier\n",
    "        \n",
    "        fake_nn_query_multi = NearestNeighbors(n_neighbors=min(50, len(fake_for_manifold)), algorithm='ball_tree', n_jobs=-1)\n",
    "        fake_nn_query_multi.fit(fake_for_manifold)\n",
    "        \n",
    "        density_sum = 0\n",
    "        total_real_samples_density = 0\n",
    "        \n",
    "        # Process in chunks\n",
    "        with tqdm(total=len(real_features), desc=\"PRDC Density\") as pbar:\n",
    "            for i in range(0, len(real_features), query_chunk_size):\n",
    "                chunk_end = min(i + query_chunk_size, len(real_features))\n",
    "                real_chunk = real_features[i:chunk_end]\n",
    "                chunk_size = len(real_chunk)\n",
    "                \n",
    "                if chunk_size == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Query multiple nearest neighbors for this chunk\n",
    "                multi_distances, _ = fake_nn_query_multi.kneighbors(real_chunk)\n",
    "                \n",
    "                # For each real point, count how many fake points are within the mean radius\n",
    "                samples_in_radius = np.sum(multi_distances <= fake_mean_radius, axis=1)\n",
    "                density_sum += np.sum(samples_in_radius)\n",
    "                total_real_samples_density += chunk_size\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.update(chunk_size)\n",
    "                \n",
    "                # Clean up chunk data\n",
    "                del real_chunk, multi_distances, samples_in_radius\n",
    "                if i % (2 * query_chunk_size) == 0:  # Less frequent cleanup\n",
    "                    gc.collect()\n",
    "        \n",
    "        # Calculate final density\n",
    "        density_individual = (density_sum / total_real_samples_density) / len(fake_for_manifold) if total_real_samples_density > 0 and len(fake_for_manifold) > 0 else 0.0\n",
    "        \n",
    "        metrics_results['individual'] = {\n",
    "            'precision': float(precision_individual), \n",
    "            'recall': float(recall_individual),\n",
    "            'density': float(density_individual), \n",
    "            'coverage': float(coverage_individual)\n",
    "        }\n",
    "        logger.info(f\"Individual distances metrics: P={precision_individual:.4f}, R={recall_individual:.4f}, D={density_individual:.6f}, C={coverage_individual:.4f}\")\n",
    "\n",
    "        # --- Mean Distances Method ---\n",
    "        # For the mean method, we can reuse the chunked calculation approach but with fixed thresholds\n",
    "        logger.info(\"Calculating metrics using mean distances...\")\n",
    "\n",
    "        real_mean_radius = np.mean(real_radii) * multiplier\n",
    "        fake_mean_radius = np.mean(fake_radii) * multiplier\n",
    "        logger.info(f\"Mean distance thresholds: real={real_mean_radius:.6f}, fake={fake_mean_radius:.6f}\")\n",
    "\n",
    "        # Since we already calculated density using mean threshold, just reuse that value\n",
    "        density_mean = density_individual\n",
    "\n",
    "        # --- CHUNKED Precision (Mean) ---\n",
    "        precision_mean_count = 0\n",
    "        precision_mean_total = 0\n",
    "        \n",
    "        with tqdm(total=len(fake_features), desc=\"Mean Precision\") as pbar:\n",
    "            for i in range(0, len(fake_features), query_chunk_size):\n",
    "                chunk_end = min(i + query_chunk_size, len(fake_features))\n",
    "                fake_chunk = fake_features[i:chunk_end]\n",
    "                chunk_size = len(fake_chunk)\n",
    "                \n",
    "                if chunk_size == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Query nearest real neighbors for this chunk\n",
    "                distances, _ = real_nn_query.kneighbors(fake_chunk)\n",
    "                \n",
    "                # Count those within the mean threshold\n",
    "                in_threshold = np.sum(distances.flatten() <= real_mean_radius)\n",
    "                precision_mean_count += in_threshold\n",
    "                precision_mean_total += chunk_size\n",
    "                \n",
    "                # Update progress and cleanup\n",
    "                pbar.update(chunk_size)\n",
    "                del fake_chunk, distances\n",
    "        \n",
    "        precision_mean = precision_mean_count / precision_mean_total if precision_mean_total > 0 else 0.0\n",
    "\n",
    "        # --- CHUNKED Recall (Mean) ---\n",
    "        recall_mean_count = 0\n",
    "        recall_mean_total = 0\n",
    "        \n",
    "        with tqdm(total=len(real_features), desc=\"Mean Recall\") as pbar:\n",
    "            for i in range(0, len(real_features), query_chunk_size):\n",
    "                chunk_end = min(i + query_chunk_size, len(real_features))\n",
    "                real_chunk = real_features[i:chunk_end]\n",
    "                chunk_size = len(real_chunk)\n",
    "                \n",
    "                if chunk_size == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Query nearest fake neighbors for this chunk\n",
    "                distances, _ = fake_nn_query.kneighbors(real_chunk)\n",
    "                \n",
    "                # Count those within the mean threshold\n",
    "                in_threshold = np.sum(distances.flatten() <= fake_mean_radius)\n",
    "                recall_mean_count += in_threshold\n",
    "                recall_mean_total += chunk_size\n",
    "                \n",
    "                # Update progress and cleanup\n",
    "                pbar.update(chunk_size)\n",
    "                del real_chunk, distances\n",
    "        \n",
    "        recall_mean = recall_mean_count / recall_mean_total if recall_mean_total > 0 else 0.0\n",
    "        coverage_mean = recall_mean\n",
    "\n",
    "        metrics_results['mean'] = {\n",
    "            'precision': float(precision_mean), \n",
    "            'recall': float(recall_mean),\n",
    "            'density': float(density_mean), \n",
    "            'coverage': float(coverage_mean)\n",
    "        }\n",
    "        logger.info(f\"Mean distances metrics: P={precision_mean:.4f}, R={recall_mean:.4f}, D={density_mean:.6f}, C={coverage_mean:.4f}\")\n",
    "\n",
    "        # Cleanup NN models\n",
    "        del real_nn, fake_nn, real_nn_query, fake_nn_query, fake_nn_query_multi\n",
    "        force_memory_cleanup(config)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Custom P/R/D/C calculation failed: {e}\", exc_info=True)\n",
    "        metrics_results['individual'] = {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
    "        metrics_results['mean'] = {'precision': 0.0, 'recall': 0.0, 'density': 0.0, 'coverage': 0.0}\n",
    "\n",
    "    return metrics_results\n",
    "    #\n",
    "\n",
    "#def generate_radar_chart(metrics, title, output_path):\n",
    "#    \"\"\"Generate a radar chart visualization of metrics.\"\"\"\n",
    "\n",
    "# --- Modify generate_radar_chart (optional: handle individual/mean dict) ---\n",
    "def generate_radar_chart(metrics_data, title, output_path):\n",
    "    \"\"\"Generate a radar chart visualization of metrics.\n",
    "       Can accept a dict like {'precision': v, ...} or {'individual': {...}, 'mean': {...}}\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"GenerationEngine\")\n",
    "    try:\n",
    "        # If passed the combined dict, use 'individual' by default, or try 'mean'\n",
    "        if 'individual' in metrics_data:\n",
    "            metrics = metrics_data['individual']\n",
    "            if not metrics: metrics = metrics_data.get('mean', {}) # Fallback to mean if individual is empty\n",
    "        else:\n",
    "            metrics = metrics_data # Assume it's the flat dict\n",
    "\n",
    "        if not metrics:\n",
    "            logger.warning(f\"No metrics data provided for radar chart '{title}'\")\n",
    "            return False\n",
    "\n",
    "        # Extract metrics - handle missing keys gracefully\n",
    "        #categories = ['precision', 'recall', 'density', 'coverage']\n",
    "        categories = ['precision', 'recall', 'coverage']\n",
    "        values = [metrics.get(cat, 0.0) for cat in categories] # Default to 0.0 if missing\n",
    "\n",
    "        # Create radar chart\n",
    "        num_vars = len(categories)\n",
    "        angles = np.linspace(0, 2*np.pi, num_vars, endpoint=False).tolist()\n",
    "        values_plot = values + values[:1] # Close the loop\n",
    "        angles_plot = angles + angles[:1] # Close the loop\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "        ax.plot(angles_plot, values_plot, 'o-', linewidth=2, color='purple') # Use consistent color\n",
    "        ax.fill(angles_plot, values_plot, alpha=0.25, color='purple')\n",
    "        ax.set_thetagrids(np.degrees(angles), [c.capitalize() for c in categories])\n",
    "\n",
    "        ax.set_ylim(0, 1.05) # Set ylim slightly above 1.0\n",
    "        plt.title(title, size=15, y=1.1)\n",
    "        ax.grid(True) # Add grid\n",
    "\n",
    "        # Add value annotations like in evaluator script\n",
    "        for angle, value, name in zip(angles, values, categories):\n",
    "            ax.text(angle, value + 0.05, f\"{value:.3f}\",\n",
    "                      horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path, dpi=300)\n",
    "        plt.close()\n",
    "        logger.info(f\"Saved radar chart to {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating radar chart '{title}': {e}\", exc_info=True)\n",
    "        return False\n",
    "        \n",
    "def save_sample_visualization(pollen_paths, composed_paths, labels_paths, output_path, num_samples=4):\n",
    "    \"\"\"Create a visualization of sample images.\"\"\"\n",
    "    try:\n",
    "        # Limit to available images\n",
    "        pollen_paths = pollen_paths[:num_samples]\n",
    "        composed_paths = composed_paths[:num_samples]\n",
    "        \n",
    "        # Create figure\n",
    "        fig, axes = plt.subplots(2, num_samples, figsize=(num_samples * 4, 8))\n",
    "        \n",
    "        # Display individual pollen images on top row\n",
    "        for i, path in enumerate(pollen_paths):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            img = Image.open(path)\n",
    "            axes[0, i].imshow(img, cmap='gray')\n",
    "            axes[0, i].set_title(f\"Pollen {i+1}\")\n",
    "            axes[0, i].axis('off')\n",
    "        \n",
    "        # Display composed images on bottom row\n",
    "        for i, path in enumerate(composed_paths):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            img = Image.open(path)\n",
    "            axes[1, i].imshow(img, cmap='gray')\n",
    "            axes[1, i].set_title(f\"Composed {i+1}\")\n",
    "            axes[1, i].axis('off')\n",
    "            \n",
    "            # Add bounding boxes if available\n",
    "            label_path = labels_paths[i] if i < len(labels_paths) else None\n",
    "            if label_path and os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    annotations = f.readlines()\n",
    "                \n",
    "                for annotation in annotations:\n",
    "                    parts = annotation.strip().split()\n",
    "                    if len(parts) == 5:\n",
    "                        # Parse YOLO format\n",
    "                        _, x_center, y_center, width, height = map(float, parts)\n",
    "                        \n",
    "                        # Convert to pixel coordinates\n",
    "                        img_w, img_h = img.size\n",
    "                        x = (x_center - width/2) * img_w\n",
    "                        y = (y_center - height/2) * img_h\n",
    "                        w = width * img_w\n",
    "                        h = height * img_h\n",
    "                        \n",
    "                        # Draw rectangle\n",
    "                        rect = plt.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "                        axes[1, i].add_patch(rect)\n",
    "        \n",
    "        # Save figure\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path, dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating sample visualization: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Report Generation ---\n",
    "\n",
    "def create_markdown_report(config, generation_results, analysis_results, stats, output_path):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive Markdown report of the generation process,\n",
    "    including separate sections for filtered and unfiltered analysis results.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"GenerationEngine\")\n",
    "    try:\n",
    "        report_dir = os.path.dirname(output_path)\n",
    "        os.makedirs(report_dir, exist_ok=True)\n",
    "\n",
    "        with open(output_path, 'w') as f:\n",
    "            # --- Header ---\n",
    "            f.write(\"# Synthetic Pollen Image Generation Report\\n\\n\")\n",
    "            f.write(f\"**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "\n",
    "            # --- Configuration ---\n",
    "            f.write(\"## Configuration\\n\\n\")\n",
    "            f.write(\"### Paths\\n\")\n",
    "            f.write(f\"- **Generator model:** `{config.CHECKPOINT_PATH}`\\n\")\n",
    "            f.write(f\"- **Real data:** `{config.get_real_data_path()}`\\n\")\n",
    "            f.write(f\"- **Backgrounds:** `{config.BACKGROUND_DIR}`\\n\")\n",
    "            f.write(f\"- **Output directory:** `{config.OUTPUT_DIR}`\\n\\n\")\n",
    "\n",
    "            f.write(\"### Generation Parameters\\n\")\n",
    "            f.write(f\"- **Target pollen images:** {config.TARGET_POLLEN_IMAGES}\\n\")\n",
    "            f.write(f\"- **Target composed images:** {config.TARGET_COMPOSED_IMAGES}\\n\")\n",
    "            f.write(f\"- **Quality filtering:** {'Enabled' if config.USE_QUALITY_FILTERING else 'Disabled'}\\n\")\n",
    "            if config.USE_QUALITY_FILTERING:\n",
    "                 f.write(f\"  - **Threshold Percentile:** {config.QUALITY_THRESHOLD_PERCENTILE}%\\n\")\n",
    "                 f.write(f\"  - **Surplus Factor:** {config.FILTERING_SURPLUS_FACTOR}x\\n\")\n",
    "            f.write(f\"- **Blending method:** {config.BLENDING_METHOD}\\n\")\n",
    "            f.write(f\"- **Statistics matching (Size):** {'Enabled' if config.USE_STATS_MATCHING_SIZE else 'Disabled'}\\n\")\n",
    "            f.write(f\"- **Statistics matching (Histogram):** {'Enabled' if config.USE_STATS_MATCHING_HISTOGRAM else 'Disabled'}\\n\")\n",
    "            f.write(f\"- **Parallel processing:** {'Enabled' if config.USE_PARALLEL_PROCESSING else 'Disabled'}\\n\\n\")\n",
    "\n",
    "            f.write(\"### Analysis Parameters\\n\")\n",
    "            f.write(f\"- **Analysis Sample Size:** {config.ANALYSIS_SAMPLE_SIZE}\\n\")\n",
    "            f.write(f\"- **PRDC Manifold k:** {config.MANIFOLD_K}\\n\")\n",
    "            f.write(f\"- **PRDC Distance Multiplier:** {config.DISTANCE_MULTIPLIER}\\n\")\n",
    "            f.write(f\"- **PRDC Fidelity k:** {config.PR_K_VALUE}\\n\\n\")\n",
    "\n",
    "\n",
    "            # --- Generation Results ---\n",
    "            f.write(\"## Generation Run Summary\\n\\n\")\n",
    "            if 'pollen_generated' in generation_results:\n",
    "                f.write(f\"- **Pollen images generated:** {generation_results['pollen_generated']} / {config.TARGET_POLLEN_IMAGES}\\n\")\n",
    "            if 'composed_generated' in generation_results:\n",
    "                f.write(f\"- **Composed images generated:** {generation_results['composed_generated']} / {config.TARGET_COMPOSED_IMAGES}\\n\")\n",
    "\n",
    "            if 'total_time' in generation_results:\n",
    "                total_seconds = generation_results['total_time']\n",
    "                hours = int(total_seconds // 3600)\n",
    "                minutes = int((total_seconds % 3600) // 60)\n",
    "                seconds = total_seconds % 60\n",
    "                f.write(f\"- **Total time:** {hours}h {minutes}m {seconds:.3f}s\\n\")\n",
    "\n",
    "                # Calculate generation rates\n",
    "                if 'pollen_generated' in generation_results and generation_results['pollen_generated'] > 0 and total_seconds > 0:\n",
    "                    rate = generation_results['pollen_generated'] / total_seconds\n",
    "                    f.write(f\"- **Pollen generation rate:** {rate:.3f} images/second\\n\")\n",
    "                if 'composed_generated' in generation_results and generation_results['composed_generated'] > 0 and total_seconds > 0:\n",
    "                    rate = generation_results['composed_generated'] / total_seconds\n",
    "                    f.write(f\"- **Composed generation rate:** {rate:.3f} images/second\\n\")\n",
    "\n",
    "            # --- Peak Memory ---\n",
    "            if 'peak_memory' in generation_results:\n",
    "                f.write(\"\\n### Peak Memory Usage During Run\\n\")\n",
    "                f.write(f\"- **RAM:** {generation_results['peak_memory'].get('ram_used_percent', 'N/A'):.1f}%\\n\")\n",
    "                gpu_perc = generation_results['peak_memory'].get('gpu_used_percent', 'N/A')\n",
    "                gpu_used = generation_results['peak_memory'].get('gpu_used_gb', 'N/A')\n",
    "                gpu_total = generation_results['peak_memory'].get('gpu_total_gb', 'N/A')\n",
    "                if gpu_perc != 'N/A':\n",
    "                    f.write(f\"- **GPU:** {gpu_perc:.1f}% ({gpu_used:.3f} / {gpu_total:.3f} GB)\\n\")\n",
    "                else:\n",
    "                     f.write(\"- **GPU:** N/A (CUDA not available or error)\\n\")\n",
    "\n",
    "                memory_chart = os.path.join(config.OUTPUT_DIR, config.STATS_SUBDIR, \"memory_usage.png\")\n",
    "                if os.path.exists(memory_chart):\n",
    "                    rel_path = os.path.relpath(memory_chart, report_dir)\n",
    "                    f.write(f\"\\n![Memory Usage Over Time](./{rel_path.replace(os.sep, '/')})\\n\") # Ensure relative path uses forward slashes\n",
    "\n",
    "            # --- Sample Images ---\n",
    "            f.write(\"\\n## Sample Generated Images\\n\\n\")\n",
    "            samples_path = os.path.join(config.OUTPUT_DIR, config.GRAPH_SUBDIR, \"sample_visualization.png\")\n",
    "            if os.path.exists(samples_path):\n",
    "                rel_path = os.path.relpath(samples_path, report_dir)\n",
    "                f.write(f\"![Sample Images](./{rel_path.replace(os.sep, '/')})\\n\\n\")\n",
    "            else:\n",
    "                 f.write(\"*Sample visualization image not found.*\\n\\n\")\n",
    "\n",
    "\n",
    "            # --- Statistical Analysis Section ---\n",
    "            f.write(\"## Statistical Analysis of Generated Images\\n\\n\")\n",
    "\n",
    "            analysis_performed = analysis_results is not None and \\\n",
    "                                 (analysis_results.get('prdc_metrics_filtered') is not None or \\\n",
    "                                  analysis_results.get('prdc_metrics_unfiltered') is not None)\n",
    "\n",
    "            if not analysis_performed:\n",
    "                 f.write(\"*Analysis was skipped or failed (check logs).*\\n\\n\")\n",
    "            else: # if analysis_performed:\n",
    "                # --- Analysis Subsection: Filtered ---\n",
    "                f.write(\"### Analysis on Filtered Generated Images\\n\\n\")\n",
    "                f.write(\"*Note: Filtered images are those saved to the output directory if quality filtering was enabled.*\\n\\n\")\n",
    "\n",
    "                # Link plots - Filtered\n",
    "                tsne_path_f = os.path.join(config.OUTPUT_DIR, config.GRAPH_SUBDIR, \"tsne_visualization_filtered.png\")\n",
    "                if os.path.exists(tsne_path_f):\n",
    "                    rel_path = os.path.relpath(tsne_path_f, report_dir)\n",
    "                    f.write(f\"**t-SNE Visualization (Filtered):**\\n![t-SNE Filtered](./{rel_path.replace(os.sep, '/')})\\n\\n\")\n",
    "                else:\n",
    "                     f.write(\"**t-SNE Visualization (Filtered):** *Plot not generated.*\\n\\n\")\n",
    "\n",
    "                umap_path_f = os.path.join(config.OUTPUT_DIR, config.GRAPH_SUBDIR, \"umap_visualization_filtered.png\")\n",
    "                if os.path.exists(umap_path_f):\n",
    "                    rel_path = os.path.relpath(umap_path_f, report_dir)\n",
    "                    f.write(f\"**UMAP Visualization (Filtered):**\\n![UMAP Filtered](./{rel_path.replace(os.sep, '/')})\\n\\n\")\n",
    "                elif config.VISUALIZE_UMAP: # Only mention if attempted\n",
    "                     f.write(\"**UMAP Visualization (Filtered):** *Plot not generated (UMAP may not be installed).*\\n\\n\")\n",
    "\n",
    "\n",
    "                # PRDC Metrics - Filtered\n",
    "                metrics_f = analysis_results.get('prdc_metrics_filtered')\n",
    "                if metrics_f:\n",
    "                    radar_path_f = os.path.join(config.OUTPUT_DIR, config.GRAPH_SUBDIR, \"prdc_radar_filtered.png\")\n",
    "                    if os.path.exists(radar_path_f):\n",
    "                         rel_path = os.path.relpath(radar_path_f, report_dir)\n",
    "                         f.write(f\"**PRDC Metrics Radar (Filtered - Individual):**\\n![Radar Filtered](./{rel_path.replace(os.sep, '/')})\\n\\n\")\n",
    "                    else:\n",
    "                         f.write(\"**PRDC Metrics Radar (Filtered):** *Plot not generated.*\\n\\n\")\n",
    "\n",
    "                    # Individual Table\n",
    "                    if metrics_f.get('individual'):\n",
    "                        f.write(\"**Individual Distances Method (Filtered):**\\n\")\n",
    "                        f.write(\"| Metric    | Value     |\\n\")\n",
    "                        f.write(\"| :-------- | :-------- |\\n\")\n",
    "                        for metric, value in metrics_f['individual'].items():\n",
    "                            f.write(f\"| {metric.capitalize():<10} | {value:.4f}    |\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                    # Mean Table\n",
    "                    if metrics_f.get('mean'):\n",
    "                        f.write(\"**Mean Distances Method (Filtered):**\\n\")\n",
    "                        f.write(\"| Metric    | Value     |\\n\")\n",
    "                        f.write(\"| :-------- | :-------- |\\n\")\n",
    "                        for metric, value in metrics_f['mean'].items():\n",
    "                            f.write(f\"| {metric.capitalize():<10} | {value:.4f}    |\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                else:\n",
    "                    f.write(\"**PRDC Metrics (Filtered):** *Not calculated or failed.*\\n\\n\")\n",
    "\n",
    "                # ... (existing Filtered section plots/metrics) ...\n",
    "\n",
    "                # --- Add Average Critic Score (Filtered) --- <-- NEW\n",
    "                avg_score_f = analysis_results.get('avg_critic_score_filtered')\n",
    "                if avg_score_f is not None:\n",
    "                    f.write(f\"**Average Critic Score (Filtered):** {avg_score_f:.4f}\\n\\n\")\n",
    "                else:\n",
    "                    f.write(\"**Average Critic Score (Filtered):** *Not calculated.*\\n\\n\")\n",
    "\n",
    "                # --- Analysis Subsection: Unfiltered ---\n",
    "                f.write(\"---\\n\") # Separator\n",
    "                f.write(\"### Analysis on Unfiltered Generated Images\\n\\n\")\n",
    "                f.write(\"*Note: Unfiltered images were generated on-the-fly specifically for this analysis.*\\n\\n\")\n",
    "\n",
    "                # Link plots - Unfiltered\n",
    "                tsne_path_u = os.path.join(config.OUTPUT_DIR, config.GRAPH_SUBDIR, \"tsne_visualization_unfiltered.png\")\n",
    "                if os.path.exists(tsne_path_u):\n",
    "                    rel_path = os.path.relpath(tsne_path_u, report_dir)\n",
    "                    f.write(f\"**t-SNE Visualization (Unfiltered):**\\n![t-SNE Unfiltered](./{rel_path.replace(os.sep, '/')})\\n\\n\")\n",
    "                else:\n",
    "                     f.write(\"**t-SNE Visualization (Unfiltered):** *Plot not generated.*\\n\\n\")\n",
    "\n",
    "                umap_path_u = os.path.join(config.OUTPUT_DIR, config.GRAPH_SUBDIR, \"umap_visualization_unfiltered.png\")\n",
    "                if os.path.exists(umap_path_u):\n",
    "                    rel_path = os.path.relpath(umap_path_u, report_dir)\n",
    "                    f.write(f\"**UMAP Visualization (Unfiltered):**\\n![UMAP Unfiltered](./{rel_path.replace(os.sep, '/')})\\n\\n\")\n",
    "                elif config.VISUALIZE_UMAP: # Only mention if attempted\n",
    "                     f.write(\"**UMAP Visualization (Unfiltered):** *Plot not generated (UMAP may not be installed).*\\n\\n\")\n",
    "\n",
    "                # PRDC Metrics - Unfiltered\n",
    "                metrics_u = analysis_results.get('prdc_metrics_unfiltered')\n",
    "                if metrics_u:\n",
    "                    radar_path_u = os.path.join(config.OUTPUT_DIR, config.GRAPH_SUBDIR, \"prdc_radar_unfiltered.png\")\n",
    "                    if os.path.exists(radar_path_u):\n",
    "                         rel_path = os.path.relpath(radar_path_u, report_dir)\n",
    "                         f.write(f\"**PRDC Metrics Radar (Unfiltered - Individual):**\\n![Radar Unfiltered](./{rel_path.replace(os.sep, '/')})\\n\\n\")\n",
    "                    else:\n",
    "                         f.write(\"**PRDC Metrics Radar (Unfiltered):** *Plot not generated.*\\n\\n\")\n",
    "\n",
    "                    # Individual Table\n",
    "                    if metrics_u.get('individual'):\n",
    "                        f.write(\"**Individual Distances Method (Unfiltered):**\\n\")\n",
    "                        f.write(\"| Metric    | Value     |\\n\")\n",
    "                        f.write(\"| :-------- | :-------- |\\n\")\n",
    "                        for metric, value in metrics_u['individual'].items():\n",
    "                            f.write(f\"| {metric.capitalize():<10} | {value:.4f}    |\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                    # Mean Table\n",
    "                    if metrics_u.get('mean'):\n",
    "                        f.write(\"**Mean Distances Method (Unfiltered):**\\n\")\n",
    "                        f.write(\"| Metric    | Value     |\\n\")\n",
    "                        f.write(\"| :-------- | :-------- |\\n\")\n",
    "                        for metric, value in metrics_u['mean'].items():\n",
    "                            f.write(f\"| {metric.capitalize():<10} | {value:.4f}    |\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                else:\n",
    "                    f.write(\"**PRDC Metrics (Unfiltered):** *Not calculated or failed.*\\n\\n\")\n",
    "\n",
    "                # ... (existing Unfiltered section plots/metrics) ...\n",
    "\n",
    "                # --- Add Average Critic Score (Unfiltered) --- <-- NEW\n",
    "                avg_score_u = analysis_results.get('avg_critic_score_unfiltered')\n",
    "                if avg_score_u is not None:\n",
    "                    f.write(f\"**Average Critic Score (Unfiltered):** {avg_score_u:.4f}\\n\\n\")\n",
    "                else:\n",
    "                    f.write(\"**Average Critic Score (Unfiltered):** *Not calculated.*\\n\\n\")\n",
    "\n",
    "                # --- Combined Comparison ---\n",
    "                f.write(\"---\\n\")\n",
    "                f.write(\"### Comparison: Filtered vs. Unfiltered\\n\\n\")\n",
    "                comp_radar_path = os.path.join(config.OUTPUT_DIR, config.GRAPH_SUBDIR, \"prdc_radar_comparison.png\")\n",
    "                if os.path.exists(comp_radar_path):\n",
    "                    rel_path = os.path.relpath(comp_radar_path, report_dir)\n",
    "                    f.write(f\"**PRDC Comparison Radar (Individual Distances):**\\n![Radar Comparison](./{rel_path.replace(os.sep, '/')})\\n\\n\")\n",
    "                elif metrics_f and metrics_u: # Only mention if data was available\n",
    "                    f.write(\"**PRDC Comparison Radar:** *Plot not generated.*\\n\\n\")\n",
    "                else:\n",
    "                    f.write(\"*Comparison plot requires successful calculation of both filtered and unfiltered metrics.*\\n\\n\")\n",
    "\n",
    "\n",
    "            # --- Real Data Statistics ---\n",
    "            if stats:\n",
    "                f.write(\"## Real Data Statistics Used\\n\\n\")\n",
    "                f.write(f\"*Based on {stats.get('metadata', {}).get('num_images_analyzed', 'N/A')} images from `{stats.get('metadata', {}).get('data_path', 'N/A')}`*\\n\\n\")\n",
    "\n",
    "                if 'size_statistics' in stats:\n",
    "                    f.write(\"### Size Distribution\\n\\n\")\n",
    "                    size_stats = stats['size_statistics']\n",
    "                    f.write(\"| Dimension | Mean  | Std Dev | Min | Max |\\n\")\n",
    "                    f.write(\"| :-------- | :---- | :------ | :-: | :-: |\\n\")\n",
    "                    for dim in ['width', 'height']:\n",
    "                        if dim in size_stats:\n",
    "                            dim_stats = size_stats[dim]\n",
    "                            f.write(f\"| {dim.capitalize():<9} | {dim_stats.get('mean', 0):.1f} | {dim_stats.get('std', 0):.1f}   | {dim_stats.get('min', 0):<3} | {dim_stats.get('max', 0):<3} |\\n\")\n",
    "                    f.write(\"\\n\")\n",
    "\n",
    "                if 'pixel_statistics' in stats:\n",
    "                    f.write(\"### Pixel Statistics\\n\\n\")\n",
    "                    pixel_stats = stats['pixel_statistics']\n",
    "                    f.write(\"| Property   | Mean  | Std Dev |\\n\")\n",
    "                    f.write(\"| :--------- | :---- | :------ |\\n\")\n",
    "                    for prop in ['brightness', 'contrast']:\n",
    "                        if prop in pixel_stats:\n",
    "                            prop_stats = pixel_stats[prop]\n",
    "                            f.write(f\"| {prop.capitalize():<10} | {prop_stats.get('mean', 0):.1f} | {prop_stats.get('std', 0):.1f}   |\\n\")\n",
    "                    f.write(\"\\n\")\n",
    "            else:\n",
    "                 f.write(\"## Real Data Statistics Used\\n\\n\")\n",
    "                 f.write(\"*Real data statistics were not calculated or loaded.*\\n\\n\")\n",
    "\n",
    "            # --- Conclusion ---\n",
    "            f.write(\"## Conclusion\\n\\n\")\n",
    "            f.write(\"The generation process has completed. Review the analysis results and sample images to assess the quality and diversity of the generated dataset.\\n\")\n",
    "\n",
    "            f.write(\"\\n---\\n\")\n",
    "            f.write(f\"*Report generated by Generation Engine v0.0 on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\\n\")\n",
    "\n",
    "        logger.info(f\"Markdown report saved successfully to {output_path}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating Markdown report: {e}\", exc_info=True)\n",
    "        return False\n",
    "\n",
    "def create_performance_summary(config, generation_results, analysis_results, logger):\n",
    "    \"\"\"\n",
    "    Create summary charts and statistics for the generation process,\n",
    "    including analysis metric summaries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stats_dir = os.path.join(config.OUTPUT_DIR, config.STATS_SUBDIR)\n",
    "        os.makedirs(stats_dir, exist_ok=True)\n",
    "\n",
    "        report_path = os.path.join(stats_dir, \"performance_summary.txt\")\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(\"=\" * 60 + \"\\n\")\n",
    "            f.write(\" GENERATION ENGINE PERFORMANCE SUMMARY\\n\")\n",
    "            f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "\n",
    "            f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Device: {config.DEVICE}\\n\")\n",
    "            f.write(f\"Output Directory: {config.OUTPUT_DIR}\\n\\n\")\n",
    "\n",
    "            f.write(\"--- GENERATION RESULTS ---\\n\")\n",
    "            total_time = generation_results.get('total_time', 0)\n",
    "            f.write(f\"- Total runtime: {total_time:.3f} seconds ({total_time / 3600:.3f} hours)\\n\")\n",
    "            f.write(f\"- Individual pollen images generated: {generation_results.get('pollen_generated', 0)} / {config.TARGET_POLLEN_IMAGES}\\n\")\n",
    "            f.write(f\"- Composed images generated: {generation_results.get('composed_generated', 0)} / {config.TARGET_COMPOSED_IMAGES}\\n\\n\")\n",
    "\n",
    "            # Performance Metrics\n",
    "            if total_time > 0:\n",
    "                f.write(\"--- PERFORMANCE METRICS ---\\n\")\n",
    "                pollen_gen = generation_results.get('pollen_generated', 0)\n",
    "                composed_gen = generation_results.get('composed_generated', 0)\n",
    "                if pollen_gen > 0:\n",
    "                    f.write(f\"- Individual pollen generation rate: {pollen_gen / total_time:.3f} images/second\\n\")\n",
    "                if composed_gen > 0:\n",
    "                    f.write(f\"- Composed image generation rate: {composed_gen / total_time:.3f} images/second\\n\")\n",
    "                f.write(\"\\n\")\n",
    "            #\n",
    "            # --- ANALYSIS METRICS SUMMARY ---\n",
    "            f.write(\"--- ANALYSIS METRICS SUMMARY ---\\n\")\n",
    "            # Check if any analysis results exist at all\n",
    "            if analysis_results and any(analysis_results.values()):\n",
    "                # PRDC Summary (Filtered)\n",
    "                metrics_f = analysis_results.get('prdc_metrics_filtered')\n",
    "                if metrics_f and metrics_f.get('individual'):\n",
    "                    m = metrics_f['individual']\n",
    "                    f.write(f\"- Filtered (PRDC Indiv): P={m.get('precision',0):.3f}, R={m.get('recall',0):.3f}, D={m.get('density',0):.4f}, C={m.get('coverage',0):.3f}\\n\")\n",
    "                elif metrics_f:\n",
    "                    f.write(f\"- Filtered (PRDC torch?): P={metrics_f.get('precision',0):.3f}, R={metrics_f.get('recall',0):.3f}, D={metrics_f.get('density',0):.4f}, C={metrics_f.get('coverage',0):.3f}\\n\")\n",
    "                else:\n",
    "                    f.write(\"- Filtered (PRDC):        Not calculated or failed.\\n\")\n",
    "\n",
    "                # PRDC Summary (Unfiltered)\n",
    "                metrics_u = analysis_results.get('prdc_metrics_unfiltered')\n",
    "                if metrics_u and metrics_u.get('individual'):\n",
    "                    m = metrics_u['individual']\n",
    "                    f.write(f\"- Unfiltered (PRDC Indiv): P={m.get('precision',0):.3f}, R={m.get('recall',0):.3f}, D={m.get('density',0):.4f}, C={m.get('coverage',0):.3f}\\n\")\n",
    "                elif metrics_u:\n",
    "                    f.write(f\"- Unfiltered (PRDC torch?):P={metrics_u.get('precision',0):.3f}, R={metrics_u.get('recall',0):.3f}, D={metrics_u.get('density',0):.4f}, C={metrics_u.get('coverage',0):.3f}\\n\")\n",
    "                else:\n",
    "                    f.write(\"- Unfiltered (PRDC):      Not calculated or failed.\\n\")\n",
    "\n",
    "                # FID/KID Summary\n",
    "                fid_kid_f = analysis_results.get('fid_kid_filtered')\n",
    "                fid_f = f\"{fid_kid_f.get('fid', 'N/A'):.3f}\" if fid_kid_f and fid_kid_f.get('fid') is not None else 'N/A'\n",
    "                kid_f = f\"{fid_kid_f.get('kid', 'N/A'):.3f}\" if fid_kid_f and fid_kid_f.get('kid') is not None else 'N/A'\n",
    "                f.write(f\"- Filtered (FID/KID):     FID={fid_f}, KID={kid_f}\\n\")\n",
    "\n",
    "                fid_kid_u = analysis_results.get('fid_kid_unfiltered')\n",
    "                fid_u = f\"{fid_kid_u.get('fid', 'N/A'):.3f}\" if fid_kid_u and fid_kid_u.get('fid') is not None else 'N/A'\n",
    "                kid_u = f\"{fid_kid_u.get('kid', 'N/A'):.3f}\" if fid_kid_u and fid_kid_u.get('kid') is not None else 'N/A'\n",
    "                f.write(f\"- Unfiltered (FID/KID):   FID={fid_u}, KID={kid_u}\\n\")\n",
    "\n",
    "                # --- Add Critic Score Summary --- <-- NEW\n",
    "                score_f = analysis_results.get('avg_critic_score_filtered')\n",
    "                score_f_str = f\"{score_f:.4f}\" if score_f is not None else \"N/A\"\n",
    "                f.write(f\"- Filtered Avg Critic:    {score_f_str}\\n\")\n",
    "\n",
    "                score_u = analysis_results.get('avg_critic_score_unfiltered')\n",
    "                score_u_str = f\"{score_u:.4f}\" if score_u is not None else \"N/A\"\n",
    "                f.write(f\"- Unfiltered Avg Critic:  {score_u_str}\\n\")\n",
    "                # --- End Critic Score Summary ---\n",
    "\n",
    "            else:\n",
    "                f.write(\"- Analysis metrics were not calculated or analysis was skipped.\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            #\n",
    "\n",
    "            # --- CONFIGURATION SUMMARY ---\n",
    "            f.write(\"--- CONFIGURATION SUMMARY ---\\n\")\n",
    "            f.write(f\"- Quality Filtering: {'Enabled' if config.USE_QUALITY_FILTERING else 'Disabled'} (Threshold: {config.QUALITY_THRESHOLD_PERCENTILE}%)\\n\")\n",
    "            f.write(f\"- Blending Method: {config.BLENDING_METHOD}\\n\")\n",
    "            f.write(f\"- Content-aware Masks: {'Enabled' if config.USE_CONTENT_AWARE_MASKS else 'Disabled'}\\n\")\n",
    "            f.write(f\"- Statistics Matching (Size): {'Enabled' if config.USE_STATS_MATCHING_SIZE else 'Disabled'}\\n\")\n",
    "            f.write(f\"- Statistics Matching (Hist): {'Enabled' if config.USE_STATS_MATCHING_HISTOGRAM else 'Disabled'}\\n\")\n",
    "            f.write(f\"- Parallel Processing Used: {'Enabled' if config.USE_PARALLEL_PROCESSING else 'Disabled'} (Workers: {config.NUM_WORKERS})\\n\\n\")\n",
    "\n",
    "\n",
    "            # Peak Memory\n",
    "            if 'peak_memory' in generation_results:\n",
    "                f.write(\"--- PEAK MEMORY USAGE ---\\n\")\n",
    "                f.write(f\"- RAM: {generation_results['peak_memory'].get('ram_used_percent', 'N/A'):.1f}%\\n\")\n",
    "                gpu_perc = generation_results['peak_memory'].get('gpu_used_percent', 'N/A')\n",
    "                gpu_used = generation_results['peak_memory'].get('gpu_used_gb', 'N/A')\n",
    "                gpu_total = generation_results['peak_memory'].get('gpu_total_gb', 'N/A')\n",
    "                if gpu_perc != 'N/A':\n",
    "                    f.write(f\"- GPU: {gpu_perc:.1f}% ({gpu_used:.3f} / {gpu_total:.3f} GB)\\n\")\n",
    "                else:\n",
    "                     f.write(\"- GPU: N/A\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "\n",
    "            f.write(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "\n",
    "        logger.info(f\"Performance summary saved to {report_path}\")\n",
    "\n",
    "        # --- Generate Performance Visualization ---\n",
    "        # (Keep the existing code for generating performance_visualization.png here)\n",
    "        # ... (code to plot generation progress and memory usage) ...\n",
    "        # Note: This plot doesn't include the analysis metrics directly, just runtime/memory.\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating performance summary: {e}\", exc_info=True)\n",
    "\n",
    "# --- Worker Functions for Parallel Processing ---\n",
    "\n",
    "def process_composed_batch(args):\n",
    "    \"\"\"Process a batch of composed images (sequential version for Jupyter compatibility).\"\"\"\n",
    "    batch_idx, config_dict, bg_paths, real_stats, layout_stats = args\n",
    "\n",
    "    # Configure logging\n",
    "    logger = logging.getLogger(f\"GenerationEngine.Worker-{batch_idx}\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Use the config_dict directly for configuration values\n",
    "    OUTPUT_DIR = config_dict[\"OUTPUT_DIR\"]\n",
    "    COMPOSED_SUBDIR = config_dict[\"COMPOSED_SUBDIR\"]\n",
    "    LABELS_SUBDIR = config_dict[\"LABELS_SUBDIR\"]\n",
    "    CHUNK_SIZE = config_dict[\"CHUNK_SIZE\"]\n",
    "    BG_SIZE = config_dict[\"BG_SIZE\"]\n",
    "    POLLEN_SIZE_BASE = config_dict[\"POLLEN_SIZE_BASE\"]\n",
    "    MARGIN = config_dict[\"MARGIN\"]\n",
    "    FILTERING_SURPLUS_FACTOR = config_dict.get(\"FILTERING_SURPLUS_FACTOR\", 1.25)\n",
    "    USE_QUALITY_FILTERING = config_dict[\"USE_QUALITY_FILTERING\"]\n",
    "    OBJECT_CLASS = config_dict[\"OBJECT_CLASS\"]\n",
    "\n",
    "    # --- MODIFIED HERE: Ensure DEVICE is a torch.device object ---\n",
    "    device_name = config_dict.get(\"DEVICE\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    try:\n",
    "        DEVICE = torch.device(device_name)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create torch.device from name '{device_name}': {e}. Defaulting to CPU.\")\n",
    "        DEVICE = torch.device(\"cpu\")\n",
    "    # --- End Modification ---\n",
    "\n",
    "    # Define output paths directly\n",
    "    composed_dir = os.path.join(OUTPUT_DIR, COMPOSED_SUBDIR)\n",
    "    labels_dir = os.path.join(OUTPUT_DIR, LABELS_SUBDIR)\n",
    "\n",
    "    # Reconstruct model parameters from config_dict\n",
    "    NOISE_DIM = config_dict[\"NOISE_DIM\"]\n",
    "    CHANNELS_IMG = config_dict[\"CHANNELS_IMG\"]\n",
    "    G_FEATURES = config_dict[\"G_FEATURES\"]\n",
    "    C_FEATURES = config_dict[\"C_FEATURES\"]\n",
    "    CHECKPOINT_PATH = config_dict[\"CHECKPOINT_PATH\"]\n",
    "\n",
    "    # Load models from checkpoint (Generator and Critic)\n",
    "    # Ensure models are loaded onto the correct DEVICE object determined above\n",
    "    generator = Generator(\n",
    "        noise_dim=NOISE_DIM,\n",
    "        channels_img=CHANNELS_IMG,\n",
    "        features_g=G_FEATURES\n",
    "    ).to(DEVICE) # Use the DEVICE object\n",
    "\n",
    "    critic = None\n",
    "    if USE_QUALITY_FILTERING:\n",
    "        critic = Critic(\n",
    "            channels_img=CHANNELS_IMG,\n",
    "            features_c=C_FEATURES\n",
    "        ).to(DEVICE) # Use the DEVICE object\n",
    "\n",
    "    # ... (rest of the model loading try...except block remains the same) ...\n",
    "    try:\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE, weights_only=False) # Load to target device\n",
    "        if 'generator_state_dict' in checkpoint:\n",
    "            generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "        elif 'model_state_dict' in checkpoint:\n",
    "             generator.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "             raise KeyError(\"Generator state dict not found\")\n",
    "\n",
    "        if USE_QUALITY_FILTERING and critic is not None:\n",
    "             try:\n",
    "                 if 'critic_state_dict' in checkpoint:\n",
    "                     critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "                 else:\n",
    "                     logger.warning(\"No critic_state_dict found, quality filtering disabled in worker\")\n",
    "                     USE_QUALITY_FILTERING = False\n",
    "                     critic = None\n",
    "             except Exception as e:\n",
    "                 logger.warning(f\"Failed to load critic in worker: {e}\")\n",
    "                 USE_QUALITY_FILTERING = False\n",
    "                 critic = None\n",
    "\n",
    "        generator.eval()\n",
    "        if critic is not None: critic.eval()\n",
    "        logger.info(f\"Worker {batch_idx}: Models loaded to {DEVICE}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Worker {batch_idx}: Error loading models: {e}\")\n",
    "        return [], [], []\n",
    "\n",
    "\n",
    "    # Track results\n",
    "    generated_images = []\n",
    "    generated_labels = []\n",
    "    timestamps = []\n",
    "\n",
    "    # Create a minimal Config-like object for functions that need it\n",
    "    # Pass the correct DEVICE object type to mini_config\n",
    "    class SimpleConfig:\n",
    "        def __init__(self):\n",
    "            # Fill in all needed attributes\n",
    "            self.USE_QUALITY_FILTERING = USE_QUALITY_FILTERING\n",
    "            self.USE_CONTINUOUS_ROTATION = False\n",
    "            self.USE_RANDOM_SCALES = config_dict.get(\"USE_RANDOM_SCALES\", True)\n",
    "            self.USE_STATS_MATCHING_SIZE = config_dict.get(\"USE_STATS_MATCHING_SIZE\", True)\n",
    "            self.SCALE_RANGE = config_dict.get(\"SCALE_RANGE\", (0.75, 1.25))\n",
    "            self.BLENDING_METHOD = config_dict.get(\"BLENDING_METHOD\", \"poisson\")\n",
    "            self.USE_CONTENT_AWARE_MASKS = config_dict.get(\"USE_CONTENT_AWARE_MASKS\", True)\n",
    "            self.FEATHER_AMOUNT = config_dict.get(\"FEATHER_AMOUNT\", 15)\n",
    "            self.PYRAMID_LEVELS = config_dict.get(\"PYRAMID_LEVELS\", 4)\n",
    "            self.DEVICE = DEVICE # <-- Assign the torch.device object\n",
    "            self.NOISE_DIM = NOISE_DIM\n",
    "            self.BATCH_SIZE = config_dict.get(\"BATCH_SIZE\", 64)\n",
    "            # Make sure SCORING_BATCH_SIZE is available if score_pollen_batch uses it via config\n",
    "            self.SCORING_BATCH_SIZE = config_dict.get(\"SCORING_BATCH_SIZE\", 128)\n",
    "            self.POLLEN_SIZE_BASE = POLLEN_SIZE_BASE\n",
    "            self.FILTERING_SURPLUS_FACTOR = FILTERING_SURPLUS_FACTOR\n",
    "            self.QUALITY_THRESHOLD_PERCENTILE = config_dict.get(\"QUALITY_THRESHOLD_PERCENTILE\", 80.0)\n",
    "            # Add analysis parameters needed by called functions (if any)\n",
    "            self.LOAD_CRITIC_TO_CPU = config_dict.get(\"LOAD_CRITIC_TO_CPU\", False) # Needed by score_pollen_batch\n",
    "\n",
    "    mini_config = SimpleConfig()\n",
    "\n",
    "    # Process each background\n",
    "    for i, bg_path in enumerate(bg_paths):\n",
    "        try:\n",
    "            global_idx = batch_idx * CHUNK_SIZE + i\n",
    "\n",
    "            bg_img = Image.open(bg_path).convert('L')\n",
    "            if bg_img.size != (BG_SIZE, BG_SIZE):\n",
    "                bg_img = bg_img.resize((BG_SIZE, BG_SIZE), Image.LANCZOS)\n",
    "            bg_img_rgb = convert_to_3channel(bg_img)\n",
    "\n",
    "            pollen_count = determine_pollen_count(layout_stats, config_dict.get(\"AVG_POLLEN_PER_IMAGE\", 14))\n",
    "            positions = generate_non_overlapping_positions(pollen_count, BG_SIZE, POLLEN_SIZE_BASE, MARGIN)\n",
    "\n",
    "            if not positions:\n",
    "                logger.warning(f\"Worker {batch_idx}: Could not generate valid positions for image {global_idx}\")\n",
    "                continue\n",
    "\n",
    "            num_needed = len(positions)\n",
    "            num_to_generate = num_needed\n",
    "            if USE_QUALITY_FILTERING:\n",
    "                num_to_generate = int(np.ceil(num_needed * FILTERING_SURPLUS_FACTOR))\n",
    "\n",
    "            # Generate RAW pollen batch (128x128)\n",
    "            pollen_batch_raw = generate_pollen_batch(generator, mini_config, num_to_generate)\n",
    "\n",
    "            pollen_batch_to_place = [] # This will hold the final images to be placed\n",
    "            if USE_QUALITY_FILTERING and critic is not None:\n",
    "                scores_raw = score_pollen_batch(critic, pollen_batch_raw, mini_config) # Score raw images\n",
    "                if scores_raw is not None and len(scores_raw) == len(pollen_batch_raw):\n",
    "                    threshold = np.percentile(scores_raw, 100.0 - mini_config.QUALITY_THRESHOLD_PERCENTILE)\n",
    "                    quality_indices = np.where(scores_raw >= threshold)[0]\n",
    "                    sorted_quality_indices = quality_indices[np.argsort(scores_raw[quality_indices])[::-1]]\n",
    "                    selected_indices = sorted_quality_indices[:num_needed]\n",
    "                    # Select the raw images that passed\n",
    "                    pollen_batch_to_place = [pollen_batch_raw[idx] for idx in selected_indices]\n",
    "                else:\n",
    "                     logger.warning(f\"Worker {batch_idx}: Scoring failed for bg {global_idx}, using raw images.\")\n",
    "                     pollen_batch_to_place = pollen_batch_raw[:num_needed] # Fallback\n",
    "            else:\n",
    "                # If not filtering, just use the first num_needed raw images\n",
    "                pollen_batch_to_place = pollen_batch_raw[:num_needed]\n",
    "\n",
    "            # Adjust positions if filtering resulted in fewer images than planned\n",
    "            if len(pollen_batch_to_place) < len(positions):\n",
    "                positions = positions[:len(pollen_batch_to_place)]\n",
    "\n",
    "            # Process each selected pollen image\n",
    "            result_img = bg_img_rgb.copy()\n",
    "            final_positions_and_sizes = []\n",
    "\n",
    "            for j, (pos, pollen_img_raw) in enumerate(zip(positions, pollen_batch_to_place)):\n",
    "                # Apply geometric transforms to the raw image before placing\n",
    "                transformed_pollen = apply_geometric_transforms(pollen_img_raw, mini_config, real_stats)\n",
    "                # Apply blending using the transformed image\n",
    "                result_img = blend_pollen_onto_background(result_img, transformed_pollen, pos, mini_config)\n",
    "                # Store final position and size of the *transformed* image\n",
    "                final_positions_and_sizes.append((pos, transformed_pollen.size))\n",
    "\n",
    "            # Generate filename, save composed image, save annotation\n",
    "            bg_name = os.path.splitext(os.path.basename(bg_path))[0]\n",
    "            filename = f\"synthetic_{bg_name}_{global_idx+1:04d}.png\"\n",
    "            img_path = os.path.join(composed_dir, filename)\n",
    "            label_path = os.path.join(labels_dir, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "\n",
    "            result_img.save(img_path)\n",
    "\n",
    "            annotation = generate_yolo_annotation(final_positions_and_sizes, BG_SIZE, OBJECT_CLASS)\n",
    "            with open(label_path, 'w') as f:\n",
    "                f.write(annotation)\n",
    "\n",
    "            generated_images.append(img_path)\n",
    "            generated_labels.append(label_path)\n",
    "            timestamps.append(time.time())\n",
    "\n",
    "            # Cleanup for this background image processing\n",
    "            del pollen_batch_raw, pollen_batch_to_place, result_img, bg_img, bg_img_rgb, positions, final_positions_and_sizes\n",
    "            if 'scores_raw' in locals(): del scores_raw\n",
    "            if i % 5 == 0: # Less frequent cleanup within worker\n",
    "                gc.collect()\n",
    "                if DEVICE.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Worker {batch_idx}: Error processing background {bg_path} (global idx {global_idx}): {e}\", exc_info=True)\n",
    "\n",
    "    # Final cleanup for the worker\n",
    "    del generator, critic, mini_config, checkpoint\n",
    "    gc.collect()\n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return generated_images, generated_labels, timestamps\n",
    "\n",
    "# --- Main Function ---\n",
    "def generate_synthetic_dataset(config, logger):\n",
    "    \"\"\"Main function to generate the synthetic dataset.\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        logger.info(\"Starting synthetic dataset generation\")\n",
    "        \n",
    "        # Setup memory monitoring if enabled\n",
    "        memory_monitor_thread = None\n",
    "        stop_monitor_event = threading.Event()\n",
    "        \n",
    "        if config.MONITOR_MEMORY:\n",
    "            memory_monitor_thread = threading.Thread(\n",
    "                target=memory_monitor,\n",
    "                args=(config, logger, stop_monitor_event),\n",
    "                daemon=True\n",
    "            )\n",
    "            memory_monitor_thread.start()\n",
    "        \n",
    "        # Create output directories\n",
    "        logger.info(\"Creating output directories\")\n",
    "        output_dirs = create_output_directories(config)\n",
    "\n",
    "        # --- NEW: Optional Cleanup ---\n",
    "        if config.CLEAN_OUTPUT_BEFORE_RUN:\n",
    "            logger.warning(\"CLEAN_OUTPUT_BEFORE_RUN is True. Deleting existing content in output subdirectories...\")\n",
    "            dirs_to_clean = [\n",
    "                output_dirs['composed'],\n",
    "                # Add others if needed (pollen? labels? graphs? stats?) but be careful\n",
    "            ]\n",
    "            for dir_path in dirs_to_clean:\n",
    "                if os.path.exists(dir_path):\n",
    "                    try:\n",
    "                        # Remove contents, not the directory itself\n",
    "                        for filename in os.listdir(dir_path):\n",
    "                            file_path = os.path.join(dir_path, filename)\n",
    "                            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                                os.unlink(file_path)\n",
    "                            elif os.path.isdir(file_path):\n",
    "                                shutil.rmtree(file_path)\n",
    "                        logger.info(f\"Cleaned directory: {dir_path}\")\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Failed to clean directory {dir_path}: {e}\")\n",
    "                else:\n",
    "                     logger.warning(f\"Directory not found for cleaning: {dir_path}\")\n",
    "        # --- End Cleanup ---\n",
    "        \n",
    "        # Load models\n",
    "        logger.info(\"Loading generator and critic models\")\n",
    "        generator, critic, _ = load_models(config, logger)\n",
    "        \n",
    "        # Calculate or load real data statistics\n",
    "        real_stats = None\n",
    "        if config.CALCULATE_REAL_STATS:\n",
    "            logger.info(\"Calculating statistics from real data\")\n",
    "            real_stats = calculate_real_data_stats(config, logger)\n",
    "        \n",
    "        # Load layout statistics\n",
    "        layout_stats = None\n",
    "        if config.GENERATE_COMPOSED_IMAGES:\n",
    "            logger.info(\"Loading layout statistics\")\n",
    "            layout_stats = load_layout_statistics(config, logger)\n",
    "        \n",
    "        # Track results\n",
    "        results = {\n",
    "            'pollen_generated': 0,\n",
    "            'composed_generated': 0,\n",
    "            'pollen_timestamps': [],\n",
    "            'composed_timestamps': [],\n",
    "            'pollen_sizes': [],\n",
    "            'peak_memory': get_memory_usage(),\n",
    "            # Initialize these to None so they're always in the results dictionary\n",
    "            'real_features_full': None,\n",
    "            'filtered_gen_features_full': None, \n",
    "            'unfiltered_gen_features_full': None,\n",
    "            'analysis_results': {}\n",
    "        }\n",
    "\n",
    "        # ---> INITIALIZATION HERE <---\n",
    "        real_features_full = None\n",
    "        filtered_gen_features_full = None\n",
    "        unfiltered_gen_features_full = None\n",
    "        analysis_results = {} # Also initialize the analysis results dict\n",
    "        # ---> END INITIALIZATION <---\n",
    "        \n",
    "        all_pollen_paths = []\n",
    "        all_composed_paths = []\n",
    "        all_label_paths = []\n",
    "        \n",
    "        # --- Generate individual pollen images ---\n",
    "        all_pollen_data = [] # <-- NEW: Will store {'path': path, 'score': score} dicts\n",
    "        if config.GENERATE_INDIVIDUAL_POLLEN:\n",
    "            logger.info(f\"Generating {config.TARGET_POLLEN_IMAGES} individual pollen images\")\n",
    "            pollen_dir = output_dirs['pollen']\n",
    "    \n",
    "            pollen_generated_count = 0\n",
    "            with tqdm(total=config.TARGET_POLLEN_IMAGES, desc=\"Generating pollen\") as pbar:\n",
    "                while pollen_generated_count < config.TARGET_POLLEN_IMAGES:\n",
    "                    # Check memory periodically\n",
    "                    if pollen_generated_count > 0 and pollen_generated_count % (config.BATCH_SIZE * config.MEMORY_CHECK_INTERVAL) == 0:\n",
    "                        memory_stats = get_memory_usage()\n",
    "                        results['peak_memory'] = max_memory_stats(results['peak_memory'], memory_stats)\n",
    "                        if not check_memory_safe(config, logger):\n",
    "                            logger.warning(\"Memory usage high during pollen generation, performing cleanup\")\n",
    "                            force_memory_cleanup(config)\n",
    "    \n",
    "                    # Determine batch size for this iteration\n",
    "                    num_needed_in_loop = config.TARGET_POLLEN_IMAGES - pollen_generated_count\n",
    "                    batch_size_actual = min(config.BATCH_SIZE, num_needed_in_loop)\n",
    "    \n",
    "                    # Determine number to generate initially (might be more if filtering)\n",
    "                    num_to_generate_raw = batch_size_actual\n",
    "                    if config.USE_QUALITY_FILTERING:\n",
    "                        # Calculate how many raw images we need to generate to likely get 'batch_size_actual' after filtering\n",
    "                        # Example: If threshold is 80% (keep top 80%), we need 1/0.8 = 1.25x\n",
    "                        # Use FILTERING_SURPLUS_FACTOR for consistency\n",
    "                        num_to_generate_raw = int(np.ceil(batch_size_actual * config.FILTERING_SURPLUS_FACTOR))\n",
    "                        # Ensure we generate at least batch_size_actual + a few extra if factor is small\n",
    "                        num_to_generate_raw = max(num_to_generate_raw, batch_size_actual + 2)\n",
    "    \n",
    "                    # Generate raw 128x128 batch\n",
    "                    raw_pollen_batch = generate_pollen_batch(generator, config, num_to_generate_raw)\n",
    "    \n",
    "                    # Score the RAW batch\n",
    "                    raw_scores = None\n",
    "                    if config.USE_QUALITY_FILTERING and critic is not None:\n",
    "                         raw_scores = score_pollen_batch(critic, raw_pollen_batch, config)\n",
    "                    elif critic is not None: # Score even if not filtering, to store the score\n",
    "                         logger.debug(\"Scoring raw batch even though filtering is off.\")\n",
    "                         raw_scores = score_pollen_batch(critic, raw_pollen_batch, config)\n",
    "                    else:\n",
    "                         logger.warning(\"Critic not available, cannot score generated images.\")\n",
    "                         raw_scores = np.zeros(len(raw_pollen_batch)) # Assign dummy scores if critic missing\n",
    "    \n",
    "                    images_to_process = [] # List of tuples: (raw_img, score)\n",
    "                    if config.USE_QUALITY_FILTERING and critic is not None:\n",
    "                        # --- Filtering Logic ---\n",
    "                        # Calculate threshold based on percentile of scores IN THIS BATCH\n",
    "                        threshold = np.percentile(raw_scores, 100.0 - config.QUALITY_THRESHOLD_PERCENTILE)\n",
    "                        # Get indices and scores of images above threshold\n",
    "                        quality_indices = np.where(raw_scores >= threshold)[0]\n",
    "                        # Sort by score (highest first)\n",
    "                        sorted_quality_indices = quality_indices[np.argsort(raw_scores[quality_indices])[::-1]]\n",
    "                        # Take the top 'batch_size_actual' needed for the target count\n",
    "                        selected_indices = sorted_quality_indices[:batch_size_actual]\n",
    "    \n",
    "                        # Add the selected raw images and their scores to the list to process\n",
    "                        for idx in selected_indices:\n",
    "                            images_to_process.append((raw_pollen_batch[idx], raw_scores[idx]))\n",
    "                        logger.debug(f\"Batch Filtering: Kept {len(selected_indices)}/{num_to_generate_raw} images.\")\n",
    "    \n",
    "                    else:\n",
    "                        # --- No Filtering ---\n",
    "                        # Process the first 'batch_size_actual' generated raw images\n",
    "                        for i in range(min(batch_size_actual, len(raw_pollen_batch))):\n",
    "                             images_to_process.append((raw_pollen_batch[i], raw_scores[i]))\n",
    "    \n",
    "                    # Process (transform, save) and store data for the selected images\n",
    "                    for raw_img, score in images_to_process:\n",
    "                        if pollen_generated_count >= config.TARGET_POLLEN_IMAGES:\n",
    "                            break # Stop if target reached mid-batch\n",
    "    \n",
    "                        # Apply geometric transforms to the raw image\n",
    "                        transformed_img = apply_geometric_transforms(raw_img, config, real_stats)\n",
    "    \n",
    "                        # Save the TRANSFORMED image\n",
    "                        filename = f\"pollen_synthetic_{pollen_generated_count+1:06d}.png\"\n",
    "                        save_path = os.path.join(pollen_dir, filename)\n",
    "                        transformed_img.save(save_path)\n",
    "    \n",
    "                        # Store path and the score of the corresponding RAW image\n",
    "                        all_pollen_data.append({\n",
    "                            'path': save_path,\n",
    "                            'score': float(score) if score is not None else None # Store score as float\n",
    "                        })\n",
    "    \n",
    "                        # Track results\n",
    "                        pollen_generated_count += 1\n",
    "                        results['pollen_timestamps'].append(time.time())\n",
    "                        # Storing transformed size might still be useful for other stats\n",
    "                        results['pollen_sizes'].append(transformed_img.size)\n",
    "                        pbar.update(1)\n",
    "    \n",
    "                    # Memory cleanup after each raw batch generation/scoring/filtering\n",
    "                    del raw_pollen_batch, raw_scores, images_to_process\n",
    "                    force_memory_cleanup(config)\n",
    "    \n",
    "                    if pollen_generated_count >= config.TARGET_POLLEN_IMAGES:\n",
    "                        break # Exit outer loop if target reached\n",
    "    \n",
    "            results['pollen_generated'] = pollen_generated_count\n",
    "            logger.info(f\"Generated {pollen_generated_count} individual pollen images and stored their raw scores.\")\n",
    "    \n",
    "        # --- Generate composed images ---\n",
    "        if config.GENERATE_COMPOSED_IMAGES:\n",
    "            logger.info(f\"Generating {config.TARGET_COMPOSED_IMAGES} composed images\")\n",
    "            \n",
    "            # Load background images\n",
    "            bg_paths = load_background_images(config, logger)\n",
    "            \n",
    "            # If we need more than available, use backgrounds multiple times\n",
    "            if len(bg_paths) < config.TARGET_COMPOSED_IMAGES:\n",
    "                multiplier = config.TARGET_COMPOSED_IMAGES // len(bg_paths) + 1\n",
    "                bg_paths = bg_paths * multiplier\n",
    "            \n",
    "            # Shuffle backgrounds for variety\n",
    "            random.shuffle(bg_paths)\n",
    "            bg_paths = bg_paths[:config.TARGET_COMPOSED_IMAGES]\n",
    "            \n",
    "            # Process sequentially (safer in Jupyter)\n",
    "            config.USE_PARALLEL_PROCESSING = False  # Force sequential processing\n",
    "            logger.info(\"Processing composed images sequentially (safer in Jupyter)\")\n",
    "            \n",
    "            # Convert config to dict\n",
    "            config_dict = {k: v for k, v in vars(config).items() if k != 'DEVICE'}\n",
    "            \n",
    "            composed_count = 0\n",
    "            all_composed_paths = []\n",
    "            all_label_paths = []\n",
    "            \n",
    "            # Prepare backgrounds in chunks\n",
    "            chunks = []\n",
    "            chunk_size = config.CHUNK_SIZE\n",
    "            for i in range(0, len(bg_paths), chunk_size):\n",
    "                chunks.append(bg_paths[i:i+chunk_size])\n",
    "            \n",
    "            # Process each chunk sequentially\n",
    "            for chunk_idx, bg_chunk in enumerate(tqdm(chunks, desc=\"Processing composed batches\")):\n",
    "                # Use process_composed_batch but call it directly\n",
    "                img_paths, label_paths, timestamps = process_composed_batch(\n",
    "                    (chunk_idx, config_dict, bg_chunk, real_stats, layout_stats)\n",
    "                )\n",
    "                \n",
    "                all_composed_paths.extend(img_paths)\n",
    "                all_label_paths.extend(label_paths)\n",
    "                results['composed_timestamps'].extend(timestamps)\n",
    "                composed_count += len(img_paths)\n",
    "                \n",
    "                # Update progress\n",
    "                logger.info(f\"Generated {composed_count}/{config.TARGET_COMPOSED_IMAGES} composed images\")\n",
    "                \n",
    "                # Enforce memory cleanup between chunks\n",
    "                force_memory_cleanup()\n",
    "            \n",
    "            # Update results\n",
    "            results['composed_generated'] = composed_count\n",
    "            logger.info(f\"Generated {composed_count} composed images\")\n",
    "        \n",
    "        \"\"\"\n",
    "        # --- Analysis and Visualization ---\n",
    "        \"\"\"\n",
    "\n",
    "        # --- Analysis and Visualization ---\n",
    "\n",
    "        # Near the beginning of your analysis section\n",
    "        logger.info(f\"DEBUG: Analysis section - VISUALIZE_TSNE={config.VISUALIZE_TSNE}, VISUALIZE_UMAP={config.VISUALIZE_UMAP}\")\n",
    "        logger.info(f\"DEBUG: VISUALIZATION_SAMPLE_SIZE={config.VISUALIZATION_SAMPLE_SIZE}, ANALYSIS_SAMPLE_SIZE={config.ANALYSIS_SAMPLE_SIZE}\")\n",
    "\n",
    "        #\n",
    "        # --- Analysis and Visualization ---\n",
    "        if config.PERFORM_ANALYSIS and (all_pollen_data or all_composed_paths): # <-- Use all_pollen_data\n",
    "            logger.info(\"=\"*40 + \" STARTING ANALYSIS \" + \"=\"*40)\n",
    "            analysis_start_time = time.time()\n",
    "            graph_dir = output_dirs['graphs']\n",
    "            stats_dir = output_dirs['stats'] # For temp files used by torch-fidelity\n",
    "            os.makedirs(graph_dir, exist_ok=True)\n",
    "            os.makedirs(stats_dir, exist_ok=True)\n",
    "        \n",
    "            # Track analysis results separately\n",
    "            analysis_results = {\n",
    "                \"prdc_metrics_filtered\": None,\n",
    "                \"prdc_metrics_unfiltered\": None,\n",
    "                \"fid_kid_filtered\": None,\n",
    "                \"fid_kid_unfiltered\": None,\n",
    "                \"avg_critic_score_filtered\": None,\n",
    "                \"avg_critic_score_unfiltered\": None\n",
    "            }\n",
    "        \n",
    "            # --- Common Setup for Analysis ---\n",
    "            inception_model = None\n",
    "            real_features_full = None\n",
    "            prdc_possible = NEIGHBORS_AVAILABLE or TORCH_FIDELITY_AVAILABLE\n",
    "            fid_kid_possible = FID_AVAILABLE and SKLEARN_KERNELS_AVAILABLE\n",
    "            critic_available_for_scoring = critic is not None # Critic needs to exist for unfiltered scoring\n",
    "        \n",
    "            # Check if any analysis requiring features is possible and enabled\n",
    "            feature_analysis_needed = (config.MEASURE_PRDC and prdc_possible) or \\\n",
    "                                      ((config.MEASURE_FID or config.MEASURE_KID) and fid_kid_possible)\n",
    "        \n",
    "            analysis_possible = feature_analysis_needed or (config.USE_QUALITY_FILTERING and critic_available_for_scoring)\n",
    "        \n",
    "            if feature_analysis_needed:\n",
    "                if FID_AVAILABLE:\n",
    "                    logger.info(\"Loading InceptionV3 model for analysis...\")\n",
    "                    try:\n",
    "                        inception_model = get_inception_model(config)\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Failed to load InceptionV3 model: {e}. Skipping feature-based analysis (FID/KID/PRDC).\")\n",
    "                        prdc_possible = False\n",
    "                        fid_kid_possible = False\n",
    "                        feature_analysis_needed = False # Can't do feature analysis\n",
    "                else:\n",
    "                    logger.warning(\"InceptionV3 (pytorch-fid) not available. Skipping feature-based analysis (FID/KID/PRDC).\")\n",
    "                    prdc_possible = False\n",
    "                    fid_kid_possible = False\n",
    "                    feature_analysis_needed = False\n",
    "        \n",
    "            # Extract real features only if needed for feature-based metrics\n",
    "            if feature_analysis_needed: # Only extract if we can and need to calculate feature metrics\n",
    "                logger.info(\"Extracting features from real images for comparison...\")\n",
    "                real_data_path = config.get_real_data_path()\n",
    "                real_image_paths = []\n",
    "                for ext in ['.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff']:\n",
    "                    real_image_paths.extend(list(Path(real_data_path).glob(f\"*{ext}\")))\n",
    "        \n",
    "                if real_image_paths:\n",
    "                    metric_sample_size = min(config.ANALYSIS_SAMPLE_SIZE, len(real_image_paths))\n",
    "                    if metric_sample_size < 100:\n",
    "                         logger.warning(f\"Not enough real images ({metric_sample_size}) for reliable analysis. Need >= 100. Skipping feature-based analysis.\")\n",
    "                         feature_analysis_needed = False\n",
    "                         prdc_possible = False\n",
    "                         fid_kid_possible = False\n",
    "                    else:\n",
    "                        random.seed(config.RANDOM_SEED)\n",
    "                        np.random.seed(config.RANDOM_SEED)\n",
    "                        real_metric_paths = random.sample(real_image_paths, metric_sample_size)\n",
    "                        logger.info(f\"Using {len(real_metric_paths)} real image samples for metric calculation.\")\n",
    "                        real_features_full = extract_features(real_metric_paths, inception_model, config, is_real=True)\n",
    "        \n",
    "                        if real_features_full is None:\n",
    "                            logger.error(\"Failed to extract real features. Aborting feature-based analysis.\")\n",
    "                            feature_analysis_needed = False\n",
    "                            prdc_possible = False\n",
    "                            fid_kid_possible = False\n",
    "                else:\n",
    "                    logger.warning(\"No real images found for analysis comparison. Aborting feature-based analysis.\")\n",
    "                    feature_analysis_needed = False\n",
    "                    prdc_possible = False\n",
    "                    fid_kid_possible = False\n",
    "        \n",
    "            # <<< Start of the main analysis block >>>\n",
    "            if analysis_possible:\n",
    "        \n",
    "                # --- Analysis 1: Using Saved (Potentially Filtered) Generated Pollen ---\n",
    "                logger.info(\"--- Analysis 1: Saved (Potentially Filtered) Generated Images ---\")\n",
    "                filtered_gen_features_full = None # Initialize\n",
    "                if not all_pollen_data:\n",
    "                    logger.warning(\"No saved pollen data found (paths/scores), skipping filtered analysis.\")\n",
    "                else:\n",
    "                    metric_gen_samples_f = min(config.ANALYSIS_SAMPLE_SIZE, len(all_pollen_data))\n",
    "                    if metric_gen_samples_f < 100:\n",
    "                        logger.warning(f\"Not enough saved generated samples ({metric_gen_samples_f}) for filtered analysis (minimum 100 required).\")\n",
    "                    else:\n",
    "                        random.seed(config.RANDOM_SEED)\n",
    "                        np.random.seed(config.RANDOM_SEED)\n",
    "                        # Sample the list of dictionaries\n",
    "                        filtered_sample_data = random.sample(all_pollen_data, metric_gen_samples_f)\n",
    "        \n",
    "                        # --- Calculate Average Critic Score (Filtered) --- # <-- MODIFIED Block\n",
    "                        # Extract scores from the sampled data\n",
    "                        filtered_scores_sample = [item['score'] for item in filtered_sample_data if item['score'] is not None]\n",
    "                        if filtered_scores_sample:\n",
    "                            avg_score_f = np.mean(filtered_scores_sample)\n",
    "                            analysis_results['avg_critic_score_filtered'] = float(avg_score_f)\n",
    "                            logger.info(f\"Average Critic Score (Filtered Sample): {avg_score_f:.4f}\")\n",
    "                        elif config.USE_QUALITY_FILTERING: # Only warn if filtering was on\n",
    "                            logger.warning(\"No valid critic scores found for the filtered sample.\")\n",
    "                        # --- End Critic Score Block ---\n",
    "        \n",
    "                        # Extract features if needed for other metrics\n",
    "                        if feature_analysis_needed and inception_model is not None:\n",
    "                            # Extract paths from the sampled data\n",
    "                            filtered_metric_paths = [item['path'] for item in filtered_sample_data]\n",
    "                            logger.info(f\"Extracting features from {len(filtered_metric_paths)} saved/filtered generated images for metrics...\")\n",
    "                            filtered_gen_features_full = extract_features(filtered_metric_paths, inception_model, config, is_real=False)\n",
    "        \n",
    "                            if filtered_gen_features_full is not None and real_features_full is not None:\n",
    "                                # --- Subsample for VISUALIZATION (t-SNE/UMAP) ---\n",
    "                                vis_samples_per_set = config.VISUALIZATION_SAMPLE_SIZE // 2\n",
    "                                n_real_vis = min(vis_samples_per_set, len(real_features_full))\n",
    "                                n_gen_vis = min(vis_samples_per_set, len(filtered_gen_features_full))\n",
    "        \n",
    "                                if n_real_vis > 0 and n_gen_vis > 0:\n",
    "                                    # (Visualization logic remains the same - uses features)\n",
    "                                    np.random.seed(config.RANDOM_SEED)\n",
    "                                    real_vis_indices = np.random.choice(len(real_features_full), n_real_vis, replace=False)\n",
    "                                    gen_vis_indices = np.random.choice(len(filtered_gen_features_full), n_gen_vis, replace=False)\n",
    "                                    real_features_vis = real_features_full[real_vis_indices]\n",
    "                                    filtered_gen_features_vis = filtered_gen_features_full[gen_vis_indices]\n",
    "                                    logger.info(f\"Subsampling {n_real_vis} real and {n_gen_vis} generated features for visualization.\")\n",
    "        \n",
    "                                    # Generate t-SNE visualization (Filtered)\n",
    "                                    if config.VISUALIZE_TSNE and TSNE_AVAILABLE:\n",
    "                                        tsne_path_f = os.path.join(graph_dir, \"tsne_visualization_filtered.png\")\n",
    "                                        logger.info(f\"Generating t-SNE plot (Filtered): {tsne_path_f}\")\n",
    "                                        generate_tsne_plot(real_features_vis, filtered_gen_features_vis, \"Real vs. Generated (Filtered)\", tsne_path_f, config)\n",
    "        \n",
    "                                    # Generate UMAP visualization (Filtered)\n",
    "                                    if config.VISUALIZE_UMAP and HAS_UMAP:\n",
    "                                        umap_path_f = os.path.join(graph_dir, \"umap_visualization_filtered.png\")\n",
    "                                        logger.info(f\"Generating UMAP plot (Filtered): {umap_path_f}\")\n",
    "                                        generate_umap_plot(real_features_vis, filtered_gen_features_vis, \"Real vs. Generated (Filtered)\", umap_path_f, config)\n",
    "        \n",
    "                                    del real_features_vis, filtered_gen_features_vis, real_vis_indices, gen_vis_indices\n",
    "                                else:\n",
    "                                    logger.warning(\"Not enough features to create filtered visualizations.\")\n",
    "        \n",
    "                                # --- Calculate METRICS (PRDC, FID, KID) ---\n",
    "                                # (Metric calculation logic remains the same - uses features)\n",
    "                                min_f_samples_metric = min(len(real_features_full), len(filtered_gen_features_full))\n",
    "                                if min_f_samples_metric < 100:\n",
    "                                     logger.warning(f\"Too few samples ({min_f_samples_metric}) for reliable filtered metric calculation.\")\n",
    "                                else:\n",
    "                                    real_features_f_metric = real_features_full[:min_f_samples_metric]\n",
    "                                    filtered_gen_features_f_metric = filtered_gen_features_full[:min_f_samples_metric]\n",
    "        \n",
    "                                    # Calculate PRDC (Filtered)\n",
    "                                    if config.MEASURE_PRDC and prdc_possible:\n",
    "                                        if min_f_samples_metric < config.MANIFOLD_K + 1 and NEIGHBORS_AVAILABLE:\n",
    "                                            logger.warning(f\"Too few samples ({min_f_samples_metric}) for custom PRDC (k={config.MANIFOLD_K}). Skipping filtered PRDC.\")\n",
    "                                        else:\n",
    "                                            logger.info(f\"Calculating PRDC metrics using {min_f_samples_metric} real vs {min_f_samples_metric} filtered generated features.\")\n",
    "                                            prdc_metrics_f = calculate_prdc_metrics(real_features_f_metric, filtered_gen_features_f_metric, config)\n",
    "                                            analysis_results['prdc_metrics_filtered'] = prdc_metrics_f\n",
    "                                            radar_path_f = os.path.join(graph_dir, \"prdc_radar_filtered.png\")\n",
    "                                            logger.info(f\"Generating PRDC radar chart (Filtered): {radar_path_f}\")\n",
    "                                            generate_radar_chart(prdc_metrics_f, \"Distribution Metrics (Filtered - Individual)\", radar_path_f)\n",
    "                                    else:\n",
    "                                         logger.info(\"Skipping PRDC metric calculation (Filtered) as per config or dependencies.\")\n",
    "        \n",
    "                                    # Calculate FID/KID (Filtered)\n",
    "                                    if (config.MEASURE_FID or config.MEASURE_KID) and fid_kid_possible:\n",
    "                                         logger.info(f\"Calculating FID/KID using {min_f_samples_metric} real vs {min_f_samples_metric} filtered generated features.\")\n",
    "                                         fid_kid_f = calculate_fid_kid(real_features_f_metric, filtered_gen_features_f_metric, config, logger)\n",
    "                                         analysis_results['fid_kid_filtered'] = fid_kid_f\n",
    "                                    else:\n",
    "                                         logger.info(\"Skipping FID/KID calculation (Filtered) as per config or dependencies.\")\n",
    "        \n",
    "                                    del real_features_f_metric, filtered_gen_features_f_metric\n",
    "        \n",
    "                            else: # If feature extraction failed\n",
    "                                 logger.warning(\"Feature extraction failed for filtered generated images. Skipping feature-based metrics.\")\n",
    "        \n",
    "                        analysis_results[\"filtered_features_computed\"] = filtered_gen_features_full is not None\n",
    "                        # Add features to the main results dict to return them\n",
    "                        results['analysis_results'] = analysis_results # Keep analysis metrics together\n",
    "                        results['filtered_gen_features_full'] = filtered_gen_features_full\n",
    "\n",
    "                        # Cleanup full features for this part if they exist\n",
    "                        if filtered_gen_features_full is not None:\n",
    "                            del filtered_gen_features_full\n",
    "                        del filtered_sample_data # <-- NEW cleanup for sampled data\n",
    "                        force_memory_cleanup(config) # Cleanup after Analysis 1\n",
    "                        #\n",
    "                        # --- CLEANUP POINT 1: After filtered analysis ---\n",
    "                        #  (redacted this code block to avoid issues)\n",
    "        \n",
    "                # --- Analysis 2: Using Unfiltered Generated Pollen ---\n",
    "                logger.info(\"--- Analysis 2: Unfiltered Generated Images ---\")\n",
    "                unfiltered_gen_features_full = None # Initialize\n",
    "                num_unfiltered_samples_metric = config.ANALYSIS_SAMPLE_SIZE\n",
    "                logger.info(f\"Generating {num_unfiltered_samples_metric} new unfiltered images for analysis...\")\n",
    "        \n",
    "                # (Generator device handling logic remains the same)\n",
    "                gen_device = next(generator.parameters()).device\n",
    "                temp_device_change = False\n",
    "                if gen_device != config.DEVICE:\n",
    "                    logger.info(f\"Temporarily moving generator to {config.DEVICE} for unfiltered generation.\")\n",
    "                    generator.to(config.DEVICE)\n",
    "                    temp_device_change = True\n",
    "        \n",
    "                unfiltered_images = [] # This list will hold raw 128x128 PIL images\n",
    "                try:\n",
    "                    batches_needed = math.ceil(num_unfiltered_samples_metric / config.BATCH_SIZE)\n",
    "                    for _ in tqdm(range(batches_needed), desc=\"Generating unfiltered images\"):\n",
    "                        batch_size = min(config.BATCH_SIZE, num_unfiltered_samples_metric - len(unfiltered_images))\n",
    "                        if batch_size <= 0: break\n",
    "                        new_batch = generate_pollen_batch(generator, config, batch_size)\n",
    "                        unfiltered_images.extend(new_batch)\n",
    "                        if len(unfiltered_images) % (config.BATCH_SIZE * 5) == 0: force_memory_cleanup(config)\n",
    "                except Exception as gen_err:\n",
    "                     logger.error(f\"Error during unfiltered image generation: {gen_err}\", exc_info=True)\n",
    "                finally:\n",
    "                     if temp_device_change:\n",
    "                         logger.info(f\"Moving generator back to {gen_device}.\")\n",
    "                         generator.to(gen_device)\n",
    "                         force_memory_cleanup(config)\n",
    "        \n",
    "                unfiltered_images = unfiltered_images[:num_unfiltered_samples_metric]\n",
    "                logger.info(f\"Generated {len(unfiltered_images)} unfiltered images.\")\n",
    "        \n",
    "                if len(unfiltered_images) < 100:\n",
    "                    logger.warning(f\"Generated fewer than 100 unfiltered images ({len(unfiltered_images)}). Skipping unfiltered analysis.\")\n",
    "                else:\n",
    "                    # --- Calculate Average Critic Score (Unfiltered) --- # <-- Keep this block\n",
    "                    if critic_available_for_scoring:\n",
    "                        logger.info(f\"Calculating average critic score for {len(unfiltered_images)} unfiltered samples...\")\n",
    "                        try:\n",
    "                            # Score the raw unfiltered images\n",
    "                            unfiltered_scores = score_pollen_batch(critic, unfiltered_images, config)\n",
    "                            if unfiltered_scores is not None and len(unfiltered_scores) > 0:\n",
    "                                 avg_score_u = np.mean(unfiltered_scores)\n",
    "                                 analysis_results['avg_critic_score_unfiltered'] = float(avg_score_u)\n",
    "                                 logger.info(f\"Average Critic Score (Unfiltered): {avg_score_u:.4f}\")\n",
    "                            else:\n",
    "                                 logger.warning(\"No scores calculated for unfiltered images.\")\n",
    "                            del unfiltered_scores\n",
    "                        except Exception as score_err:\n",
    "                             logger.error(f\"Error calculating critic scores for unfiltered images: {score_err}\", exc_info=True)\n",
    "                        finally:\n",
    "                             force_memory_cleanup(config)\n",
    "                    else:\n",
    "                         logger.info(\"Skipping critic score calculation (Unfiltered) as critic is not available.\")\n",
    "                    # --- End Critic Score Block ---\n",
    "        \n",
    "                    # Extract features if needed\n",
    "                    if feature_analysis_needed and inception_model is not None:\n",
    "                        logger.info(f\"Extracting features from {len(unfiltered_images)} unfiltered generated images for metrics...\")\n",
    "                        # Pass the raw 128x128 PIL images; extract_features handles resizing\n",
    "                        unfiltered_gen_features_full = extract_features(unfiltered_images, inception_model, config, is_real=False)\n",
    "        \n",
    "                    # Cleanup PIL images (do this AFTER feature extraction AND scoring)\n",
    "                    logger.debug(\"Cleaning up unfiltered PIL images from memory.\")\n",
    "                    del unfiltered_images\n",
    "                    force_memory_cleanup(config)\n",
    "        \n",
    "                    if unfiltered_gen_features_full is not None and real_features_full is not None:\n",
    "                        # --- Subsample for VISUALIZATION ---\n",
    "                        # (Visualization logic remains the same)\n",
    "                        vis_samples_per_set = config.VISUALIZATION_SAMPLE_SIZE // 2\n",
    "                        n_real_vis = min(vis_samples_per_set, len(real_features_full))\n",
    "                        n_gen_vis = min(vis_samples_per_set, len(unfiltered_gen_features_full))\n",
    "                        if n_real_vis > 0 and n_gen_vis > 0:\n",
    "                            np.random.seed(config.RANDOM_SEED)\n",
    "                            real_vis_indices = np.random.choice(len(real_features_full), n_real_vis, replace=False)\n",
    "                            gen_vis_indices = np.random.choice(len(unfiltered_gen_features_full), n_gen_vis, replace=False)\n",
    "                            real_features_vis = real_features_full[real_vis_indices]\n",
    "                            unfiltered_gen_features_vis = unfiltered_gen_features_full[gen_vis_indices]\n",
    "                            logger.info(f\"Subsampling {n_real_vis} real and {n_gen_vis} generated features for visualization.\")\n",
    "                            # t-SNE Unfiltered\n",
    "                            if config.VISUALIZE_TSNE and TSNE_AVAILABLE:\n",
    "                                tsne_path_u = os.path.join(graph_dir, \"tsne_visualization_unfiltered.png\")\n",
    "                                logger.info(f\"Generating t-SNE plot (Unfiltered): {tsne_path_u}\")\n",
    "                                generate_tsne_plot(real_features_vis, unfiltered_gen_features_vis, \"Real vs. Generated (Unfiltered)\", tsne_path_u, config)\n",
    "                            # UMAP Unfiltered\n",
    "                            if config.VISUALIZE_UMAP and HAS_UMAP:\n",
    "                                umap_path_u = os.path.join(graph_dir, \"umap_visualization_unfiltered.png\")\n",
    "                                logger.info(f\"Generating UMAP plot (Unfiltered): {umap_path_u}\")\n",
    "                                generate_umap_plot(real_features_vis, unfiltered_gen_features_vis, \"Real vs. Generated (Unfiltered)\", umap_path_u, config)\n",
    "                            del real_features_vis, unfiltered_gen_features_vis, real_vis_indices, gen_vis_indices\n",
    "                        else:\n",
    "                             logger.warning(\"Not enough features to create unfiltered visualizations.\")\n",
    "        \n",
    "                        # --- Calculate METRICS (PRDC, FID, KID) ---\n",
    "                        # (Metric calculation logic remains the same)\n",
    "                        min_u_samples_metric = min(len(real_features_full), len(unfiltered_gen_features_full))\n",
    "                        if min_u_samples_metric < 100:\n",
    "                             logger.warning(f\"Too few samples ({min_u_samples_metric}) for reliable unfiltered metric calculation.\")\n",
    "                        else:\n",
    "                            real_features_u_metric = real_features_full[:min_u_samples_metric]\n",
    "                            unfiltered_gen_features_u_metric = unfiltered_gen_features_full[:min_u_samples_metric]\n",
    "                            # PRDC Unfiltered\n",
    "                            if config.MEASURE_PRDC and prdc_possible:\n",
    "                                if min_u_samples_metric < config.MANIFOLD_K + 1 and NEIGHBORS_AVAILABLE:\n",
    "                                    logger.warning(f\"Too few samples ({min_u_samples_metric}) for custom PRDC (k={config.MANIFOLD_K}). Skipping unfiltered PRDC.\")\n",
    "                                else:\n",
    "                                    logger.info(f\"Calculating PRDC metrics using {min_u_samples_metric} real vs {min_u_samples_metric} unfiltered generated features.\")\n",
    "                                    prdc_metrics_u = calculate_prdc_metrics(real_features_u_metric, unfiltered_gen_features_u_metric, config)\n",
    "                                    analysis_results['prdc_metrics_unfiltered'] = prdc_metrics_u\n",
    "                                    radar_path_u = os.path.join(graph_dir, \"prdc_radar_unfiltered.png\")\n",
    "                                    logger.info(f\"Generating PRDC radar chart (Unfiltered): {radar_path_u}\")\n",
    "                                    generate_radar_chart(prdc_metrics_u, \"Distribution Metrics (Unfiltered - Individual)\", radar_path_u)\n",
    "                            else:\n",
    "                                logger.info(\"Skipping PRDC metric calculation (Unfiltered) as per config or dependencies.\")\n",
    "                            # FID/KID Unfiltered\n",
    "                            if (config.MEASURE_FID or config.MEASURE_KID) and fid_kid_possible:\n",
    "                                 logger.info(f\"Calculating FID/KID using {min_u_samples_metric} real vs {min_u_samples_metric} unfiltered generated features.\")\n",
    "                                 fid_kid_u = calculate_fid_kid(real_features_u_metric, unfiltered_gen_features_u_metric, config, logger)\n",
    "                                 analysis_results['fid_kid_unfiltered'] = fid_kid_u\n",
    "                            else:\n",
    "                                 logger.info(\"Skipping FID/KID calculation (Unfiltered) as per config or dependencies.\")\n",
    "                            del real_features_u_metric, unfiltered_gen_features_u_metric\n",
    "        \n",
    "                        analysis_results[\"unfiltered_features_computed\"] = unfiltered_gen_features_full is not None\n",
    "                        # Add features to the main results dict to return them\n",
    "                        results['analysis_results'] = analysis_results # Keep analysis metrics together\n",
    "                        results['unfiltered_gen_features_full'] = unfiltered_gen_features_full\n",
    "\n",
    "                        # Cleanup full features for this part if they exist\n",
    "                        if unfiltered_gen_features_full is not None:\n",
    "                             del unfiltered_gen_features_full\n",
    "        \n",
    "                    elif not feature_analysis_needed: # If only critic scoring was done\n",
    "                         logger.info(\"Only critic scoring performed for unfiltered images as feature analysis was skipped or failed.\")\n",
    "                    else: # If feature extraction failed for unfiltered gen images\n",
    "                        logger.warning(\"Feature extraction failed for unfiltered generated images. Skipping feature-based metrics.\")\n",
    "\n",
    "                force_memory_cleanup(config) # Cleanup after Analysis 2\n",
    "                #\n",
    "                # --- CLEANUP POINT 2: After unfiltered analysis ---\n",
    "                #  (redacted this code block to avoid issues)\n",
    "        \n",
    "                # --- Generate Combined/Comparison Plots AFTER both analyses attempts ---\n",
    "                # Combined PRDC Radar Chart\n",
    "                metrics_f_prdc = analysis_results.get('prdc_metrics_filtered')\n",
    "                metrics_u_prdc = analysis_results.get('prdc_metrics_unfiltered')\n",
    "                if metrics_f_prdc and metrics_u_prdc:\n",
    "                    combined_prdc_radar_path = os.path.join(graph_dir, \"prdc_radar_comparison.png\")\n",
    "                    logger.info(f\"Generating combined PRDC radar chart: {combined_prdc_radar_path}\")\n",
    "                    plot_combined_radar_chart(\n",
    "                        metrics_f_prdc, metrics_u_prdc,\n",
    "                        label1='Filtered', label2='Unfiltered',\n",
    "                        title='PRDC Comparison (Individual Distances)',\n",
    "                        output_path=combined_prdc_radar_path\n",
    "                    )\n",
    "                elif config.MEASURE_PRDC:\n",
    "                    logger.warning(\"Skipping combined PRDC radar chart generation as one or both metric sets are missing.\")\n",
    "        \n",
    "                # Combined FID/KID Bar Chart\n",
    "                fid_kid_f = analysis_results.get('fid_kid_filtered')\n",
    "                fid_kid_u = analysis_results.get('fid_kid_unfiltered')\n",
    "                if fid_kid_f or fid_kid_u: # If at least one result exists\n",
    "                     combined_fid_kid_path = os.path.join(graph_dir, \"fid_kid_comparison.png\")\n",
    "                     logger.info(f\"Generating FID/KID comparison chart: {combined_fid_kid_path}\")\n",
    "                     plot_fid_kid_comparison(analysis_results, combined_fid_kid_path, logger)\n",
    "                elif config.MEASURE_FID or config.MEASURE_KID:\n",
    "                     logger.warning(\"Skipping FID/KID comparison plot as no FID/KID results were calculated.\")\n",
    "                #\n",
    "                # --- Sample Visualization ---\n",
    "                if all_pollen_data and all_composed_paths: # Use all_pollen_data here\n",
    "                    logger.info(\"Creating sample visualization\")\n",
    "                    sample_vis_path = os.path.join(graph_dir, \"sample_visualization.png\")\n",
    "                    # Define how many samples the visualization function should display\n",
    "                    num_samples = 4 # <-- DEFINE the variable here\n",
    "                    # Extract more paths than needed initially, the function will select the first num_samples\n",
    "                    # Ensure we don't try to slice more than available\n",
    "                    num_paths_to_get = min(len(all_pollen_data), num_samples * 2)\n",
    "                    pollen_paths_for_vis = [item['path'] for item in all_pollen_data[:num_paths_to_get]]\n",
    "                    save_sample_visualization(\n",
    "                        pollen_paths_for_vis, all_composed_paths, all_label_paths, # Pass paths list\n",
    "                        sample_vis_path, num_samples=num_samples # Use the variable for clarity\n",
    "                    )\n",
    "                #\n",
    "                # --- CLEANUP POINT 3: After comparison plots ---\n",
    "                #  (redacted this code block to avoid issues)\n",
    "\n",
    "                # Inside generate_synthetic_dataset, near the end of the analysis block\n",
    "                # ... (existing analysis code) ...\n",
    "                \n",
    "                analysis_results[\"real_features_computed\"] = real_features_full is not None\n",
    "                # Add features to the main results dict to return them\n",
    "                results['analysis_results'] = analysis_results # Keep analysis metrics together\n",
    "                results['real_features_full'] = real_features_full\n",
    "                \n",
    "                # ... (rest of the function, e.g., report generation) ...\n",
    "        \n",
    "                # --- Final Cleanup of Analysis Resources ---\n",
    "                logger.debug(\"Cleaning up final analysis resources.\")\n",
    "                if inception_model is not None:\n",
    "                    del inception_model\n",
    "                    logger.debug(\"Deleted Inception model.\")\n",
    "                if real_features_full is not None:\n",
    "                    del real_features_full\n",
    "                    logger.debug(\"Deleted full real features.\")\n",
    "                force_memory_cleanup(config) # One last cleanup\n",
    "        \n",
    "                analysis_duration = time.time() - analysis_start_time\n",
    "                logger.info(f\"Analysis and Visualization completed in {analysis_duration:.3f} seconds\")\n",
    "                logger.info(\"=\"*40 + \" FINISHED ANALYSIS \" + \"=\"*40)\n",
    "        \n",
    "            # <<< End of the main analysis block gated by initial analysis_possible check >>>\n",
    "            else: # If analysis was not possible from the start\n",
    "                logger.warning(\"Analysis was skipped because dependencies were missing, initial setup failed, or not enough data.\")\n",
    "        \n",
    "        # <<< This else belongs to the initial if config.PERFORM_ANALYSIS check >>>\n",
    "        else:\n",
    "            logger.info(\"Skipping analysis as per configuration or no images were generated.\")\n",
    "        \n",
    "        # --- Finalize Results ---\n",
    "        end_time = time.time()\n",
    "        results['total_time'] = end_time - start_time\n",
    "        \n",
    "        # Get peak memory usage\n",
    "        memory_stats = get_memory_usage()\n",
    "        results['peak_memory'] = max_memory_stats(results['peak_memory'], memory_stats)\n",
    "        \n",
    "        # Create summary report\n",
    "        logger.info(\"Creating performance summary\")\n",
    "        create_performance_summary(config, results, analysis_results, logger)\n",
    "        \n",
    "        # Generate markdown report\n",
    "        if config.GENERATE_REPORTS:\n",
    "            logger.info(\"Generating markdown report\")\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            report_path = os.path.join(output_dirs['reports'], f\"generation_report_{timestamp}.md\")\n",
    "            create_markdown_report(config, results, analysis_results, real_stats, report_path)\n",
    "            logger.info(f\"Report saved to {report_path}\")\n",
    "        \n",
    "        # Save final configuration\n",
    "        if config.SAVE_CHECKPOINTS:\n",
    "            logger.info(\"Saving final configuration\")\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            config_path = os.path.join(output_dirs['configs'], f\"config_{timestamp}.json\")\n",
    "            config.save(config_path)\n",
    "            logger.info(f\"Configuration saved to {config_path}\")\n",
    "        \n",
    "        # Stop memory monitoring\n",
    "        if memory_monitor_thread is not None:\n",
    "            stop_monitor_event.set()\n",
    "            memory_monitor_thread.join(timeout=5)\n",
    "        \n",
    "        logger.info(\"=\" * 80)\n",
    "        logger.info(\"Synthetic dataset generation completed\")\n",
    "        logger.info(f\"Total execution time: {results['total_time']:.3f} seconds\")\n",
    "        logger.info(f\"Individual pollen images: {results['pollen_generated']}/{config.TARGET_POLLEN_IMAGES}\")\n",
    "        logger.info(f\"Composed images: {results['composed_generated']}/{config.TARGET_COMPOSED_IMAGES}\")\n",
    "        logger.info(\"=\" * 80)\n",
    "        #\n",
    "        # --- CLEANUP POINT 4: Before returning results ---\n",
    "        #  (redacted this code block to avoid issues)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Critical error in synthetic dataset generation: {e}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        \n",
    "        # Stop memory monitoring\n",
    "        if 'stop_monitor_event' in locals() and stop_monitor_event is not None:\n",
    "            stop_monitor_event.set()\n",
    "        \n",
    "        raise\n",
    " \n",
    "# --- Utility Functions ---\n",
    "def max_memory_stats(stats1, stats2):\n",
    "    \"\"\"Return the maximum values between two memory statistics dictionaries.\"\"\"\n",
    "    result = {}\n",
    "    for key in stats1.keys():\n",
    "        if key in stats2:\n",
    "            result[key] = max(stats1[key], stats2[key])\n",
    "        else:\n",
    "            result[key] = stats1[key]\n",
    "    return result\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Configure exception handling for better visibility in Jupyter\n",
    "    configure_exception_handler()\n",
    "    \n",
    "    # Initialize configuration\n",
    "    config = Config()\n",
    "\n",
    "    # Uncomment to inspect the checkpoint structure:\n",
    "    inspect_checkpoint(config.CHECKPOINT_PATH)\n",
    "\n",
    "    # quantitatively inspect the generated surplus & the selected top \n",
    "    print(\"\\n'FILTERING_SURPLUS_FACTOR' = '\", config.FILTERING_SURPLUS_FACTOR, \"'; \")\n",
    "    print(\"\\n'QUALITY_THRESHOLD_PERCENTILE' = '\", config.QUALITY_THRESHOLD_PERCENTILE, \"'; \")\n",
    "    \n",
    "    # Setup logging with more console output\n",
    "    logger = setup_logging(config)\n",
    "    logger.handlers[1].setLevel(logging.DEBUG)  # Console handler gets all messages\n",
    "\n",
    "    # ... (setup config, logger) ...\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"=\" * 80)\n",
    "        logger.info(\"Starting Generation Engine v0.0\")\n",
    "        logger.info(f\"Device: {config.DEVICE}\")\n",
    "        \n",
    "        # Print hardware info\n",
    "        logger.info(\"Hardware Information:\")\n",
    "        if torch.cuda.is_available():\n",
    "            logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            logger.info(f\"CUDA Version: {torch.version.cuda}\")\n",
    "            gpu_mem = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "            logger.info(f\"GPU Memory: {gpu_mem:.3f} GB\")\n",
    "        else:\n",
    "            logger.info(\"No GPU detected, using CPU\")\n",
    "        \n",
    "        # Log CPU info\n",
    "        cpu_count = os.cpu_count() or 0\n",
    "        logger.info(f\"CPU Cores: {cpu_count}\")\n",
    "        \n",
    "        # Log RAM info\n",
    "        ram = psutil.virtual_memory()\n",
    "        logger.info(f\"Total RAM: {ram.total / (1024**3):.3f} GB\")\n",
    "        logger.info(f\"Available RAM: {ram.available / (1024**3):.3f} GB\")\n",
    "        \n",
    "        # Run main function\n",
    "        results = generate_synthetic_dataset(config, logger)\n",
    "\n",
    "        # --> ADD THESE LINES <--\n",
    "        # Extract features into global scope if they exist in results\n",
    "        real_features_full = results.get('real_features_full')\n",
    "        filtered_gen_features_full = results.get('filtered_gen_features_full')\n",
    "        unfiltered_gen_features_full = results.get('unfiltered_gen_features_full')\n",
    "        analysis_results = results.get('analysis_results', {}) # Also get analysis results if needed elsewhere\n",
    "        # ... (rest of the original main block logging) ...\n",
    "\n",
    "        # --- PART 1: Add this to the __main__ block after generate_synthetic_dataset ---\n",
    "        # Add this right after results = generate_synthetic_dataset(config, logger)\n",
    "        # But before any logging about completion\n",
    "        \n",
    "        # --- Save important variables for KID comparison ---\n",
    "        feature_save_dir = os.path.join(config.OUTPUT_DIR, config.STATS_SUBDIR, \"temp_features_for_kid_comp\")\n",
    "        os.makedirs(feature_save_dir, exist_ok=True)\n",
    "        logger.info(f\"Saving features for KID comparison to: {feature_save_dir}\")\n",
    "        \n",
    "        feature_paths = {}  # Store paths for loading later\n",
    "        \n",
    "        # Extract features from results\n",
    "        real_features_full_main = results.get('real_features_full')\n",
    "        filtered_gen_features_full_main = results.get('filtered_gen_features_full')\n",
    "        unfiltered_gen_features_full_main = results.get('unfiltered_gen_features_full')\n",
    "        \n",
    "        # Save Real Features\n",
    "        if real_features_full_main is not None:\n",
    "            try:\n",
    "                save_path = os.path.join(feature_save_dir, \"real_features.npy\")\n",
    "                np.save(save_path, real_features_full_main)\n",
    "                feature_paths['real'] = save_path\n",
    "                logger.info(f\"Saved real features to {save_path}\")\n",
    "                del real_features_full_main  # Delete immediately after saving\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to save or delete real features: {e}\", exc_info=True)\n",
    "        else:\n",
    "            logger.warning(\"Real features are None, cannot save for KID comparison\")\n",
    "        \n",
    "        # Save Filtered Features\n",
    "        if filtered_gen_features_full_main is not None:\n",
    "            try:\n",
    "                save_path = os.path.join(feature_save_dir, \"filtered_gen_features.npy\")\n",
    "                np.save(save_path, filtered_gen_features_full_main)\n",
    "                feature_paths['filtered'] = save_path\n",
    "                logger.info(f\"Saved filtered gen features to {save_path}\")\n",
    "                del filtered_gen_features_full_main  # Delete immediately after saving\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to save or delete filtered gen features: {e}\", exc_info=True)\n",
    "        else:\n",
    "            logger.warning(\"Filtered gen features are None, cannot save for KID comparison\")\n",
    "        \n",
    "        # Save Unfiltered Features\n",
    "        if unfiltered_gen_features_full_main is not None:\n",
    "            try:\n",
    "                save_path = os.path.join(feature_save_dir, \"unfiltered_gen_features.npy\")\n",
    "                np.save(save_path, unfiltered_gen_features_full_main)\n",
    "                feature_paths['unfiltered'] = save_path\n",
    "                logger.info(f\"Saved unfiltered gen features to {save_path}\")\n",
    "                del unfiltered_gen_features_full_main  # Delete immediately after saving\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to save or delete unfiltered gen features: {e}\", exc_info=True)\n",
    "        else:\n",
    "            logger.warning(\"Unfiltered gen features are None, cannot save for KID comparison\")\n",
    "        \n",
    "        # Save the paths for later use\n",
    "        paths_file = os.path.join(feature_save_dir, \"feature_paths.json\")\n",
    "        with open(paths_file, 'w') as f:\n",
    "            json.dump(feature_paths, f, indent=2)\n",
    "        logger.info(f\"Saved feature paths to {paths_file}\")\n",
    "        \n",
    "        # Force cleanup after saving\n",
    "        logger.info(\"Forcing memory cleanup after saving features\")\n",
    "        force_memory_cleanup(config)\n",
    "        \n",
    "        logger.info(\"=\" * 80)\n",
    "        logger.info(\"Generation Engine completed successfully\")\n",
    "        logger.info(f\"Generated {results['pollen_generated']} individual pollen images\")\n",
    "        logger.info(f\"Generated {results['composed_generated']} composed images with annotations\")\n",
    "        logger.info(f\"Total execution time: {results['total_time']:.3f} seconds\")\n",
    "        logger.info(\"=\" * 80)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unhandled exception in Generation Engine: {e}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        logger.info(\"=\" * 80)\n",
    "        logger.info(\"Generation Engine failed\")\n",
    "        logger.info(\"=\" * 80)\n",
    "        sys.exit(1)\n",
    "\n",
    "# --- Usage Example ---\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1476bcfc-1a2f-40b2-b502-1be95dc3a86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d860cb43-250b-4633-a037-3e503010aa7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# Define all required variables if running in a separate cell\n",
    "if 'graph_dir' not in locals() or graph_dir is None:\n",
    "    if 'output_dirs' in locals() and output_dirs is not None:\n",
    "        graph_dir = output_dirs['graphs']\n",
    "    else:\n",
    "        # Fallback - recreate graph_dir directly\n",
    "        graph_dir = os.path.join(config.OUTPUT_DIR, config.GRAPH_SUBDIR)\n",
    "        os.makedirs(graph_dir, exist_ok=True)\n",
    "        print(f\"Created graph_dir: {graph_dir}\")\n",
    "# Now your KID Calculation Method Implementation Comparison code can access the graph_dir variable\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# --- START: KID Method Comparison Block ---\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"=\" * 40 + \" STARTING KID METHOD COMPARISON \" + \"=\" * 40)\n",
    "\n",
    "# --- PART 2: Add this to the beginning of the KID Comparison Block ---\n",
    "# Add this right after the KID comparison block starts\n",
    "# After: logger.info(\"=\" * 40 + \" STARTING KID METHOD COMPARISON \" + \"=\" * 40)\n",
    "\n",
    "# --- Load features from disk for KID comparison ---\n",
    "logger.info(\"Loading features for KID comparison from disk...\")\n",
    "\n",
    "# Initialize variables\n",
    "real_features_full_comp = None\n",
    "filtered_gen_features_full_comp = None\n",
    "unfiltered_gen_features_full_comp = None\n",
    "\n",
    "# Get the save directory\n",
    "feature_save_dir = os.path.join(config.OUTPUT_DIR, config.STATS_SUBDIR, \"temp_features_for_kid_comp\")\n",
    "\n",
    "# Load paths from JSON if available\n",
    "try:\n",
    "    paths_file = os.path.join(feature_save_dir, \"feature_paths.json\")\n",
    "    if os.path.exists(paths_file):\n",
    "        with open(paths_file, 'r') as f:\n",
    "            feature_paths = json.load(f)\n",
    "    else:\n",
    "        logger.warning(f\"Paths file not found: {paths_file}\")\n",
    "        feature_paths = {}\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading feature paths: {e}\", exc_info=True)\n",
    "    feature_paths = {}\n",
    "\n",
    "# Load Real Features\n",
    "real_path = feature_paths.get('real')\n",
    "if real_path and os.path.exists(real_path):\n",
    "    try:\n",
    "        real_features_full_comp = np.load(real_path)\n",
    "        logger.info(f\"Loaded real features (shape: {real_features_full_comp.shape}) from {real_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load real features from {real_path}: {e}\", exc_info=True)\n",
    "else:\n",
    "    logger.warning(\"Saved real features path not found or not saved\")\n",
    "\n",
    "# Load Filtered Features\n",
    "filtered_path = feature_paths.get('filtered')\n",
    "if filtered_path and os.path.exists(filtered_path):\n",
    "    try:\n",
    "        filtered_gen_features_full_comp = np.load(filtered_path)\n",
    "        logger.info(f\"Loaded filtered gen features (shape: {filtered_gen_features_full_comp.shape}) from {filtered_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load filtered gen features from {filtered_path}: {e}\", exc_info=True)\n",
    "else:\n",
    "    logger.warning(\"Saved filtered gen features path not found or not saved\")\n",
    "\n",
    "# Load Unfiltered Features\n",
    "unfiltered_path = feature_paths.get('unfiltered')\n",
    "if unfiltered_path and os.path.exists(unfiltered_path):\n",
    "    try:\n",
    "        unfiltered_gen_features_full_comp = np.load(unfiltered_path)\n",
    "        logger.info(f\"Loaded unfiltered gen features (shape: {unfiltered_gen_features_full_comp.shape}) from {unfiltered_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load unfiltered gen features from {unfiltered_path}: {e}\", exc_info=True)\n",
    "else:\n",
    "    logger.warning(\"Saved unfiltered gen features path not found or not saved\")\n",
    "\n",
    "# --- Modify the rest of the KID comparison block to use the loaded variables ---\n",
    "# Throughout the remainder of the KID comparison block, use:\n",
    "# - real_features_full_comp instead of real_features_full\n",
    "# - filtered_gen_features_full_comp instead of filtered_gen_features_full\n",
    "# - unfiltered_gen_features_full_comp instead of unfiltered_gen_features_full\n",
    "\n",
    "# Validate loaded features\n",
    "kid_comparison_possible = True\n",
    "if real_features_full_comp is None:\n",
    "    logger.error(\"KID Comparison Error: Real features failed to load\")\n",
    "    kid_comparison_possible = False\n",
    "\n",
    "if filtered_gen_features_full_comp is None and unfiltered_gen_features_full_comp is None:\n",
    "    logger.warning(\"KID Comparison Warning: No generated features loaded. Skipping comparison\")\n",
    "    kid_comparison_possible = False\n",
    "\n",
    "# The rest of the KID comparison block continues, but using the _comp variables\n",
    "# if kid_comparison_possible:\n",
    "#    ... use real_features_full_comp, filtered_gen_features_full_comp, etc.\n",
    "\n",
    "# --- Configuration & Variable Check ---\n",
    "# This block assumes the following variables exist from the main script execution:\n",
    "# - real_features_full: Numpy array of real image features\n",
    "# - filtered_gen_features_full: Numpy array of filtered generated image features (if analysis ran)\n",
    "# - unfiltered_gen_features_full: Numpy array of unfiltered generated image features (if analysis ran)\n",
    "# - config: The Config object instance\n",
    "# - logger: The logger instance\n",
    "# - graph_dir: Path to the main graphs directory (e.g., output_dirs['graphs'])\n",
    "\n",
    "kid_comparison_possible = True\n",
    "required_vars = ['real_features_full', 'config', 'logger', 'graph_dir']\n",
    "available_vars = locals() # Check variables available in the current scope\n",
    "\n",
    "for var_name in required_vars:\n",
    "    if var_name not in available_vars or available_vars[var_name] is None:\n",
    "        logger.error(f\"KID Calculation Method Implementation Comparison Error: Required variable '{var_name}' not found or is None.\")\n",
    "        kid_comparison_possible = False\n",
    "\n",
    "# Check if at least one set of generated features exists\n",
    "filtered_gen_features_full = available_vars.get('filtered_gen_features_full')\n",
    "unfiltered_gen_features_full = available_vars.get('unfiltered_gen_features_full')\n",
    "\n",
    "if filtered_gen_features_full is None and unfiltered_gen_features_full is None:\n",
    "    logger.warning(\"KID Calculation Method Implementation Comparison Warning: No generated features (filtered or unfiltered) available. Skipping comparison.\")\n",
    "    kid_comparison_possible = False\n",
    "\n",
    "if kid_comparison_possible:\n",
    "    try:\n",
    "        # --- Define Helper Functions ---\n",
    "\n",
    "        # 1. Method from training Continuation Script (custom version)\n",
    "        def polynomial_kernel_custom(X, Y, degree=3, gamma=None, coef0=1.0):\n",
    "            \"\"\"Polynomial kernel for KID (from training script)\"\"\"\n",
    "            # 1. Type conversion\n",
    "            X = X.astype(np.float64)\n",
    "            Y = Y.astype(np.float64)\n",
    "            \n",
    "            # 4.1a. Feature normalization (not in Generation Method)\n",
    "            X_norm = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-8)\n",
    "            Y_norm = Y / (np.linalg.norm(Y, axis=1, keepdims=True) + 1e-8)\n",
    "            \n",
    "            # 4.1b. Hard-coded parameters \n",
    "            gamma = 0.2  # Fixed value (Generation uses 1/n_features)\n",
    "            coef0 = 1.0\n",
    "            degree = 3\n",
    "            \n",
    "            # 4.1c. Compute kernel\n",
    "            dot_product = np.matmul(X_norm, Y_norm.T)\n",
    "            return np.clip((gamma * dot_product + coef0) ** degree, 1e-8, 1e6)\n",
    "        \n",
    "        def calculate_kid_from_features_custom(real_features, fake_features, config, logger):\n",
    "            \"\"\"Calculate KID using custom polynomial kernel (from training script)\"\"\"\n",
    "            try:\n",
    "                # 1. Type conversion\n",
    "                real_features = real_features.astype(np.float64)\n",
    "                fake_features = fake_features.astype(np.float64)\n",
    "                \n",
    "                # 2. Feature centering (not in Generation Method)\n",
    "                real_features = real_features - np.mean(real_features, axis=0, keepdims=True)\n",
    "                fake_features = fake_features - np.mean(fake_features, axis=0, keepdims=True)\n",
    "                \n",
    "                # 3a. Setup for multiple subsets\n",
    "\n",
    "                subset_size = getattr(config, 'KID_SUBSET_SIZE', 1000) # Use config if available\n",
    "                num_subsets = getattr(config, 'KID_SUBSETS', 100)\n",
    "\n",
    "                n_r, n_f = real_features.shape[0], fake_features.shape[0]\n",
    "\n",
    "                if n_r == 0 or n_f == 0: # failsafe\n",
    "                    logger.warning(\"KID Custom: Cannot calculate with empty feature sets.\") # failsafe\n",
    "                    return np.nan, np.nan # failsafe\n",
    "\n",
    "                subset_size = min(subset_size, min(n_r, n_f)) # failsafe\n",
    "\n",
    "                if subset_size < 2: # failsafe\n",
    "                     logger.warning(f\"KID Custom: Subset size {subset_size} too small. Need at least 2.\") # failsafe\n",
    "                     return np.nan, np.nan # failsafe\n",
    "                \n",
    "                kid_values = []\n",
    "                # 3b. Sample multiple subsets\n",
    "                for _ in tqdm(range(num_subsets), desc=\"KID Custom Subsets\"):\n",
    "                    # 3c. Random sampling without replacement\n",
    "                    r_idx = np.random.choice(n_r, size=subset_size, replace=False)\n",
    "                    f_idx = np.random.choice(n_f, size=subset_size, replace=False)\n",
    "                    r_subset = real_features[r_idx]\n",
    "                    f_subset = fake_features[f_idx]\n",
    "        \n",
    "                    # 4. Calculate kernel matrices\n",
    "                    k_rr = polynomial_kernel_custom(r_subset, r_subset)\n",
    "                    k_rf = polynomial_kernel_custom(r_subset, f_subset)\n",
    "                    k_ff = polynomial_kernel_custom(f_subset, f_subset)\n",
    "        \n",
    "                    # 5a. Calculate MMD with diagonal correction\n",
    "                    n = subset_size\n",
    "                    mmd_numerator = np.sum(k_rr) - np.trace(k_rr) + np.sum(k_ff) - np.trace(k_ff) - 2 * np.sum(k_rf)\n",
    "                    \n",
    "                    # 5b. Normalize by n*(n-1)\n",
    "                    mmd_denominator = n * (n - 1)\n",
    "\n",
    "                    if mmd_denominator <= 0: # failsafe\n",
    "                        logger.warning(\"KID Custom: Invalid denominator in MMD calculation!\") # failsafe\n",
    "                        mmd = np.nan # failsafe\n",
    "                    else: # failsafe\n",
    "                        mmd = mmd_numerator / mmd_denominator\n",
    "        \n",
    "                    # 6a. Collect valid MMD values\n",
    "                    if np.isfinite(mmd):\n",
    "                        kid_values.append(max(1e-8, mmd)) # Ensure non-negative and non-zero\n",
    "\n",
    "                if not kid_values: # Check if list is empty after loop # failsafe\n",
    "                    logger.warning(\"KID Custom: No valid MMD values calculated.\") # failsafe\n",
    "                    return np.nan, np.nan # failsafe\n",
    "\n",
    "                # 6b. Calculate statistics across subsets\n",
    "                scaling_factor = 10000  # 100² to account for square root difference\n",
    "                return np.mean(kid_values) * scaling_factor, np.std(kid_values) * scaling_factor\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in calculate_kid_from_features_custom: {e}\", exc_info=True)\n",
    "                return np.nan, np.nan\n",
    "\n",
    "        # 2. Method from Generation Engine Script (using sklearn)\n",
    "        def calculate_kid_generation_method(real_features, fake_features, logger, chunk_size=1000): # Added chunk_size\n",
    "            \"\"\"Calculate KID using sklearn polynomial kernel, processed in chunks.\"\"\"\n",
    "            try:\n",
    "                if not SKLEARN_KERNELS_AVAILABLE: # Use the global flag check\n",
    "                    logger.warning(\"scikit-learn polynomial_kernel not available for Generation Method KID.\")\n",
    "                    return np.nan\n",
    "        \n",
    "                min_samples = min(len(real_features), len(fake_features))\n",
    "                if min_samples < 10: # Increased minimum for stability\n",
    "                    logger.warning(f\"KID Gen Method: Too few samples ({min_samples}) for reliable calculation. Need >= 10.\")\n",
    "                    return np.nan\n",
    "        \n",
    "                # Use features up to min_samples\n",
    "                real_f = real_features[:min_samples]\n",
    "                fake_f = fake_features[:min_samples]\n",
    "                logger.info(f\"Calculating KID (Generation Method) on {min_samples} samples.\")\n",
    "        \n",
    "                # Kernel parameters\n",
    "                degree = 3\n",
    "                gamma = None # Defaults to 1/n_features in sklearn\n",
    "                coef0 = 1\n",
    "        \n",
    "                # Initialize accumulators for sums\n",
    "                sum_k_rr = 0.0\n",
    "                sum_k_ff = 0.0\n",
    "                sum_k_rf = 0.0\n",
    "        \n",
    "                num_chunks = math.ceil(min_samples / chunk_size)\n",
    "                logger.info(f\"Calculating KID kernel sums in {num_chunks} chunks of size approx {chunk_size}...\")\n",
    "        \n",
    "                # --- Calculate K_rr sum ---\n",
    "                current_processed = 0\n",
    "                # Use tqdm for progress bar\n",
    "                with tqdm(total=min_samples, desc=\"KID Chunks (Real-Real)\") as pbar_rr:\n",
    "                    for i in range(0, min_samples, chunk_size):\n",
    "                        real_chunk = real_f[i:min(i + chunk_size, min_samples)]\n",
    "                        if len(real_chunk) == 0: continue\n",
    "                        # K_real_real for this chunk vs ALL real\n",
    "                        k_rr_chunk = polynomial_kernel(real_chunk, real_f, degree=degree, gamma=gamma, coef0=coef0)\n",
    "                        sum_k_rr += np.sum(k_rr_chunk)\n",
    "                        current_processed += len(real_chunk)\n",
    "                        pbar_rr.update(len(real_chunk))\n",
    "                        # Optional cleanup\n",
    "                        del k_rr_chunk, real_chunk\n",
    "                        if i % 10 == 0: # Less frequent cleanup\n",
    "                             gc.collect()\n",
    "        \n",
    "                # --- Calculate K_ff sum ---\n",
    "                current_processed = 0\n",
    "                with tqdm(total=min_samples, desc=\"KID Chunks (Fake-Fake)\") as pbar_ff:\n",
    "                     for i in range(0, min_samples, chunk_size):\n",
    "                        fake_chunk = fake_f[i:min(i + chunk_size, min_samples)]\n",
    "                        if len(fake_chunk) == 0: continue\n",
    "                        # K_fake_fake for this chunk vs ALL fake\n",
    "                        k_ff_chunk = polynomial_kernel(fake_chunk, fake_f, degree=degree, gamma=gamma, coef0=coef0)\n",
    "                        sum_k_ff += np.sum(k_ff_chunk)\n",
    "                        current_processed += len(fake_chunk)\n",
    "                        pbar_ff.update(len(fake_chunk))\n",
    "                        # Optional cleanup\n",
    "                        del k_ff_chunk, fake_chunk\n",
    "                        if i % 10 == 0: # Less frequent cleanup\n",
    "                             gc.collect()\n",
    "        \n",
    "                # --- Calculate K_rf sum ---\n",
    "                current_processed = 0\n",
    "                with tqdm(total=min_samples, desc=\"KID Chunks (Real-Fake)\") as pbar_rf:\n",
    "                    for i in range(0, min_samples, chunk_size):\n",
    "                        real_chunk = real_f[i:min(i + chunk_size, min_samples)]\n",
    "                        if len(real_chunk) == 0: continue\n",
    "                         # K_real_fake for this chunk of real vs ALL fake\n",
    "                        k_rf_chunk = polynomial_kernel(real_chunk, fake_f, degree=degree, gamma=gamma, coef0=coef0)\n",
    "                        sum_k_rf += np.sum(k_rf_chunk)\n",
    "                        current_processed += len(real_chunk)\n",
    "                        pbar_rf.update(len(real_chunk))\n",
    "                        # Optional cleanup\n",
    "                        del k_rf_chunk, real_chunk\n",
    "                        if i % 10 == 0: # Less frequent cleanup\n",
    "                             gc.collect()\n",
    "        \n",
    "                # Calculate final means (divide sum by total number of elements: min_samples * min_samples)\n",
    "                n_elements = float(min_samples * min_samples) # Use float for division\n",
    "                if n_elements == 0: return np.nan\n",
    "        \n",
    "                mean_k_rr = sum_k_rr / n_elements\n",
    "                mean_k_ff = sum_k_ff / n_elements\n",
    "                mean_k_rf = sum_k_rf / n_elements\n",
    "                logger.debug(f\"KID Means: K_rr={mean_k_rr:.4f}, K_ff={mean_k_ff:.4f}, K_rf={mean_k_rf:.4f}\")\n",
    "        \n",
    "                # Calculate MMD^2 using means\n",
    "                mmd2 = mean_k_rr + mean_k_ff - 2 * mean_k_rf\n",
    "        \n",
    "                # Transform value with square root and scaling\n",
    "                kid_value = np.sqrt(max(0, mmd2)) * 100\n",
    "                logger.info(\"KID (Generation Method) chunked calculation complete.\")\n",
    "                return float(kid_value) if np.isfinite(kid_value) else np.nan\n",
    "        \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in calculate_kid_generation_method (chunked): {e}\", exc_info=True)\n",
    "                return np.nan\n",
    "            #\n",
    "            \n",
    "        # 3. Plotting Function\n",
    "        def plot_kid_method_comparison(results_dict, output_path, logger):\n",
    "            \"\"\" Generates a bar chart comparing KID scores from two methods \"\"\"\n",
    "            logger.info(f\"Generating the KID method comparison plot: {output_path}\")\n",
    "\n",
    "            labels = list(results_dict.keys()) # Should be ['Filtered', 'Unfiltered'] or just one\n",
    "            if not labels:\n",
    "                logger.warning(\"No results of the KID available to plot for comparison.\")\n",
    "                return False\n",
    "\n",
    "            continuation_scores = [results_dict[label].get('Continuation Method', np.nan) for label in labels]\n",
    "            generation_scores = [results_dict[label].get('Generation Method', np.nan) for label in labels]\n",
    "\n",
    "            x = np.arange(len(labels)) # Label locations\n",
    "            width = 0.35 # Width of the bars\n",
    "\n",
    "            # Check if any valid scores exist\n",
    "            has_cont_scores = any(np.isfinite(s) for s in continuation_scores)\n",
    "            has_gen_scores = any(np.isfinite(s) for s in generation_scores)\n",
    "\n",
    "            if not has_cont_scores and not has_gen_scores:\n",
    "                 logger.warning(\"No valid KID scores found for comparison plot.\")\n",
    "                 return False\n",
    "\n",
    "            plt.style.use('seaborn-v0_8-darkgrid')\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "            # Plot bars, handling potential NaN values gracefully\n",
    "            rects1 = ax.bar(x - width/2, [s if np.isfinite(s) else 0 for s in continuation_scores], width, label='Continuation Method', color='purple')\n",
    "            rects2 = ax.bar(x + width/2, [s if np.isfinite(s) else 0 for s in generation_scores], width, label='Generation Method', color='pink')\n",
    "\n",
    "            # Add labels, title, ticks\n",
    "            ax.set_ylabel('KID Score (Lower is Better)')\n",
    "            ax.set_title('KID Score Comparison by Calculation Method')\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels(labels)\n",
    "            ax.legend()\n",
    "\n",
    "            # Add text labels above bars, showing NaN if score was invalid\n",
    "            def autolabel(rects, scores):\n",
    "                for i, rect in enumerate(rects):\n",
    "                    height = rect.get_height()\n",
    "                    score_val = scores[i]\n",
    "                    label_text = f'{score_val:.3f}' if np.isfinite(score_val) else 'N/A'\n",
    "                    ax.annotate(label_text,\n",
    "                                xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                                xytext=(0, 3), # 3 points vertical offset\n",
    "                                textcoords=\"offset points\",\n",
    "                                ha='center', va='bottom')\n",
    "\n",
    "            autolabel(rects1, continuation_scores)\n",
    "            autolabel(rects2, generation_scores)\n",
    "\n",
    "            fig.tight_layout()\n",
    "            try:\n",
    "                plt.savefig(output_path, dpi=300)\n",
    "                plt.close(fig)\n",
    "                logger.info(f\"Saved the KID Calculation Method Implementation Comparison plot to {output_path}\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error saving the KID Calculation Method Implementation Comparison plot: {e}\", exc_info=True)\n",
    "                plt.close(fig) # Attempt to close plot even if saving failed\n",
    "                return False\n",
    "\n",
    "\n",
    "        # --- Main Calculation Logic ---\n",
    "        kid_comparison_results = {}\n",
    "        analysis_sample_size = config.ANALYSIS_SAMPLE_SIZE\n",
    "\n",
    "        # Ensure comparison subdirectory exists\n",
    "        kid_comparison_dir = os.path.join(graph_dir, \"kid_methods_comparison\")\n",
    "        os.makedirs(kid_comparison_dir, exist_ok=True)\n",
    "        logger.info(f\"Saving the KID Calculation Method Implementation Comparison results to: {kid_comparison_dir}\")\n",
    "\n",
    "        # 1. Calculate for Filtered data (if available)\n",
    "        if filtered_gen_features_full is not None:\n",
    "            logger.info(\"--- Comparing the KID methods for Filtered Data ---\")\n",
    "            min_samples_f = min(len(real_features_full), len(filtered_gen_features_full), analysis_sample_size)\n",
    "            if min_samples_f < 10: # Need at least a few samples\n",
    "                logger.warning(f\"Too few filtered samples ({min_samples_f}) for reliable KID Calculation Method Implementation Comparison.\")\n",
    "            else:\n",
    "                real_f_comp = real_features_full[:min_samples_f]\n",
    "                filt_f_comp = filtered_gen_features_full[:min_samples_f]\n",
    "\n",
    "                # Calculate using Continuation method\n",
    "                logger.debug(\"Calculating the KID (Filtered) using Continuation Method...\")\n",
    "                kid_cont_f, kid_std_cont_f = calculate_kid_from_features_custom(real_f_comp, filt_f_comp, config, logger)\n",
    "                logger.info(f\"Filtered KID (Continuation Method): {kid_cont_f:.6f} ± {kid_std_cont_f:.6f}\")\n",
    "\n",
    "                # Calculate using Generation method\n",
    "                logger.debug(\"Calculating the KID (Filtered) using Generation Method...\")\n",
    "                kid_gen_f = calculate_kid_generation_method(real_f_comp, filt_f_comp, logger)\n",
    "                logger.info(f\"Filtered KID (Generation Method): {kid_gen_f:.3f}\")\n",
    "\n",
    "                kid_comparison_results['Filtered'] = {\n",
    "                    'Continuation Method': kid_cont_f,\n",
    "                    'Generation Method': kid_gen_f\n",
    "                }\n",
    "                del real_f_comp, filt_f_comp # Cleanup\n",
    "\n",
    "        # 2. Calculate for Unfiltered data (if available)\n",
    "        if unfiltered_gen_features_full is not None:\n",
    "            logger.info(\"--- Comparing the KID methods for Unfiltered Data ---\")\n",
    "            min_samples_u = min(len(real_features_full), len(unfiltered_gen_features_full), analysis_sample_size)\n",
    "            if min_samples_u < 10:\n",
    "                 logger.warning(f\"Too few unfiltered samples ({min_samples_u}) for reliable KID comparison.\")\n",
    "            else:\n",
    "                real_u_comp = real_features_full[:min_samples_u]\n",
    "                unfilt_u_comp = unfiltered_gen_features_full[:min_samples_u]\n",
    "\n",
    "                # Calculate using Continuation method\n",
    "                logger.debug(\"Calculating the KID (Unfiltered) using Continuation Method...\")\n",
    "                kid_cont_u, kid_std_cont_u = calculate_kid_from_features_custom(real_u_comp, unfilt_u_comp, config, logger)\n",
    "                logger.info(f\"Unfiltered KID (Continuation Method): {kid_cont_u:.6f} ± {kid_std_cont_u:.6f}\")\n",
    "\n",
    "                # Calculate using Generation method\n",
    "                logger.debug(\"Calculating the KID (Unfiltered) using Generation Method...\")\n",
    "                kid_gen_u = calculate_kid_generation_method(real_u_comp, unfilt_u_comp, logger)\n",
    "                logger.info(f\"Unfiltered KID (Generation Method): {kid_gen_u:.3f}\")\n",
    "\n",
    "                kid_comparison_results['Unfiltered'] = {\n",
    "                    'Continuation Method': kid_cont_u,\n",
    "                    'Generation Method': kid_gen_u\n",
    "                }\n",
    "                del real_u_comp, unfilt_u_comp # Cleanup\n",
    "\n",
    "        # 3. Generate Comparison Plot\n",
    "        if kid_comparison_results:\n",
    "            plot_path = os.path.join(kid_comparison_dir, f\"kid_methods_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\")\n",
    "            plot_kid_method_comparison(kid_comparison_results, plot_path, logger)\n",
    "        else:\n",
    "             logger.warning(\"No results for the KID Calculation Method Implementation Comparison were generated.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during the KID Calculation Method Implementation Comparison: {e}\", exc_info=True)\n",
    "\n",
    "# Clear memory after comparison block\n",
    "force_memory_cleanup(config) # Assuming force_memory_cleanup is defined globally\n",
    "\n",
    "# --- PART 3: Add this to the end of the KID Comparison Block ---\n",
    "# Add this right before the KID comparison block ends\n",
    "\n",
    "# Clean up loaded features\n",
    "logger.info(\"Cleaning up after KID comparison...\")\n",
    "if 'real_features_full_comp' in locals() and real_features_full_comp is not None:\n",
    "    del real_features_full_comp\n",
    "    \n",
    "if 'filtered_gen_features_full_comp' in locals() and filtered_gen_features_full_comp is not None:\n",
    "    del filtered_gen_features_full_comp\n",
    "    \n",
    "if 'unfiltered_gen_features_full_comp' in locals() and unfiltered_gen_features_full_comp is not None:\n",
    "    del unfiltered_gen_features_full_comp\n",
    "    \n",
    "# Also clean up any subset variables created during comparison\n",
    "# This will vary based on exact variable names in your comparison code\n",
    "for var_name in list(locals().keys()):\n",
    "    if var_name.endswith('_comp') or '_comp_' in var_name:\n",
    "        if var_name in locals():\n",
    "            del locals()[var_name]\n",
    "\n",
    "# Final cleanup\n",
    "force_memory_cleanup(config)\n",
    "logger.info(\"KID comparison cleanup complete\")\n",
    "\n",
    "logger.info(\"=\" * 40 + \" FINISHED THE KID CALCULATION IMPLEMENTATION METHOD COMPARISON \" + \"=\" * 40)\n",
    "\n",
    "# ============================================================================\n",
    "# --- END: KID Method Comparison Block ---\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0de25a-6069-4eef-955f-1ac537147d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
