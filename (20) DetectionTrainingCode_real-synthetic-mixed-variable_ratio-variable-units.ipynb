{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes: The second alternative new code for the object detection model training step (the old code was discarded due to mismatch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "try:\n",
    "    import pip\n",
    "    packages = ['ultralytics', 'torch', 'torchvision', 'torchaudio']\n",
    "    for package in packages:\n",
    "        !pip install {package}\n",
    "    print(\"\\n! ~ All required packages installed successfully ~ !\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Error installing packages: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages with error handling\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    from matplotlib import pyplot as plt\n",
    "    from PIL import Image\n",
    "    from ultralytics.data.utils import check_det_dataset\n",
    "    from ultralytics.utils.plotting import plot_results\n",
    "    from pathlib import Path\n",
    "    import torch\n",
    "    import yaml\n",
    "    import os\n",
    "    import json\n",
    "    import shutil\n",
    "    from datetime import datetime\n",
    "    import stat\n",
    "    import subprocess\n",
    "    from ultralytics import settings\n",
    "    from ultralytics.utils.checks import check_yolo\n",
    "    #from ultralytics.cfg import get_cfg, set_cfg\n",
    "    from ultralytics.utils import DEFAULT_CFG, ROOT\n",
    "    from ultralytics.data.dataset import YOLODataset\n",
    "    from ultralytics.data.base import BaseDataset\n",
    "    import torch\n",
    "    import gc\n",
    "    print(\"\\n! ~ All required libraries imported successfully ~ !\\n\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing required packages: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing helper functions\n",
    "def validate_yaml_content(yaml_path):\n",
    "    \"\"\"\n",
    "    Validate the content of the YAML file for cross-validation setup\n",
    "    Returns tuple of (is_valid, error_message)\n",
    "    \"\"\"\n",
    "    required_keys = ['train', 'val', 'test', 'nc', 'names']\n",
    "    \n",
    "    try:\n",
    "        with open(yaml_path, 'r') as stream:\n",
    "            data = yaml.safe_load(stream)\n",
    "            \n",
    "            # Check for required keys\n",
    "            missing_keys = [key for key in required_keys if key not in data]\n",
    "            if missing_keys:\n",
    "                return False, f\"Missing required keys in YAML: {missing_keys}\"\n",
    "            \n",
    "            # Get the base directory (where data.yaml is located)\n",
    "            base_dir = os.path.dirname(yaml_path)\n",
    "            \n",
    "            # Validate paths exist by joining with base directory\n",
    "            for key in ['train', 'val', 'test']:\n",
    "                if key in data and data[key]:\n",
    "                    # Remove '../' from the path as we're already in the base directory\n",
    "                    cleaned_path = data[key].replace('../', '')\n",
    "                    full_path = os.path.join(base_dir, cleaned_path)\n",
    "                    if not os.path.exists(full_path):\n",
    "                        return False, f\"Path specified in YAML for {key} does not exist: {full_path}\"\n",
    "            \n",
    "            # Validate class names\n",
    "            if len(data['names']) != data['nc']:\n",
    "                return False, f\"Number of class names ({len(data['names'])}) doesn't match nc ({data['nc']})\"\n",
    "                \n",
    "            return True, \"YAML content validation successful\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return False, f\"Error validating YAML content: {str(e)}\"\n",
    "\n",
    "def validate_image_label_pairs(base_path):\n",
    "    \"\"\"\n",
    "    Validate that each image has a corresponding label file in train/valid/test setup\n",
    "    Returns tuple of (is_valid, error_message)\n",
    "    \"\"\"\n",
    "    mismatched_pairs = []\n",
    "    missing_labels = []\n",
    "    \n",
    "    # Check all three directories: train, valid, test\n",
    "    for subset in ['train', 'valid', 'test']:\n",
    "        img_dir = os.path.join(base_path, subset, 'images')\n",
    "        label_dir = os.path.join(base_path, subset, 'labels')\n",
    "        \n",
    "        if not os.path.exists(img_dir) or not os.path.exists(label_dir):\n",
    "            return False, f\"Directory not found: {img_dir} or {label_dir}\"\n",
    "        \n",
    "        # Get all image files\n",
    "        image_files = [f for f in os.listdir(img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        for img_file in image_files:\n",
    "            # Convert image filename to expected label filename\n",
    "            label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "            label_path = os.path.join(label_dir, label_file)\n",
    "            \n",
    "            if not os.path.exists(label_path):\n",
    "                missing_labels.append(f\"{subset}/{img_file}\")\n",
    "            else:\n",
    "                # Validate label file format\n",
    "                try:\n",
    "                    with open(label_path, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                        for line in lines:\n",
    "                            # Check if label format is correct (class x_center y_center width height)\n",
    "                            parts = line.strip().split()\n",
    "                            if len(parts) != 5:\n",
    "                                mismatched_pairs.append(f\"{subset}/{img_file}\")\n",
    "                                break\n",
    "                            # Validate class id and coordinates\n",
    "                            class_id = int(parts[0])\n",
    "                            coords = [float(p) for p in parts[1:]]\n",
    "                            if class_id < 0 or any(c < 0 or c > 1 for c in coords):\n",
    "                                mismatched_pairs.append(f\"{subset}/{img_file}\")\n",
    "                                break\n",
    "                except:\n",
    "                    mismatched_pairs.append(f\"{subset}/{img_file}\")\n",
    "    \n",
    "    if missing_labels or mismatched_pairs:\n",
    "        error_msg = \"\"\n",
    "        if missing_labels:\n",
    "            error_msg += f\"\\nMissing label files for: {missing_labels}\"\n",
    "        if mismatched_pairs:\n",
    "            error_msg += f\"\\nInvalid label format in: {mismatched_pairs}\"\n",
    "        return False, error_msg\n",
    "    \n",
    "    return True, \"All image-label pairs validated successfully\"\n",
    "\n",
    "def get_device_config():\n",
    "    \"\"\"\n",
    "    Detect and configure device settings\n",
    "    Returns tuple of (device, batch_size, device_info)\n",
    "    \"\"\"\n",
    "    device_info = {}\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        device_info = {\n",
    "            \"device_name\": torch.cuda.get_device_name(0),\n",
    "            \"gpu_memory\": f\"{gpu_memory:.2f} GB\",\n",
    "            \"cuda_version\": torch.version.cuda\n",
    "        }\n",
    "        \n",
    "        # Batch size based on available GPU memory\n",
    "        if gpu_memory >= 6:\n",
    "            batch_size = 16\n",
    "        elif gpu_memory >= 4:\n",
    "            batch_size = 8\n",
    "        else:\n",
    "            batch_size = 4\n",
    "            \n",
    "        return \"cuda\", batch_size, device_info\n",
    "    else:\n",
    "        device_info = {\n",
    "            \"device_name\": \"CPU\",\n",
    "            \"memory\": \"N/A\",\n",
    "            \"reason\": \"No GPU detected\"\n",
    "        }\n",
    "        return \"cpu\", 4, device_info\n",
    "\n",
    "def debug_paths(yaml_path):\n",
    "    with open(yaml_path) as f:\n",
    "        data = yaml.safe_load(f)\n",
    "        base_dir = os.path.dirname(yaml_path)\n",
    "        print(\"\\n[DEBUG] Path resolution:\")\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            original = data.get(split, '')\n",
    "            abs_path = os.path.abspath(os.path.join(base_dir, original))\n",
    "            exists = os.path.exists(abs_path)\n",
    "            print(f\"{split.upper():<6} | Original: {original:<20} | Absolute: {abs_path} | Exists: {exists}\")\n",
    "\n",
    "\n",
    "def create_directory(path):\n",
    "    \"\"\"\n",
    "    Creates a directory with full permissions (777) and clears read-only attributes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        original_umask = os.umask(0)  # Temporarily set umask to 0\n",
    "        Path(path).mkdir(parents=True, exist_ok=True, mode=0o777)\n",
    "    finally:\n",
    "        os.umask(original_umask)  # Restore original umask\n",
    "\n",
    "    try:\n",
    "        # Windows: Remove read-only attribute\n",
    "        if os.name == 'nt':\n",
    "            subprocess.run(f'attrib -r \"{os.path.abspath(path)}\" /s /d', shell=True, check=True)\n",
    "        # Set permissions for all platforms\n",
    "        os.chmod(path, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating directory {path}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def safe_delete(path):\n",
    "    \"\"\"\n",
    "    Force-deletes directories with proper permission handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove read-only attributes first\n",
    "        subprocess.run(f'attrib -r \"{os.path.abspath(path)}\" /s /d', shell=True, check=True)\n",
    "        \n",
    "        # Delete with retries\n",
    "        shutil.rmtree(path, onerror=lambda func, path, _: func(path))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting {path}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def check_directory_contents(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Directory {directory} does not exist!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Contents of {directory}:\")\n",
    "    #for item in os.listdir(directory):\n",
    "    #    print(f\"  - {item}\")\n",
    "    \n",
    "    lst = os.listdir(directory) # your directory path\n",
    "    number_files = len(lst)\n",
    "    print(f\"  - {number_files} items\")\n",
    "\n",
    "def set_permissions_recursive(path, mode):\n",
    "    \"\"\"\n",
    "    Recursively sets permissions on all directories and files in the given path.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dir_name in dirs:\n",
    "            dir_path = os.path.join(root, dir_name)\n",
    "            try:\n",
    "                os.chmod(dir_path, mode)\n",
    "                if os.name == 'nt':\n",
    "                    subprocess.run(f'attrib -r \"{dir_path}\"', shell=True, check=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error setting permissions for {dir_path}: {str(e)}\")\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            try:\n",
    "                os.chmod(file_path, mode)\n",
    "                if os.name == 'nt':\n",
    "                    subprocess.run(f'attrib -r \"{file_path}\"', shell=True, check=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error setting permissions for {file_path}: {str(e)}\")\n",
    "\n",
    "def remove_corrupted_files(folder):\n",
    "    from PIL import Image\n",
    "    corrupt_files = []\n",
    "    for file in Path(folder).rglob('*.*'):\n",
    "        try:\n",
    "            if file.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                with Image.open(file) as img:\n",
    "                    img.verify()\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            corrupt_files.append(str(file))\n",
    "            os.remove(file)\n",
    "            label_file = Path(str(file).replace('images', 'labels')).with_suffix('.txt')\n",
    "            if label_file.exists():\n",
    "                os.remove(label_file)\n",
    "    return corrupt_files\n",
    "\n",
    "def verify_labels(label_dir, verbose=False, max_errors=100):\n",
    "    \"\"\"\n",
    "    Verify that label files follow the YOLO format requirements.\n",
    "    Optimized to handle both NumPy and Python native float values while minimizing output.\n",
    "    \n",
    "    Args:\n",
    "        label_dir (str): Directory containing label files\n",
    "        verbose (bool): Whether to print progress information\n",
    "        max_errors (int): Maximum number of errors to collect before stopping\n",
    "        \n",
    "    Returns:\n",
    "        list: List of files with formatting issues and their errors\n",
    "    \"\"\"\n",
    "    from pathlib import Path\n",
    "    from tqdm.notebook import tqdm\n",
    "    import os\n",
    "    \n",
    "    bad_labels = []\n",
    "    label_files = list(Path(label_dir).glob('*.txt'))\n",
    "    total_files = len(label_files)\n",
    "    \n",
    "    # Use tqdm for a progress bar instead of printing status for each file\n",
    "    progress_bar = tqdm(label_files, desc=f\"Validating {os.path.basename(label_dir)}\", \n",
    "                         disable=not verbose)\n",
    "    \n",
    "    for label_file in progress_bar:\n",
    "        try:\n",
    "            with open(label_file) as f:\n",
    "                lines = f.readlines()\n",
    "                for line_num, line in enumerate(lines, 1):\n",
    "                    parts = line.strip().split()\n",
    "                    \n",
    "                    # Check if we have exactly 5 values per line (class, x, y, w, h)\n",
    "                    if len(parts) != 5:\n",
    "                        raise ValueError(f\"Line {line_num}: Expected 5 values, got {len(parts)}\")\n",
    "                    \n",
    "                    # First value should be an integer class ID\n",
    "                    try:\n",
    "                        cls = int(parts[0])\n",
    "                    except ValueError:\n",
    "                        raise ValueError(f\"Line {line_num}: Class ID must be an integer, got '{parts[0]}'\")\n",
    "                    \n",
    "                    # The remaining values should be floats between 0 and 1\n",
    "                    for i, (name, value) in enumerate(zip(['x', 'y', 'w', 'h'], parts[1:5])):\n",
    "                        try:\n",
    "                            # Convert to Python native float (handles both Python floats and NumPy floats)\n",
    "                            val = float(value)\n",
    "                            # Check bounds\n",
    "                            if not (0 <= val <= 1):\n",
    "                                raise ValueError(f\"Line {line_num}: {name.upper()} value '{val}' is out of bounds (0-1)\")\n",
    "                        except (ValueError, TypeError) as e:\n",
    "                            raise ValueError(f\"Line {line_num}: {name.upper()} value '{value}' is not a valid float: {str(e)}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            bad_labels.append(f\"{label_file.name}: {str(e)}\")\n",
    "            # Limit the number of errors we collect to avoid memory issues\n",
    "            if len(bad_labels) >= max_errors:\n",
    "                bad_labels.append(f\"... and potentially more (stopped after {max_errors} errors)\")\n",
    "                break\n",
    "    \n",
    "    # Don't update the progress bar too often to reduce output load\n",
    "    progress_bar.close()\n",
    "    \n",
    "    # Return only the number of issues if there are too many to display\n",
    "    if len(bad_labels) > 50:\n",
    "        return [f\"Found {len(bad_labels)} label issues. First 10 examples:\", *bad_labels[:10], \"...\"]\n",
    "    \n",
    "    return bad_labels\n",
    "\n",
    "def validate_label_formats(train_labels_dir, val_labels_dir, verbose=False):\n",
    "    \"\"\"\n",
    "    Wrapper function that validates both training and validation labels\n",
    "    while producing minimal output.\n",
    "    \n",
    "    Args:\n",
    "        train_labels_dir (str): Directory containing training labels\n",
    "        val_labels_dir (str): Directory containing validation labels\n",
    "        verbose (bool): Whether to print progress information\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if validation succeeds, False otherwise\n",
    "    \"\"\"\n",
    "    print(\"\\nValidating label formats...\")\n",
    "    \n",
    "    # Check training labels\n",
    "    train_label_issues = verify_labels(train_labels_dir, verbose=verbose)\n",
    "    \n",
    "    # Check validation labels\n",
    "    val_label_issues = verify_labels(val_labels_dir, verbose=verbose)\n",
    "    \n",
    "    # Summarize results without printing too much data\n",
    "    if train_label_issues or val_label_issues:\n",
    "        print(f\"Label validation failed:\")\n",
    "        if train_label_issues:\n",
    "            print(f\"- Training labels: {len(train_label_issues)} issues\")\n",
    "        if val_label_issues:\n",
    "            print(f\"- Validation labels: {len(val_label_issues)} issues\")\n",
    "            \n",
    "        # Write detailed errors to a file instead of printing to screen\n",
    "        with open(\"label_validation_errors.log\", \"w\") as f:\n",
    "            f.write(\"TRAINING LABEL ISSUES:\\n\")\n",
    "            f.write(\"\\n\".join(train_label_issues) + \"\\n\\n\")\n",
    "            f.write(\"VALIDATION LABEL ISSUES:\\n\")\n",
    "            f.write(\"\\n\".join(val_label_issues))\n",
    "            \n",
    "        print(f\"Detailed error log written to 'label_validation_errors.log'\")\n",
    "        return False\n",
    "    \n",
    "    print(\"All label formats validated successfully!\")\n",
    "    return True\n",
    "\n",
    "def validate_label_ranges(label_dir, max_errors=100):\n",
    "    \"\"\"\n",
    "    Validates that all label values are within acceptable ranges for YOLO format.\n",
    "    Optimized to handle large datasets without overwhelming Jupyter outputs.\n",
    "    \n",
    "    Args:\n",
    "        label_dir (str): Directory containing label files\n",
    "        max_errors (int): Maximum number of errors to collect\n",
    "        \n",
    "    Returns:\n",
    "        list: List of files with value range issues\n",
    "    \"\"\"\n",
    "    from pathlib import Path\n",
    "    from tqdm.notebook import tqdm\n",
    "    import os\n",
    "    \n",
    "    invalid = []\n",
    "    label_files = list(Path(label_dir).glob('*.txt'))\n",
    "    \n",
    "    # Use tqdm for a progress bar instead of printing for each file\n",
    "    progress_bar = tqdm(label_files, desc=f\"Validating ranges ({os.path.basename(label_dir)})\")\n",
    "    \n",
    "    for lbl_file in progress_bar:\n",
    "        try:\n",
    "            with open(lbl_file) as f:\n",
    "                for line_num, line in enumerate(f, 1):\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) != 5:\n",
    "                        invalid.append(f\"{lbl_file.name}:{line_num}: Bad field count\")\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        # Convert each value explicitly to handle NumPy float64 values\n",
    "                        cls = float(parts[0]) \n",
    "                        x = float(parts[1])\n",
    "                        y = float(parts[2])\n",
    "                        w = float(parts[3])\n",
    "                        h = float(parts[4])\n",
    "                        \n",
    "                        if not (0 <= x <= 1 and 0 <= y <= 1):\n",
    "                            invalid.append(f\"{lbl_file.name}:{line_num}: Center out of bounds (x={x}, y={y})\")\n",
    "                        if not (0 < w <= 1 and 0 < h <= 1):\n",
    "                            invalid.append(f\"{lbl_file.name}:{line_num}: Dimensions out of bounds (w={w}, h={h})\")\n",
    "                    except ValueError as e:\n",
    "                        invalid.append(f\"{lbl_file.name}:{line_num}: Value error ({str(e)})\")\n",
    "                    except Exception as e:\n",
    "                        invalid.append(f\"{lbl_file.name}:{line_num}: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            invalid.append(f\"{lbl_file.name}: File error ({str(e)})\")\n",
    "        \n",
    "        # Limit the number of errors we collect\n",
    "        if len(invalid) >= max_errors:\n",
    "            invalid.append(f\"... and potentially more (stopped after {max_errors} errors)\")\n",
    "            break\n",
    "    \n",
    "    # Don't update the progress bar too often\n",
    "    progress_bar.close()\n",
    "    \n",
    "    return invalid\n",
    "\n",
    "def validate_all_label_ranges(train_labels, valid_labels):\n",
    "    \"\"\"\n",
    "    Performs label range validation on both training and validation datasets\n",
    "    with optimized output handling for Jupyter.\n",
    "    \n",
    "    Args:\n",
    "        train_labels (str): Path to training labels directory\n",
    "        valid_labels (str): Path to validation labels directory\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if validation succeeds, False otherwise\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    print(\"Validating label value ranges...\")\n",
    "    \n",
    "    # Check training labels\n",
    "    train_label_issues = validate_label_ranges(train_labels)\n",
    "    \n",
    "    # Check validation labels\n",
    "    val_label_issues = validate_label_ranges(valid_labels)\n",
    "    \n",
    "    # Handle the issues\n",
    "    if train_label_issues or val_label_issues:\n",
    "        # Write detailed errors to a file\n",
    "        with open(\"label_range_errors.log\", \"w\") as f:\n",
    "            if train_label_issues:\n",
    "                f.write(\"TRAINING LABEL ISSUES:\\n\")\n",
    "                f.write(\"\\n\".join(train_label_issues) + \"\\n\\n\")\n",
    "            \n",
    "            if val_label_issues:\n",
    "                f.write(\"VALIDATION LABEL ISSUES:\\n\")\n",
    "                f.write(\"\\n\".join(val_label_issues))\n",
    "        \n",
    "        # Show summary in the notebook\n",
    "        print(f\"Label range validation failed:\")\n",
    "        if train_label_issues:\n",
    "            print(f\"- Training labels: {len(train_label_issues)} issues\")\n",
    "        if val_label_issues:\n",
    "            print(f\"- Validation labels: {len(val_label_issues)} issues\")\n",
    "        print(f\"Detailed error log written to 'label_range_errors.log'\")\n",
    "        \n",
    "        # Return a small sample for immediate viewing\n",
    "        sample_size = min(5, max(len(train_label_issues), len(val_label_issues)))\n",
    "        if train_label_issues:\n",
    "            print(\"\\nSample training issues:\")\n",
    "            for issue in train_label_issues[:sample_size]:\n",
    "                print(f\"  - {issue}\")\n",
    "        \n",
    "        if val_label_issues:\n",
    "            print(\"\\nSample validation issues:\")\n",
    "            for issue in val_label_issues[:sample_size]:\n",
    "                print(f\"  - {issue}\")\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    print(\"All label value ranges validated successfully!\")\n",
    "    return True\n",
    "\n",
    "def reset_ultralytics_paths(path_var):\n",
    "    \"\"\"\n",
    "    Resets Ultralytics cached paths to point to your current dataset directory.\n",
    "    This addresses path conflicts between old and new directory structures.\n",
    "    \"\"\"\n",
    "    # Your new, correct path\n",
    "    correct_path = path_var\n",
    "    \n",
    "    # Ultralytics config directory\n",
    "    ultralytics_dir = Path(os.path.expanduser(\"~\")) / \"AppData\" / \"Roaming\" / \"Ultralytics\"\n",
    "    \n",
    "    # 1. Handle settings.json\n",
    "    settings_file = ultralytics_dir / \"settings.json\"\n",
    "    if settings_file.exists():\n",
    "        print(f\"Found settings file at: {settings_file}\")\n",
    "        try:\n",
    "            # Read current settings\n",
    "            with open(settings_file, 'r') as f:\n",
    "                settings = json.load(f)\n",
    "            \n",
    "            # Print current settings for debugging\n",
    "            print(\"Current settings:\")\n",
    "            for key, value in settings.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "            \n",
    "            # Update the datasets_dir setting\n",
    "            old_path = settings.get('datasets_dir', 'Not set')\n",
    "            settings['datasets_dir'] = correct_path\n",
    "            \n",
    "            # Create backup\n",
    "            backup_file = ultralytics_dir / \"settings.json.backup\"\n",
    "            shutil.copy2(settings_file, backup_file)\n",
    "            print(f\"Created backup at: {backup_file}\")\n",
    "            \n",
    "            # Write updated settings\n",
    "            with open(settings_file, 'w') as f:\n",
    "                json.dump(settings, f, indent=4)\n",
    "            \n",
    "            print(f\"Updated datasets_dir from '{old_path}' to '{correct_path}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating settings.json: {e}\")\n",
    "    \n",
    "    # 2. Handle persistent_cache.json\n",
    "    cache_file = ultralytics_dir / \"persistent_cache.json\"\n",
    "    if cache_file.exists():\n",
    "        print(f\"Found persistent cache at: {cache_file}\")\n",
    "        try:\n",
    "            # Create backup\n",
    "            backup_file = ultralytics_dir / \"persistent_cache.json.backup\"\n",
    "            shutil.copy2(cache_file, backup_file)\n",
    "            print(f\"Created backup at: {backup_file}\")\n",
    "            \n",
    "            # Option 1: Delete cache completely to force fresh creation\n",
    "            os.remove(cache_file)\n",
    "            print(f\"Deleted persistent cache to force fresh creation\")\n",
    "            \n",
    "            # Option 2 (alternative): Update paths in cache\n",
    "            # with open(cache_file, 'r') as f:\n",
    "            #     cache = json.load(f)\n",
    "            # \n",
    "            # # Replace all occurrences of old path in the cache\n",
    "            # cache_str = json.dumps(cache)\n",
    "            # updated_str = cache_str.replace('manual_labels', 'automated_labels')\n",
    "            # updated_cache = json.loads(updated_str)\n",
    "            # \n",
    "            # with open(cache_file, 'w') as f:\n",
    "            #     json.dump(updated_cache, f, indent=4)\n",
    "            # print(f\"Updated paths in persistent cache\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error handling persistent_cache.json: {e}\")\n",
    "    \n",
    "    # 3. Clear other potential caches\n",
    "    cache_dirs = [\n",
    "        Path.home() / \".cache\" / \"torch\" / \"ultralytics\",\n",
    "        Path.home() / \".cache\" / \"torch\" / \"hub\" / \"ultralytics\"\n",
    "    ]\n",
    "    \n",
    "    for cache_dir in cache_dirs:\n",
    "        if cache_dir.exists():\n",
    "            try:\n",
    "                shutil.rmtree(cache_dir)\n",
    "                print(f\"Cleared cache directory: {cache_dir}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not clear {cache_dir}: {e}\")\n",
    "    \n",
    "    # 4. Set environment variable for this session\n",
    "    os.environ[\"ULTRALYTICS_DATASETS_DIR\"] = correct_path\n",
    "    print(f\"Set ULTRALYTICS_DATASETS_DIR environment variable to: {correct_path}\")\n",
    "    \n",
    "    print(\"\\nUltralytics paths have been reset successfully!\")\n",
    "    return True\n",
    "\n",
    "def clear_ultralytics_cache(path_var):\n",
    "    \"\"\"\n",
    "    Completely removes all Ultralytics cache files and settings.\n",
    "    This ensures no path conflicts between training runs.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Your correct dataset path\n",
    "    correct_path = path_var\n",
    "    \n",
    "    # 1. Delete Ultralytics directory in AppData completely\n",
    "    ultralytics_dir = Path(os.path.expanduser(\"~\")) / \"AppData\" / \"Roaming\" / \"Ultralytics\"\n",
    "    if ultralytics_dir.exists():\n",
    "        print(f\"Removing Ultralytics settings directory: {ultralytics_dir}\")\n",
    "        try:\n",
    "            shutil.rmtree(ultralytics_dir)\n",
    "            print(\"✓ Removed successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"! Could not remove directory: {e}\")\n",
    "            \n",
    "            # If we can't remove the directory, try to at least remove individual files\n",
    "            for file in [\"settings.json\", \"persistent_cache.json\", \"Arial.ttf\"]:\n",
    "                file_path = ultralytics_dir / file\n",
    "                if file_path.exists():\n",
    "                    try:\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"✓ Removed {file}\")\n",
    "                    except:\n",
    "                        print(f\"! Could not remove {file}\")\n",
    "    \n",
    "    # 2. Delete all torch cache directories related to Ultralytics\n",
    "    cache_locations = [\n",
    "        Path.home() / \".cache\" / \"torch\" / \"ultralytics\",\n",
    "        Path.home() / \".cache\" / \"torch\" / \"hub\" / \"ultralytics\",\n",
    "        Path.home() / \".cache\" / \"torch\" / \"hub\" / \"checkpoints\",\n",
    "        Path.home() / \".config\" / \"Ultralytics\",\n",
    "    ]\n",
    "    \n",
    "    for location in cache_locations:\n",
    "        if location.exists():\n",
    "            print(f\"Removing cache: {location}\")\n",
    "            try:\n",
    "                shutil.rmtree(location)\n",
    "                print(\"✓ Removed successfully\")\n",
    "            except Exception as e:\n",
    "                print(f\"! Could not remove: {e}\")\n",
    "    \n",
    "    # 3. Create a fresh settings.json with correct path\n",
    "    os.makedirs(ultralytics_dir, exist_ok=True)\n",
    "    settings = {\n",
    "        \"datasets_dir\": correct_path,\n",
    "        \"weights_dir\": str(Path.home() / \".config\" / \"Ultralytics\" / \"weights\"),\n",
    "        \"runs_dir\": str(Path(correct_path) / \"runs\"),\n",
    "        \"uuid\": \"track\"  # Set to None to disable tracking\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(ultralytics_dir / \"settings.json\", \"w\") as f:\n",
    "            json.dump(settings, f, indent=4)\n",
    "        print(f\"✓ Created fresh settings with correct path: {correct_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"! Could not create settings file: {e}\")\n",
    "    \n",
    "    # 4. Set environment variables (belt and suspenders approach)\n",
    "    os.environ[\"ULTRALYTICS_DATASETS_DIR\"] = correct_path\n",
    "    \n",
    "    # 5. Clear project-specific cache directories \n",
    "    project_caches = [\n",
    "        Path(correct_path) / \"train\" / \"cache\",\n",
    "        Path(correct_path) / \"valid\" / \"cache\",\n",
    "        Path(correct_path) / \"test\" / \"cache\"\n",
    "    ]\n",
    "    \n",
    "    for cache_dir in project_caches:\n",
    "        if cache_dir.exists():\n",
    "            print(f\"Removing project cache: {cache_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(cache_dir)\n",
    "                print(\"✓ Removed successfully\")\n",
    "            except Exception as e:\n",
    "                print(f\"! Could not remove: {e}\")\n",
    "    \n",
    "    print(\"\\n✓ Cache clearing completed. Ultralytics will use fresh paths on next run.\")\n",
    "    return True\n",
    "\n",
    "def clear_memory():\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "print(\"\\n! ~ All helper functions are ready ~ !\\n\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Main execution block with comprehensive error handling\n",
    "try:    \n",
    "    # Configure PyTorch to be more memory-efficient\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    # For extreme cases, limit CUDA memory use\n",
    "    # torch.cuda.set_per_process_memory_fraction(0.7)  # Use only 70% of GPU memory\n",
    "\n",
    "    # Add before model.train()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()  # Clear GPU cache\n",
    "        \n",
    "    # Set a memory-efficient training approach\n",
    "    gc.collect()  # Force garbage collection\n",
    "\n",
    "    # Device configuration\n",
    "    device, batch_size, device_info = get_device_config()\n",
    "    print(\"\\nDevice Configuration:\")\n",
    "    for key, value in device_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(f\"Suggested batch size: {batch_size}\")\n",
    "    \n",
    "    # Clear global settings cache\n",
    "    # early in the script\n",
    "    shutil.rmtree(os.path.join(os.path.expanduser('~'), '.cache', 'torch', 'ultralytics'), ignore_errors=True)\n",
    "    # Reset YOLO checks\n",
    "    # early in the script\n",
    "    check_yolo(verbose=False)\n",
    "\n",
    "    # Define paths - Update this to your dataset path\n",
    "    # Replace with your actual path ~ default : 'path_to_your_dataset_folder'\n",
    "    # default : '/Users/gustavszviedris/Desktop/vet_images_sliced_split' ; \n",
    "    # example 00 : 'E:\\\\-_EDI_-\\\\notes\\\\havetai+vetcyto\\\\vet_images_sliced_split' ; \n",
    "    # notes : \"example 01\" = “attempt-02” (experiment-step-05) [ManualAnnotations] ~ 100%\n",
    "    # example 01 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_manual_labels_T_500' ; \n",
    "    # notes : \"example 02\" = “attempt-03” (experiment-step-06) [ManualAnnotations] ~ 100%\n",
    "    # example 02 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_manual_labels_T_640'\n",
    "    # notes : \"example 03\" = “attempt-04” (experiment-step-07) [AutomatedAnnotations] ~ 100%\n",
    "    # example 03 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640'\n",
    "    # notes : \"example 04\" =  “attempt-05” (experiment-step-08) [ManualAnnotations] ~ 125%\n",
    "    # example 04 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_manual_labels_T_640_pc_125'\n",
    "    # notes : example 05 = “attempt-06” (experiment-step-09) [AutomatedAnnotations] ~ 125%\n",
    "    # example 05 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_125'\n",
    "    # notes : \"example 06\" =  “attempt-07” (experiment-step-10) [ManualAnnotations] ~ 150%\n",
    "    # example 06 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_manual_labels_T_640_pc_150'\n",
    "    # notes : \"example 07\" =  “attempt-08” (experiment-step-11) [AutomatedAnnotations] ~ 150%\n",
    "    # example 07 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_automated_labels_T_640_pc_150'\n",
    "    # notes : \"example 08\" =  “attempt-09” (experiment-step-12) [ManualAnnotations] ~ 175%\n",
    "    # example 08 : 'C:\\\\Users\\\\praam\\\\Desktop\\\\havetai+vetcyto\\\\04th_task-04_new-work-03\\\\February15.v1i.yolov8\\\\splitting_output_manual_labels_T_640_pc_175'\n",
    "    # notes : ?\n",
    "    # example 09 : ''\n",
    "    # notes : synthetic + original + mixed + 640 ;\n",
    "    # example : 'C:\\Users\\praam\\Desktop\\havetai+vetcyto\\task-05_dataset\\splitting_output_automated_labels_T_640_pc_150_mixed_01'\n",
    "    base_path = r\"C:\\Users\\praam\\Desktop\\havetai+vetcyto\\task-05_dataset\\T_640_real-synthetic-mixed-03_ratio-1.5-units\"  \n",
    "    data_yaml_path = os.path.join(base_path, \"data.yaml\")\n",
    "    \n",
    "    reset_ultralytics_paths(base_path)\n",
    "    clear_ultralytics_cache(base_path)\n",
    "\n",
    "    # Call this function before any YOLO operations ~ useful only for automated labels\n",
    "    #force_correct_paths(base_path)\n",
    "\n",
    "    # Clear Ultralytics cache directories\n",
    "    cache_dirs = [\n",
    "        Path.home() / '.cache' / 'torch' / 'ultralytics',\n",
    "        Path.home() / '.cache' / 'torch' / 'hub',\n",
    "        Path.home() / '.config' / 'Ultralytics'\n",
    "    ]\n",
    "    for d in cache_dirs:\n",
    "        if d.exists():\n",
    "            print(f\"Clearing cache: {d}\")\n",
    "            shutil.rmtree(d, ignore_errors=True)\n",
    "\n",
    "    # Add this before initializing the model\n",
    "    # execute earlier in the script, before any YOLO operations\n",
    "    settings.update({'datasets_dir': base_path})\n",
    "    settings['datasets_dir'] = base_path  # Force update internal settings\n",
    "    \n",
    "    os.chdir(base_path)  # Change working directory to dataset root\n",
    "\n",
    "    # Add this line right after defining base_path:\n",
    "    print(f\"\\n=== Directory Structure Check ===\")\n",
    "    print(f\"Checking: {base_path}\")\n",
    "    ! echo \"results for 'dir' :\" && dir\n",
    "\n",
    "    # Validate YAML content\n",
    "    print(\"\\nValidating YAML content...\")\n",
    "    yaml_valid, yaml_message = validate_yaml_content(data_yaml_path)\n",
    "    if not yaml_valid:\n",
    "        raise ValueError(yaml_message)\n",
    "    print(yaml_message)\n",
    "\n",
    "    # Validate image-label pairs\n",
    "    print(\"\\nValidating image-label pairs...\")\n",
    "    pairs_valid, pairs_message = validate_image_label_pairs(base_path)\n",
    "    if not pairs_valid:\n",
    "        raise ValueError(pairs_message)\n",
    "    print(pairs_message)\n",
    "\n",
    "    # Create versioned project directory for results\n",
    "    project_path = os.path.join(base_path, \"results\")\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    name = f\"yolov8s_training_{timestamp}\"\n",
    "    \n",
    "    # Make sure the project directory exists\n",
    "    create_directory(project_path) # use custom function instead of \"os.makedirs\" to avoid creating read-only folders\n",
    "    \n",
    "    print(f\"\\nResults will be saved to: {os.path.join(project_path, name)}\")\n",
    "\n",
    "    # Initialize model\n",
    "    try:\n",
    "        model_name='yolov8s.pt'\n",
    "        # Delete existing model if present\n",
    "        model_path = Path(model_name)\n",
    "        if model_path.exists():\n",
    "            model_path.unlink()\n",
    "        # Download fresh model\n",
    "        model = YOLO(model_name)  # Load pretrained YOLOv8s model\n",
    "        # Override any stored paths\n",
    "        if hasattr(model, 'args'):\n",
    "            if hasattr(model.args, 'data'):\n",
    "                model.args.data = None  # Reset data path\n",
    "        print(\"\\nModel initialized successfully\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error initializing YOLO model: {str(e)}\")\n",
    "\n",
    "    # troubleshooting step is to print out the actual absolute paths that YOLO is trying to open\n",
    "    print(\"\\n!!! result for 'os.getcwd()' = \", os.getcwd())\n",
    "\n",
    "    # Call this before model training\n",
    "    debug_paths(data_yaml_path)\n",
    "\n",
    "    # Add cache clearing before training\n",
    "    shutil.rmtree(os.path.join(base_path, \"train\", \"cache\"), ignore_errors=True)\n",
    "    shutil.rmtree(os.path.join(base_path, \"valid\", \"cache\"), ignore_errors=True)\n",
    "\n",
    "    # Check critical directories\n",
    "    train_images = os.path.join(base_path, \"train\", \"images\")\n",
    "    train_labels = os.path.join(base_path, \"train\", \"labels\")\n",
    "    check_directory_contents(train_images)\n",
    "    check_directory_contents(train_labels)\n",
    "    valid_images = os.path.join(base_path, \"valid\", \"images\")\n",
    "    valid_labels = os.path.join(base_path, \"valid\", \"labels\")\n",
    "    check_directory_contents(valid_images)\n",
    "    check_directory_contents(valid_labels)\n",
    "\n",
    "    # Add after directory checks:\n",
    "    print(\"\\nValidating label formats...\")\n",
    "    if not validate_label_formats(train_labels, os.path.join(base_path, \"valid/labels\"), verbose=True):\n",
    "        raise ValueError(\"Label validation failed. Check the error log for details.\")\n",
    "    \n",
    "    # Add before training:\n",
    "    print(\"\\nChecking for corrupt media files...\")\n",
    "    corrupt_train = remove_corrupted_files(os.path.join(base_path, \"train/images\"))\n",
    "    corrupt_val = remove_corrupted_files(os.path.join(base_path, \"valid/images\"))\n",
    "    print(f\"Removed {len(corrupt_train)+len(corrupt_val)} corrupt files\")\n",
    "\n",
    "    # Add before training\n",
    "    print(\"Validating label value ranges...\")\n",
    "    if not validate_all_label_ranges(train_labels, valid_labels):\n",
    "        raise ValueError(\"Label range validation failed. Check the error log for details.\")\n",
    "    \n",
    "    print(\"ULTRALYTICS_DATASETS_DIR:\", os.getenv('ULTRALYTICS_DATASETS_DIR'))\n",
    "    print(\"Current working directory:\", os.getcwd())\n",
    "    print(\"Data YAML path being used:\", data_yaml_path)\n",
    "    \n",
    "    # Test model sanity with a single batch\n",
    "    # \"\"\"\n",
    "    print(\"\\nRunning sanity check...\")\n",
    "    tmp_model = YOLO('yolov8s.pt')\n",
    "    tmp_results = tmp_model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=3,\n",
    "        imgsz=512,\n",
    "        batch=4,\n",
    "        device=device, # 'cpu',\n",
    "        workers=4,\n",
    "        cache=False,\n",
    "        name='sanity_check', #, #_break='train' # not a valid yolo argument\n",
    "    )\n",
    "    #assert tmp_results.box.loss > 0.5, \"Sanity check failed - model not learning\" # removed \"[0]\" & replaced \"boxes\" with \"box\"\n",
    "    mp, mr, map50, map = tmp_results.mean_results()  # returns mean precision, recall, AP@0.5, and AP@0.5:0.95\n",
    "    assert mr > 0.05, \"Sanity check failed - model not learning\" # change box recall threshold value from 0.1 to either 0.05 or 0.025 if ncessary\n",
    "    # \"\"\"\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"\\nStarting training...\")\n",
    "\n",
    "    original_umask = os.umask(0)  # Set umask to 0 for full permissions\n",
    "\n",
    "    # Call this between major operations\n",
    "    clear_memory()\n",
    "\n",
    "    results = model.train(\n",
    "        data=data_yaml_path,\n",
    "        task='detect',  # Add this line to ensure paths are resolved correctly\n",
    "        project=project_path,\n",
    "        name=name,\n",
    "        epochs=200,\n",
    "        patience=25,\n",
    "        batch=4,  # manual annotations ~ batch size = \"batch_size\" (8) ; automated annotations ~ batch size = \"4\" ;\n",
    "        nbs=8,    # manual annotations ~ commented out ; automated annotations ~ effective/nominal batch size = \"8\" ;\n",
    "        imgsz=640,  # either using 512 as the closest multiple of 32 to 500 or using 640 as the default for yolo ;\n",
    "        device=device,\n",
    "        workers=min(8, os.cpu_count() or 1),\n",
    "        degrees=45,\n",
    "        flipud=0.5,\n",
    "        mixup=0.1,\n",
    "        cache='disk',  # Use disk cache instead of RAM # formerly : cache=True,\n",
    "        amp=True,\n",
    "        exist_ok=False,  # Prevent overwriting\n",
    "        val=True,  # Enable validation during training\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining completed successfully\")\n",
    "\n",
    "    # Ensure all result directories are writable\n",
    "    training_output_dir = os.path.join(project_path, name)\n",
    "    print(f\"\\nSetting permissions for {training_output_dir}...\")\n",
    "    set_permissions_recursive(training_output_dir, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n",
    "    \n",
    "    # Plot results\n",
    "    try:\n",
    "        plot_results(file=f'{project_path}/{name}')\n",
    "        print(\"Training results plotted successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not plot results: {str(e)}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"\\nStarting evaluation on test set...\")\n",
    "    test_results = model.val(\n",
    "        data=data_yaml_path,\n",
    "        project=project_path,\n",
    "        name=f\"{name}_test\",\n",
    "        split='test'  # Specifically use test set for final evaluation\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTest Set Evaluation Results:\")\n",
    "    #print(test_results)\n",
    "    print(\"...\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nError: Required file not found: {str(e)}\")\n",
    "except PermissionError as e:\n",
    "    print(f\"\\nError: Permission denied when accessing files: {str(e)}\")\n",
    "except ValueError as e:\n",
    "    print(f\"\\nError: Validation failed: {str(e)}\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\nError: Runtime error occurred: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nUnexpected error occurred: {str(e)}\")\n",
    "finally:\n",
    "    print(\"\\nScript execution completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes: The end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
