{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNGqIxBRj6Ug"
   },
   "source": [
    "## **The new code for handling small images (the old code was discarded).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-qeyDuGz0LUf",
    "outputId": "dc75a6bd-4a93-4770-a7fd-70bb45ab8974"
   },
   "outputs": [],
   "source": [
    "# LIBRARY IMPORTS\n",
    "\n",
    "# Install the ultralytics package using pip\n",
    "!pip install ultralytics\n",
    "\n",
    "# Import required libraries\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Without this Colab is giving an error when installing Roboflow\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "# Connect to google drive for accessing files.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHUJj8Z91mGD"
   },
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS (\"get_next_version_path\" / \"convert_yolo_to_labelme\" / \"save_detections\")\n",
    "\n",
    "def get_next_version_path(base_path):\n",
    "    \"\"\"\n",
    "    Get the next available version number for a directory.\n",
    "\n",
    "    Args:\n",
    "        base_path (Path): Base directory path without version number\n",
    "\n",
    "    Returns:\n",
    "        Path: New directory path with appropriate version number\n",
    "\n",
    "    Example:\n",
    "        If 'generated-labeling' exists, returns 'generated-labeling-1'\n",
    "        If 'generated-labeling-1' exists too, returns 'generated-labeling-2'\n",
    "    \"\"\"\n",
    "    if not base_path.exists():\n",
    "        return base_path\n",
    "\n",
    "    # Check for existing versioned directories\n",
    "    parent = base_path.parent\n",
    "    base_name = base_path.name\n",
    "\n",
    "    # Get all existing directories that match the pattern base_name(-N)?\n",
    "    existing_dirs = [d for d in parent.glob(f\"{base_name}*\") if d.is_dir()]\n",
    "\n",
    "    if not existing_dirs:\n",
    "        return base_path\n",
    "\n",
    "    # Extract version numbers from existing directories\n",
    "    versions = [0]  # Include 0 for the base directory\n",
    "    for dir_path in existing_dirs:\n",
    "        dir_name = dir_path.name\n",
    "        if dir_name == base_name:\n",
    "            continue\n",
    "        # Try to extract version number from directory name\n",
    "        try:\n",
    "            version = int(dir_name.replace(f\"{base_name}-\", \"\"))\n",
    "            versions.append(version)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    # Get the next version number\n",
    "    next_version = max(versions) + 1\n",
    "    return parent / f\"{base_name}-{next_version}\"\n",
    "\n",
    "def convert_yolo_to_labelme(image_path, boxes, class_ids, class_names, confidence_scores):\n",
    "    \"\"\"Convert YOLO format detections to LabelMe JSON format\n",
    "\n",
    "    Args:\n",
    "        image_path (str/Path): Path to the source image\n",
    "        boxes (np.array): Array of normalized bounding box coordinates [x1, y1, x2, y2]\n",
    "        class_ids (np.array): Array of class IDs for each detection\n",
    "        class_names (dict): Dictionary mapping class IDs to class names\n",
    "        confidence_scores (np.array): Array of confidence scores for each detection\n",
    "\n",
    "    Returns:\n",
    "        dict: LabelMe format JSON dictionary, or None if conversion fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open image to get dimensions\n",
    "        img = Image.open(image_path)\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "        # Initialize list to store shape dictionaries\n",
    "        shapes = []\n",
    "\n",
    "        # Process each detection\n",
    "        for box, class_id, conf in zip(boxes, class_ids, confidence_scores):\n",
    "            # Convert normalized coordinates (0-1) to absolute pixel coordinates\n",
    "            x1, y1, x2, y2 = box\n",
    "            x1 = float(x1 * img_width)\n",
    "            y1 = float(y1 * img_height)\n",
    "            x2 = float(x2 * img_width)\n",
    "            y2 = float(y2 * img_height)\n",
    "\n",
    "            # Create shape dictionary for current detection\n",
    "            shape = {\n",
    "                \"label\": class_names[int(class_id)],  # Convert class ID to name\n",
    "                \"points\": [[x1, y1], [x2, y1], [x2, y2], [x1, y2]],  # Rectangle corners\n",
    "                \"group_id\": None,  # Not using groups\n",
    "                \"shape_type\": \"polygon\",  # Using polygon type for rectangle\n",
    "                \"flags\": {},  # No special flags\n",
    "                \"confidence\": float(conf)  # Add confidence score\n",
    "            }\n",
    "            shapes.append(shape)\n",
    "\n",
    "        # Create full LabelMe format dictionary\n",
    "        labelme_format = {\n",
    "            \"version\": \"5.1.1\",  # LabelMe version\n",
    "            \"flags\": {},  # No global flags\n",
    "            \"shapes\": shapes,  # List of all detected objects\n",
    "            \"imagePath\": os.path.basename(image_path),  # Just the filename\n",
    "            \"imageData\": None,  # No embedded image data\n",
    "            \"imageHeight\": img_height,\n",
    "            \"imageWidth\": img_width\n",
    "        }\n",
    "\n",
    "        return labelme_format\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting to LabelMe format for {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def save_detections(model, test_images_dir, project_dir, name):\n",
    "    \"\"\"\n",
    "    Run object detection and save results in both YOLO and LabelMe formats\n",
    "\n",
    "    Args:\n",
    "        model: Loaded YOLO model\n",
    "        test_images_dir (str/Path): Directory containing test images\n",
    "        project_dir (str/Path): Base directory for saving results\n",
    "        name (str): Name prefix for output directories\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create base directory path\n",
    "        base_gen_lab_dir = Path(project_dir) / \"generated-labeling\"\n",
    "\n",
    "        # Get next available version of the directory\n",
    "        gen_lab_dir = get_next_version_path(base_gen_lab_dir)\n",
    "\n",
    "        # Create subdirectories for YOLO and LabelMe formats\n",
    "        yolo_dir = gen_lab_dir / \"yolo\"\n",
    "        labelme_dir = gen_lab_dir / \"labelme\"\n",
    "\n",
    "        # Create all required directories\n",
    "        for directory in [gen_lab_dir, yolo_dir, labelme_dir]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(f\"\\nCreated new output directory: {gen_lab_dir}\")\n",
    "\n",
    "        # Convert test_images_dir to Path object\n",
    "        test_path = Path(test_images_dir)\n",
    "        print(f\"Looking for images in: {test_path}\")\n",
    "\n",
    "        # Process each image and its detections\n",
    "        image_extensions = ('.jpg', '.jpeg', '.png')\n",
    "        image_files = []\n",
    "        for ext in image_extensions:\n",
    "            image_files.extend(list(test_path.glob(f'*{ext}')))\n",
    "\n",
    "        if not image_files:\n",
    "            raise Exception(f\"No images found in {test_path}\")\n",
    "\n",
    "        print(f\"Found {len(image_files)} images to process\")\n",
    "\n",
    "        # Process each image\n",
    "        for image_path in image_files:\n",
    "            try:\n",
    "                print(f\"\\nProcessing image: {image_path}\")\n",
    "                # Get predictions for this image\n",
    "                results = model(image_path)\n",
    "                boxes = results[0].boxes\n",
    "\n",
    "                # Get normalized coordinates\n",
    "                coords = boxes.xyxyn.cpu().numpy()\n",
    "                class_ids = boxes.cls.cpu().numpy()\n",
    "                confidence_scores = boxes.conf.cpu().numpy()\n",
    "\n",
    "                print(f\"Found {len(coords)} detections\")\n",
    "\n",
    "                # Save YOLO format\n",
    "                yolo_path = yolo_dir / f\"{image_path.stem}.txt\"\n",
    "                with open(yolo_path, 'w') as f:\n",
    "                    for box, class_id, conf in zip(coords, class_ids, confidence_scores):\n",
    "                        # Convert to YOLO format: <class> <x_center> <y_center> <width> <height>\n",
    "                        x1, y1, x2, y2 = box\n",
    "                        x_center = (x1 + x2) / 2\n",
    "                        y_center = (y1 + y2) / 2\n",
    "                        width = x2 - x1\n",
    "                        height = y2 - y1\n",
    "                        f.write(f\"{int(class_id)} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "                # Save LabelMe format\n",
    "                labelme_json = convert_yolo_to_labelme(\n",
    "                    image_path,\n",
    "                    coords,\n",
    "                    class_ids,\n",
    "                    model.names,\n",
    "                    confidence_scores\n",
    "                )\n",
    "\n",
    "                if labelme_json:\n",
    "                    labelme_path = labelme_dir / f\"{image_path.stem}.json\"\n",
    "                    with open(labelme_path, 'w') as f:\n",
    "                        json.dump(labelme_json, f, indent=2)\n",
    "\n",
    "                print(f\"Saved results for {image_path.name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        print(f\"\\nResults saved in:\")\n",
    "        print(f\"YOLO format: {yolo_dir}\")\n",
    "        print(f\"LabelMe format: {labelme_dir}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in save_detections: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9DiULnhLKCkB",
    "outputId": "c972c3c8-8100-46de-a116-bb698c06c50f"
   },
   "outputs": [],
   "source": [
    "# CORE CODE\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"cwd:\", os.getcwd())\n",
    "\n",
    "    # Define paths\n",
    "    # default address : \"/content/drive/MyDrive/October15.v1i.yolov8/results\" ;\n",
    "    project = \"/content/drive/MyDrive/October15.v1i.yolov8/results\"\n",
    "    # default address : \"/content/drive/MyDrive/October15.v1i.yolov8/test/images\" ; alt : \"/content/drive/MyDrive/October15.v1i.yolov8/sampling_set/images\" ;\n",
    "    test_images_dir = \"/content/drive/MyDrive/October15.v1i.yolov8/slicing_output\"\n",
    "    name = \"200_epochs-\"\n",
    "\n",
    "    try:\n",
    "        # Load trained model\n",
    "        best_model = YOLO(f'{project}/{name}/weights/best.pt')\n",
    "\n",
    "        # Save detections in both formats\n",
    "        save_detections(\n",
    "            model=best_model,\n",
    "            test_images_dir=test_images_dir,\n",
    "            project_dir=project,\n",
    "            name=f'{name}'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OV9lo2SuOZ_L",
    "outputId": "e6b13a4d-a733-4b7a-a2c0-a079a0f07a98"
   },
   "outputs": [],
   "source": [
    "# SETTINGS CHECK\n",
    "\n",
    "project = \"/content/drive/MyDrive/October15.v1i.yolov8/results\"\n",
    "name = \"200_epochs-\"\n",
    "best_model = YOLO(f'{project}/{name}/weights/best.pt')\n",
    "print(best_model)  # This may show default settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goKipHlpsct4"
   },
   "source": [
    "## **The final version of the code for handling big images (it didn't exist previously).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dAOItiItLWP3",
    "outputId": "5a10e112-9722-41dd-a9eb-8011226b69e4"
   },
   "outputs": [],
   "source": [
    "!pip install sahi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5wkD7lNbRSWD",
    "outputId": "4a741d64-c97c-4e0a-cd04-458883b6a1ee"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enhanced Object Detection Script using SAHI and YOLO\n",
    "\n",
    "Key Improvements:\n",
    "- Robust error handling\n",
    "- Comprehensive logging\n",
    "- Flexible image processing\n",
    "- Detailed performance tracking\n",
    "\"\"\"\n",
    "\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# using an enhanced logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# versioning of directories for saving resulting outputs in the two suitable file types\n",
    "def get_next_version_path(base_path):\n",
    "    \"\"\"\n",
    "    Generate the next available versioned directory path.\n",
    "\n",
    "    Prevents overwriting existing result directories by\n",
    "    incrementing a version number.\n",
    "    \"\"\"\n",
    "    if not base_path.exists():\n",
    "        return base_path\n",
    "\n",
    "    parent = base_path.parent\n",
    "    base_name = base_path.name\n",
    "\n",
    "    # Find existing versioned directories\n",
    "    existing_dirs = [d for d in parent.glob(f\"{base_name}*\") if d.is_dir()]\n",
    "\n",
    "    versions = [0]\n",
    "    for dir_path in existing_dirs:\n",
    "        dir_name = dir_path.name\n",
    "        if dir_name == base_name:\n",
    "            continue\n",
    "        try:\n",
    "            version = int(dir_name.replace(f\"{base_name}-\", \"\"))\n",
    "            versions.append(version)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    next_version = max(versions) + 1\n",
    "    return parent / f\"{base_name}-{next_version}\"\n",
    "\n",
    "# filtering the outliers based on the ratio of a bounding box area with the image area\n",
    "def filter_detections(detections, image_path, max_relative_area=0.0035, min_confidence=0.6): # reduced max_relative_area from 0.4 (40%) to 0.0035 (0.35%)\n",
    "    # get numbers\n",
    "    #print(\"\\n\", \"type(detections): \", type(detections))\n",
    "    #print(\"len(detections): \", len(detections), \"\\n\")\n",
    "\n",
    "    # get attributes\n",
    "    #print(\"\\ndetections attributes: \", dir(detections))\n",
    "    #print(\"\\ndetections[0] attributes: \", dir(detections[0]))\n",
    "    #print(\"\\ndetections[0].bbox attributes: \", dir(detections[0].bbox))\n",
    "\n",
    "    \"\"\"\n",
    "    Robust detection filtering with image dimension handling.\n",
    "\n",
    "    Filters detections based on:\n",
    "    - Relative bounding box area\n",
    "    - Confidence threshold\n",
    "    - Direct image dimension reading\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Safely read image dimensions\n",
    "        with Image.open(image_path) as img:\n",
    "            img_width, img_height = img.size\n",
    "\n",
    "        filtered_detections = []\n",
    "\n",
    "        for detection in detections:\n",
    "            # Safely extract bounding box coordinates\n",
    "            bbox = detection.bbox.to_xyxy()\n",
    "\n",
    "            # Robust dimension and confidence calculation\n",
    "            bbox_width = max(0, bbox[2] - bbox[0])\n",
    "            bbox_height = max(0, bbox[3] - bbox[1])\n",
    "\n",
    "            # Prevent division by zero\n",
    "            relative_area = (\n",
    "                (bbox_width * bbox_height) / (img_width * img_height)\n",
    "                if img_width > 0 and img_height > 0\n",
    "                else 0\n",
    "            )\n",
    "\n",
    "            # Safe confidence extraction\n",
    "            try:\n",
    "                confidence = float(detection.score.value)\n",
    "            except (TypeError, AttributeError):\n",
    "                confidence = 0.0\n",
    "\n",
    "            # Apply filtering criteria with detailed logging\n",
    "            if (relative_area <= max_relative_area and\n",
    "                confidence >= min_confidence):\n",
    "                filtered_detections.append(detection)\n",
    "            else:\n",
    "                logger.debug(\n",
    "                    f\"Filtered detection: \"\n",
    "                    f\"Area={relative_area:.4f}, \"\n",
    "                    f\"Confidence={confidence:.4f}\"\n",
    "                )\n",
    "\n",
    "        # get numbers\n",
    "        #print(\"\\n\", \"type(filtered_detections): \", type(filtered_detections))\n",
    "        #print(\"len(filtered_detections): \", len(filtered_detections), \"\\n\")\n",
    "\n",
    "        return filtered_detections\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in filter_detections: {e}\")\n",
    "        return []\n",
    "\n",
    "# converting between the two suitable file types for saving the resulting outputs\n",
    "def convert_yolo_to_labelme(image_path, detections, class_names):\n",
    "    \"\"\"\n",
    "    Comprehensive conversion of YOLO detections to LabelMe format.\n",
    "\n",
    "    Includes:\n",
    "    - Robust error handling\n",
    "    - Full conversion of all detections\n",
    "    - Detailed JSON generation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open image safely\n",
    "        with Image.open(image_path) as img:\n",
    "            img_width, img_height = img.size\n",
    "\n",
    "        # Prepare shapes with comprehensive type checking\n",
    "        shapes = []\n",
    "        for detection in detections:\n",
    "            try:\n",
    "                # Safe attribute extraction\n",
    "                class_id = int(detection.category.id)\n",
    "                bbox = detection.bbox.to_xyxy()\n",
    "                confidence = float(detection.score.value)\n",
    "\n",
    "                shape = {\n",
    "                    \"label\": str(\n",
    "                        class_names.get(\n",
    "                            class_id,\n",
    "                            f\"Unknown_Class_{class_id}\"\n",
    "                        )\n",
    "                    ),\n",
    "                    \"points\": [\n",
    "                        [float(bbox[0]), float(bbox[1])],  # Top-left\n",
    "                        [float(bbox[2]), float(bbox[1])],  # Top-right\n",
    "                        [float(bbox[2]), float(bbox[3])],  # Bottom-right\n",
    "                        [float(bbox[0]), float(bbox[3])]   # Bottom-left\n",
    "                    ],\n",
    "                    \"group_id\": None,\n",
    "                    \"shape_type\": \"polygon\",\n",
    "                    \"flags\": {},\n",
    "                    \"confidence\": confidence\n",
    "                }\n",
    "                shapes.append(shape)\n",
    "\n",
    "            except Exception as detection_err:\n",
    "                logger.error(\n",
    "                    f\"Error processing detection in conversion: {detection_err}\"\n",
    "                )\n",
    "\n",
    "        # Construct LabelMe format dictionary\n",
    "        labelme_format = {\n",
    "            \"version\": \"5.1.1\",\n",
    "            \"flags\": {},\n",
    "            \"shapes\": shapes,\n",
    "            \"imagePath\": os.path.basename(image_path),\n",
    "            \"imageData\": None,\n",
    "            \"imageHeight\": int(img_height),\n",
    "            \"imageWidth\": int(img_width)\n",
    "        }\n",
    "\n",
    "        return labelme_format\n",
    "\n",
    "    except Exception as main_err:\n",
    "        logger.error(f\"LabelMe conversion error for {image_path}: {main_err}\")\n",
    "        return None\n",
    "\n",
    "# filtering the outliers based on the average bounding box area using statistical techniques\n",
    "def remove_area_outliers(detections, multiplier=4.5): # increased multiplier from 1.5 (strict) to 4.5 (lenient)\n",
    "    \"\"\"\n",
    "    Remove area outliers using the IQR method\n",
    "\n",
    "    Args:\n",
    "        detections (list): List of object predictions\n",
    "        multiplier (float): IQR multiplier for outlier detection (new [lenient] default = 3.0, old [strict] default = 1.5)\n",
    "\n",
    "    Returns:\n",
    "        list: Filtered detections without area outliers\n",
    "    \"\"\"\n",
    "    # Extract areas\n",
    "    areas = [detection.bbox.area for detection in detections]\n",
    "\n",
    "    # Calculate Q1, Q3, and IQR\n",
    "    q1 = np.percentile(areas, 25)\n",
    "    q3 = np.percentile(areas, 75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Define outlier boundaries\n",
    "    lower_bound = q1 - (multiplier * iqr)\n",
    "    upper_bound = q3 + (multiplier * iqr)\n",
    "\n",
    "    # Filter detections\n",
    "    filtered_detections = [\n",
    "        detection for detection in detections\n",
    "        if lower_bound <= detection.bbox.area <= upper_bound\n",
    "    ]\n",
    "\n",
    "    # Log outlier information\n",
    "    logger.info(f\"Total detections: {len(detections)}\")\n",
    "    logger.info(f\"Detections after outlier removal: {len(filtered_detections)}\")\n",
    "    logger.info(f\"Outlier boundaries: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "    logger.info(f\"Removed {len(detections) - len(filtered_detections)} outliers\")\n",
    "\n",
    "    return filtered_detections\n",
    "\n",
    "# visualizing area distribution before and after filtering\n",
    "def plot_area_distribution(original_detections, filtered_detections):\n",
    "    original_areas = [det.bbox.area for det in original_detections]\n",
    "    filtered_areas = [det.bbox.area for det in filtered_detections]\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Box plot for original areas\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title('Input Areas - With Outliers - Box Plot')\n",
    "    sns.boxplot(original_areas)\n",
    "    plt.xlabel('Area')\n",
    "\n",
    "    # Box plot for filtered areas\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title('Output Areas - Without Outliers - Box Plot')\n",
    "    sns.boxplot(filtered_areas)\n",
    "    plt.xlabel('Area')\n",
    "\n",
    "    # Violin plot for original areas\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title('Input Areas - With Outliers - Violin Plot')\n",
    "    sns.violinplot(original_areas)\n",
    "    plt.xlabel('Area')\n",
    "\n",
    "    # Violin plot for filtered areas\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title('Output Areas - Without Outliers - Violin Plot')\n",
    "    sns.violinplot(filtered_areas)\n",
    "    plt.xlabel('Area')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('area_distribution_comparison.png')\n",
    "    plt.show()\n",
    "\n",
    "# using the trained model to detect objects in images\n",
    "def test_sahi_yolo(\n",
    "    model_path,\n",
    "    test_images_dir,\n",
    "    project_dir,\n",
    "    name='detection',\n",
    "    slice_height=640,  # maybe reduce from 640 to 512/480\n",
    "    slice_width=640,   # maybe reduce from 640 to 512/480\n",
    "    overlap_ratio=0.2, # maybe increase from 0.2 to 0.3\n",
    "    conf_threshold=0.5 # maybe increase from 0.5 to 0.6\n",
    "):\n",
    "    \"\"\"\n",
    "    Enhanced object detection pipeline with:\n",
    "    - Comprehensive error handling\n",
    "    - Detailed logging\n",
    "    - Performance tracking\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "    logger.info(f\"Starting detection process at {start_time}\")\n",
    "    logger.info(f\"Model Path: {model_path}\")\n",
    "    logger.info(f\"Test Images Directory: {test_images_dir}\")\n",
    "    logger.info(f\"Project Directory: {project_dir}\")\n",
    "\n",
    "    # Setup output directories\n",
    "    base_gen_lab_dir = Path(project_dir) / \"generated-labeling\"\n",
    "    gen_lab_dir = get_next_version_path(base_gen_lab_dir)\n",
    "    yolo_dir = gen_lab_dir / \"yolo\"\n",
    "    labelme_dir = gen_lab_dir / \"labelme\"\n",
    "\n",
    "    # Create output directories\n",
    "    for directory in [gen_lab_dir, yolo_dir, labelme_dir]:\n",
    "        directory.mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(f\"Created output directories in: {gen_lab_dir}\")\n",
    "\n",
    "    # Initialize detection model\n",
    "    try:\n",
    "        detection_model = AutoDetectionModel.from_pretrained(\n",
    "            model_type='yolov8',\n",
    "            model_path=model_path,\n",
    "            confidence_threshold=conf_threshold\n",
    "        )\n",
    "        logger.info(\"YOLO model loaded successfully\")\n",
    "    except Exception as model_load_err:\n",
    "        logger.error(f\"Model loading failed: {model_load_err}\")\n",
    "        return\n",
    "\n",
    "    # Performance tracking variables\n",
    "    total_images = 0\n",
    "    total_detections = 0\n",
    "    failed_images = []\n",
    "    detailed_errors = {}\n",
    "\n",
    "    # Walk through image directories\n",
    "    for root, _, files in os.walk(test_images_dir):\n",
    "        image_files = [\n",
    "            f for f in files\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ]\n",
    "\n",
    "        if not image_files:\n",
    "            continue\n",
    "\n",
    "        # Create corresponding output subdirectories\n",
    "        relative_path = os.path.relpath(root, test_images_dir)\n",
    "        current_yolo_dir = yolo_dir / relative_path\n",
    "        current_labelme_dir = labelme_dir / relative_path\n",
    "        current_yolo_dir.mkdir(parents=True, exist_ok=True)\n",
    "        current_labelme_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        logger.info(f\"Processing directory: {relative_path}\")\n",
    "\n",
    "        # Process each image\n",
    "        for image_name in tqdm(image_files, desc=f\"Processing {relative_path}\", unit=\"image\"):\n",
    "            try:\n",
    "                image_path = os.path.join(root, image_name)\n",
    "                logger.info(f\"Processing image: {image_path}\")\n",
    "\n",
    "                # Perform sliced prediction\n",
    "                results = get_sliced_prediction(\n",
    "                    image_path,\n",
    "                    detection_model,\n",
    "                    slice_height=slice_height,\n",
    "                    slice_width=slice_width,\n",
    "                    overlap_height_ratio=overlap_ratio,\n",
    "                    overlap_width_ratio=overlap_ratio\n",
    "                )\n",
    "\n",
    "                # get numbers\n",
    "                #print(\"\\n\", \"type(results): \", type(results))\n",
    "                print(\"\\n\", \"type(results.object_prediction_list): \", type(results.object_prediction_list))\n",
    "                print(\"len(results.object_prediction_list): \", len(results.object_prediction_list), \"\\n\")\n",
    "\n",
    "                # get attributes\n",
    "                #print(\"\\nresults attributes: \", dir(results))\n",
    "                #print(\"\\nresults.object_prediction_list attributes: \", dir(results.object_prediction_list))\n",
    "                #print(\"\\nresults.object_prediction_list[0] attributes: \", dir(results.object_prediction_list[0]))\n",
    "                #print(\"\\nresults.object_prediction_list[0].bbox attributes: \", dir(results.object_prediction_list[0].bbox))\n",
    "\n",
    "                # Filter detections (as a list)\n",
    "                filtered_results = filter_detections(\n",
    "                    results.object_prediction_list,\n",
    "                    image_path,\n",
    "                    max_relative_area=0.0035, # reduced max_relative_area from 0.4 (40%) to 0.0035 (0.35%)\n",
    "                    min_confidence=conf_threshold\n",
    "                )\n",
    "\n",
    "                # get numbers\n",
    "                print(\"\\n\", \"type(filtered_results): \", type(filtered_results))\n",
    "                print(\"len(filtered_results): \", len(filtered_results), \"\\n\")\n",
    "\n",
    "                # visualize area distribution before and after filtering\n",
    "                print(\"\\n> plotting \\'results.object_prediction_list\\' & \\'filtered_results\\' values >\\n\")\n",
    "                plot_area_distribution(results.object_prediction_list, filtered_results) # (original_detections, filtered_detections)\n",
    "\n",
    "                # filter out outliers based on bounding box area using statistical techniques\n",
    "                cleaned_results = remove_area_outliers(filtered_results)\n",
    "\n",
    "                # get numbers\n",
    "                print(\"\\n\", \"type(cleaned_results): \", type(cleaned_results))\n",
    "                print(\"len(cleaned_results): \", len(cleaned_results), \"\\n\")\n",
    "\n",
    "                # visualize area distribution before and after filtering\n",
    "                print(\"\\n> plotting \\'filtered_results\\' & \\'cleaned_results\\' values >\\n\")\n",
    "                plot_area_distribution(filtered_results, cleaned_results) # (original_detections, filtered_detections)\n",
    "\n",
    "                # Update tracking\n",
    "                num_detections = len(cleaned_results) # replaced \"filtered_results\" with \"cleaned_results\" to remove large outliers\n",
    "                total_images += 1\n",
    "                total_detections += num_detections\n",
    "\n",
    "                # Save YOLO format\n",
    "                yolo_output_path = current_yolo_dir / f\"{os.path.splitext(image_name)[0]}.txt\"\n",
    "                with open(yolo_output_path, 'w') as f:\n",
    "                    for pred in cleaned_results: # replaced \"filtered_results\" with \"cleaned_results\" to remove large outliers\n",
    "                        bbox = pred.bbox.to_xyxy()\n",
    "                        class_id = pred.category.id\n",
    "                        conf = float(pred.score.value)\n",
    "                        f.write(f\"{class_id} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]} {conf}\\n\")\n",
    "\n",
    "                # Save LabelMe format results\n",
    "                labelme_json = convert_yolo_to_labelme(\n",
    "                    image_path,\n",
    "                    cleaned_results, # replaced \"filtered_results\" with \"cleaned_results\" to remove large outliers\n",
    "                    detection_model.model.names\n",
    "                )\n",
    "\n",
    "                if labelme_json:\n",
    "                    labelme_output_path = current_labelme_dir / f\"{os.path.splitext(image_name)[0]}.json\"\n",
    "                    with open(labelme_output_path, 'w') as f:\n",
    "                        json.dump(labelme_json, f, indent=2)\n",
    "                else:\n",
    "                    # Track detailed error information\n",
    "                    detailed_errors[image_path] = \"LabelMe JSON conversion failed\"\n",
    "                    failed_images.append(image_path)\n",
    "\n",
    "                logger.info(f\"Completed {image_name}: {num_detections} detections\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Comprehensive error processing {image_path}:\")\n",
    "                logger.error(f\"Error type: {type(e)}\")\n",
    "                logger.error(f\"Error details: {str(e)}\")\n",
    "\n",
    "                # Track detailed error information\n",
    "                detailed_errors[image_path] = str(e)\n",
    "                failed_images.append(image_path)\n",
    "                continue\n",
    "\n",
    "    # Final reporting\n",
    "    end_time = datetime.now()\n",
    "    processing_time = end_time - start_time\n",
    "\n",
    "    logger.info(\"\\nDetection Process Summary:\")\n",
    "    logger.info(f\"Total processing time: {processing_time}\")\n",
    "    logger.info(f\"Total images processed: {total_images}\")\n",
    "    logger.info(f\"Total detections found: {total_detections}\")\n",
    "    logger.info(f\"Average detections per image: {total_detections/total_images:.2f}\" if total_images > 0 else \"No images processed\")\n",
    "\n",
    "    if failed_images:\n",
    "        logger.warning(f\"Failed to process {len(failed_images)} images\")\n",
    "        for img, error in detailed_errors.items():\n",
    "            logger.warning(f\"Image: {img} - Error: {error}\")\n",
    "\n",
    "    logger.info(f\"\\nResults saved in:\")\n",
    "    logger.info(f\"YOLO format: {yolo_dir}\")\n",
    "    logger.info(f\"LabelMe format: {labelme_dir}\")\n",
    "\n",
    "# using the google drive paths from the original script\n",
    "project_input = \"/content/drive/MyDrive/October15.v1i.yolov8\"\n",
    "result_input = f'{project_input}/results'\n",
    "run_input = \"200_epochs-\"\n",
    "model_input = f'{result_input}/{run_input}/weights/best.pt'\n",
    "test_input = f'{project_input}/sampling_set/'\n",
    "\n",
    "# running the execution step code block\n",
    "if __name__ == \"__main__\":\n",
    "    # Verify paths before running\n",
    "    logger.info(\"Verifying paths...\")\n",
    "    logger.info(f\"Model path: {model_input}\")\n",
    "    logger.info(f\"Test images directory: {test_input}\")\n",
    "\n",
    "    if not os.path.exists(model_input):\n",
    "        raise FileNotFoundError(f\"Model file not found at: {model_input}\")\n",
    "\n",
    "    # Run detection with full configuration\n",
    "    test_sahi_yolo(\n",
    "        model_path=model_input,\n",
    "        test_images_dir=test_input,\n",
    "        project_dir=result_input\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHPbXUtHLdH_"
   },
   "source": [
    "# The end."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
